{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\CSANADANSYS\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from category_encoders import BinaryEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from kneed import KneeLocator\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PCAAutoencoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, last_hidden_shape):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.ModuleList(encoder)  # Ensure encoder is a ModuleList\n",
    "        self.decoder = nn.ModuleList(decoder)  # Ensure decoder is a ModuleList\n",
    "        self.last_hidden_shape = last_hidden_shape\n",
    "        self.bottleneck = nn.ModuleList([nn.Linear(in_features=self.last_hidden_shape, out_features=1),\n",
    "                                         nn.BatchNorm1d(num_features=1, affine=False)])\n",
    "\n",
    "    def increase_latentdim(self):\n",
    "        # Create new bottleneck expansion layer\n",
    "        new_bottleneck = nn.ModuleList([nn.Linear(in_features=self.last_hidden_shape, out_features=self.bottleneck[0].out_features + 1),\n",
    "                                        nn.BatchNorm1d(num_features=self.bottleneck[0].out_features + 1, affine=False)])\n",
    "        # Copying weights while freezing old neurons\n",
    "        with torch.no_grad():\n",
    "            new_bottleneck[0].weight[: self.bottleneck[0].out_features] = self.bottleneck[0].weight\n",
    "            new_bottleneck[0].bias[: self.bottleneck[0].out_features] = self.bottleneck[0].bias\n",
    "\n",
    "        self.bottleneck = new_bottleneck  # Replace the layer\n",
    "        self.bottleneck[0].requires_grad_(True)  # Allow gradients\n",
    "\n",
    "        # Freeze the old neurons using a hook\n",
    "        self.bottleneck[0].weight.register_hook(self._freeze_old_neurons_hook)\n",
    "        self.bottleneck[0].bias.register_hook(self._freeze_old_neurons_hook)\n",
    "\n",
    "        # Turn off gradients for all layers in the encoder (just in case)\n",
    "        for layer in self.encoder:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self._recreate_decoder()\n",
    "\n",
    "    def _freeze_old_neurons_hook(self, grad):\n",
    "        \"\"\"Backward hook: Freeze gradients for old neurons, allowing updates only for new ones\"\"\"\n",
    "        grad[: -1] = 0  # Zero out gradients for old neurons\n",
    "        return grad\n",
    "\n",
    "    def _recreate_decoder(self):\n",
    "        # Copying old decoder to new\n",
    "        new_decoder = nn.ModuleList()\n",
    "        for i, layer in enumerate(self.decoder):\n",
    "            if i == 0 and isinstance(layer, nn.Linear):\n",
    "                new_layer = nn.Linear(layer.in_features + 1, layer.out_features)\n",
    "                nn.init.xavier_uniform_(new_layer.weight)\n",
    "                if new_layer.bias is not None:\n",
    "                    nn.init.zeros_(new_layer.bias)\n",
    "                new_decoder.append(new_layer)\n",
    "            else:\n",
    "                new_decoder.append(layer)\n",
    "        \n",
    "        self.decoder = new_decoder  # Ensure it's still a ModuleList\n",
    "\n",
    "    def encode(self, x):\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "        for layer in self.bottleneck:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def decode(self, x):\n",
    "        for layer in self.decoder:\n",
    "            x = layer(x)\n",
    "        return x  # Return the output\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc = self.encode(x)\n",
    "        out = self.decode(enc)\n",
    "        return out, enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCAAE_Loss(nn.Module):\n",
    "    def __init__(self, loss_func, lambda_cov=0.01):\n",
    "        super().__init__()\n",
    "        self.loss_func = loss_func\n",
    "        self.lambda_cov = lambda_cov\n",
    "\n",
    "    \n",
    "    def forward(self, y_hat, y, z):\n",
    "        recon_loss = self.loss_func(y_hat, y)\n",
    "\n",
    "        batch_size, latent_dim = z.shape\n",
    "        z_mean = torch.mean(z, dim=0, keepdim=True)\n",
    "        z_centered = z - z_mean\n",
    "\n",
    "        covariance_matrix = (z_centered.T @ z_centered) / batch_size\n",
    "        covariance_loss = torch.sum(covariance_matrix**2) - torch.sum(torch.diagonal(covariance_matrix)**2)\n",
    "\n",
    "        total_loss = recon_loss + self.lambda_cov * covariance_loss\n",
    "        return total_loss, recon_loss, covariance_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, goal_hidden_dim, optimizer, loss_func, epochs, trainloader, testloader, print_every):\n",
    "    writer = SummaryWriter()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    outer_steps = 0\n",
    "    total_steps = 0\n",
    "    total_train_losses, total_test_losses = [], []\n",
    "    if isinstance(loss_func, PCAAE_Loss):\n",
    "        total_train_recon_losses, total_test_recon_losses = [], []\n",
    "        total_train_cov_losses, total_test_cov_losses = [], []\n",
    "    total_min_testloss = np.Inf\n",
    "    hidden_dim = 1\n",
    "    \n",
    "    while hidden_dim != goal_hidden_dim:\n",
    "        if not outer_steps == 0:\n",
    "            # Increasing latent space\n",
    "            model.increase_latentdim()\n",
    "            hidden_dim += 1\n",
    "            model.to(device)\n",
    "\n",
    "        outer_steps += 1\n",
    "        print(f\"Training with hidden dim: {hidden_dim}\")\n",
    "        steps = 0\n",
    "        train_losses, test_losses = [], []\n",
    "        if isinstance(loss_func, PCAAE_Loss):\n",
    "            train_recon_losses, test_recon_losses = [], []\n",
    "            train_cov_losses, test_cov_losses = [], []\n",
    "        min_test_loss = np.Inf\n",
    "\n",
    "        # Training loop\n",
    "        for e in range(epochs):\n",
    "            running_loss = 0\n",
    "            # Only for printing it\n",
    "            running_loss_ = 0\n",
    "            if isinstance(loss_func, PCAAE_Loss):\n",
    "                running_recon_loss = 0\n",
    "                running_cov_loss = 0\n",
    "                running_recon_loss_ = 0\n",
    "                running_cov_loss_ = 0\n",
    "\n",
    "            for X, y in trainloader:\n",
    "                steps += 1\n",
    "                total_steps += 1\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                y_hat, hidden = model(X)\n",
    "                if isinstance(loss_func, PCAAE_Loss):\n",
    "                    loss, recon_loss, cov_loss = loss_func(y_hat, y, hidden)\n",
    "                    running_recon_loss += recon_loss.item()*X.size(0)\n",
    "                    running_cov_loss += cov_loss.item()*X.size(0)\n",
    "                    running_recon_loss_ += recon_loss.item()\n",
    "                    running_cov_loss_ += cov_loss.item()\n",
    "                else:\n",
    "                    loss = loss_func(y_hat, y)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()*X.size(0)\n",
    "                running_loss_ += loss.item()\n",
    "\n",
    "                if steps % print_every == 0:\n",
    "                    writer.add_scalar(\"Loss x steps/train\", running_loss_/print_every, steps)\n",
    "                    if isinstance(loss_func, PCAAE_Loss):\n",
    "                        print(f\"Epoch: {e + 1}/{epochs}, Step {steps}, Train loss: {running_loss_/print_every:.3f} \" \n",
    "                              f\"Train reconstruction loss: {running_recon_loss_/print_every:.3f} \"\n",
    "                              f\"Train covariance loss: {running_cov_loss_/print_every:.3f}\")\n",
    "                        writer.add_scalar(\"Reconstruction loss x steps/train\", running_recon_loss/print_every, steps)\n",
    "                        writer.add_scalar(\"Covariance loss x steps/train\", running_cov_loss_/print_every, steps)\n",
    "                    else:\n",
    "                        print(f\"Epoch: {e + 1}/{epochs}, Step {steps}, Train loss: {running_loss_/print_every:.3f}\")\n",
    "\n",
    "                    running_loss_ = 0\n",
    "\n",
    "                    if isinstance(loss_func, PCAAE_Loss):\n",
    "                        running_recon_loss_ = 0\n",
    "                        running_cov_loss_ = 0\n",
    "\n",
    "            # Running model on the test data  \n",
    "            else:\n",
    "                running_testloss = 0\n",
    "                if isinstance(loss_func, PCAAE_Loss):\n",
    "                    running_test_recon_loss = 0\n",
    "                    running_test_cov_loss = 0\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    for X, y in testloader:\n",
    "                        X, y = X.to(device), y.to(device)\n",
    "                        y_hat, hidden = model(X)\n",
    "                        if isinstance(loss_func, PCAAE_Loss):\n",
    "                            test_loss, test_recon_loss, test_cov_loss = loss_func(y_hat, y, hidden)\n",
    "                            running_test_recon_loss += test_recon_loss.item()*X.size(0)\n",
    "                            running_test_cov_loss += test_cov_loss.item()*X.size(0)\n",
    "                        else:\n",
    "                            loss = loss_func(y_hat, y)\n",
    "                        running_testloss += test_loss.item()*X.size(0)\n",
    "\n",
    "\n",
    "                model.train()\n",
    "\n",
    "                train_losses.append(running_loss/len(trainloader.dataset))\n",
    "                total_train_losses.append(running_loss/len(trainloader.dataset))\n",
    "                test_losses.append(running_testloss/len(testloader.dataset))\n",
    "                total_test_losses.append(running_testloss/len(testloader.dataset))\n",
    "\n",
    "                if isinstance(loss_func, PCAAE_Loss):\n",
    "                    train_recon_losses.append(running_recon_loss/len(trainloader.dataset))\n",
    "                    total_train_recon_losses.append(running_recon_loss/len(trainloader.dataset))\n",
    "                    train_cov_losses.append(running_cov_loss/len(trainloader.dataset))\n",
    "                    total_train_cov_losses.append(running_cov_loss/len(trainloader.dataset))\n",
    "                    test_recon_losses.append(running_test_recon_loss/len(testloader.dataset))\n",
    "                    total_test_recon_losses.append(running_test_recon_loss/len(testloader.dataset))\n",
    "                    test_cov_losses.append(running_test_cov_loss/len(testloader.dataset))\n",
    "                    total_test_cov_losses.append(running_test_cov_loss/len(testloader.dataset))\n",
    "\n",
    "                # Saving model when test loss improved\n",
    "                if test_losses[-1] <= min_test_loss:\n",
    "                    print('Test loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(min_test_loss,test_losses[-1]))\n",
    "                    torch.save(model.state_dict(), f'PCAAE_hidden_dim{hidden_dim}.pt')\n",
    "                    min_test_loss = test_losses[-1]\n",
    "                \n",
    "                #TODO - Add logging of test losses to the tensorboard session as well\n",
    "                writer.add_scalar(\"Loss x epochs/train\", running_loss/len(trainloader.dataset), e+1)\n",
    "                writer.add_scalar(\"Loss x epochs/test\", running_testloss/len(testloader.dataset), e+1)\n",
    "                if isinstance(loss_func, PCAAE_Loss):\n",
    "                    print(f\"Epoch {e+1}/{epochs},\\nTrain Loss: {running_loss/len(trainloader.dataset):.3f} \"\n",
    "                        f\"Train reconstruction loss: {running_recon_loss_/len(trainloader.dataset):.3f} \"\n",
    "                        f\"Train covariance loss: {running_cov_loss_/len(trainloader.dataset):.3f}\\n\"\n",
    "                        f\"Test Loss: {running_testloss/len(testloader.dataset):.3f} \"\n",
    "                        f\"Test reconstruction loss: {running_test_recon_loss/len(testloader.dataset):.3f} \"\n",
    "                        f\"Test covariance loss: {running_test_cov_loss/len(testloader.dataset):.3f}\")\n",
    "                    writer.add_scalar(\"Reconstruction loss x epochs/train\", running_recon_loss/len(trainloader.dataset), e+1)\n",
    "                    writer.add_scalar(\"Covariance loss x epochs/train\", running_cov_loss/len(trainloader.dataset), e+1)\n",
    "                    writer.add_scalar(\"Reconstruction loss x epochs/test\", running_test_recon_loss/len(trainloader.dataset), e+1)\n",
    "                    writer.add_scalar(\"Covariance loss x epochs/test\", running_test_cov_loss/len(testloader.dataset), e+1)    \n",
    "                else:\n",
    "                    print(f\"Epoch {e+1}/{epochs}\\nTrain Loss: {running_loss/len(trainloader.dataset):.3f} \"\n",
    "                          f\"Test Loss: {running_testloss/len(testloader.dataset):.3f}\")\n",
    "                \n",
    "\n",
    "    logs =  {\"train_losses\": total_train_losses, \n",
    "             \"train_recon_losses\": total_train_recon_losses, \n",
    "             \"train_cov_losses\": total_train_cov_losses, \n",
    "             \"test_losses\": total_test_losses, \n",
    "             \"test_recon_losses\": total_test_recon_losses, \n",
    "             \"test_cov_losses\": total_test_cov_losses, \n",
    "             \"steps\": total_steps}\n",
    "    \n",
    "    writer.close()\n",
    "    return logs           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for tabular data\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "inputFeature = pd.read_csv('../Data/NIBRS_ND_2021/processed/input.csv', index_col='Unnamed: 0')\n",
    "# Separating numerical and categorical features\n",
    "numerical_features=['population','victim_seq_num','age_num_victim','incident_hour','incident_month','incident_day','incident_dayofmonth','incident_weekofyear']\n",
    "categorical_features = ['resident_status_code','race_desc_victim',\n",
    "'ethnicity_name_victim','pub_agency_name','offense_name','location_name','weapon_name'\n",
    ",'injury_name','relationship_name','incident_isweekend']\n",
    "# Onehot-encoding categorical features\n",
    "inputFeature_1h = pd.get_dummies(inputFeature, columns=categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert object columns to numeric if they represent categories\n",
    "for column in inputFeature_1h.select_dtypes(include=['object']):\n",
    "    inputFeature_1h[column] = inputFeature_1h[column].astype('category').cat.codes\n",
    "\n",
    "# Train-test split\n",
    "train, test = train_test_split(inputFeature_1h, test_size=0.1, random_state=42)\n",
    "\n",
    "# Normalizing numerical features\n",
    "for feature in numerical_features:\n",
    "  train[feature] = (train[feature] - train[feature].min()) / (train[feature].max() - train[feature].min())\n",
    "  test[feature] = (test[feature] - test[feature].min()) / (test[feature].max() - test[feature].min())\n",
    "\n",
    "# Converting data to tensors\n",
    "X_train = torch.nan_to_num(torch.Tensor(train.values.astype(np.float32)))\n",
    "y_train = torch.nan_to_num(torch.Tensor(train.values.astype(np.float32)))\n",
    "\n",
    "X_test = torch.nan_to_num(torch.Tensor(test.values.astype(np.float32)))\n",
    "y_test = torch.nan_to_num(torch.Tensor(test.values.astype(np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "trainset = MyDataset(X_train, y_train)\n",
    "testset = MyDataset(X_test, y_test)\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sizes for the layers\n",
    "layer_sizes = [227, 64, 32]  # Example decreasing sizes for the encoder\n",
    "\n",
    "# Create the encoder ModuleList\n",
    "encoder = nn.ModuleList()\n",
    "for i in range(len(layer_sizes) - 1):\n",
    "    encoder.append(nn.Linear(layer_sizes[i], layer_sizes[i + 1]))\n",
    "    encoder.append(nn.ReLU())\n",
    "\n",
    "# Create the decoder ModuleList (mirror of the encoder)\n",
    "decoder = nn.ModuleList()\n",
    "decoder.append(nn.Linear(1, layer_sizes[len(layer_sizes) - 1]))\n",
    "for i in range(len(layer_sizes) - 1, 0, -1):\n",
    "    decoder.append(nn.Linear(layer_sizes[i], layer_sizes[i - 1]))\n",
    "    decoder.append(nn.ReLU())\n",
    "\n",
    "# Remove the last ReLU from the decoder (optional, depending on use case)\n",
    "decoder = decoder[:-1]\n",
    "criterion = PCAAE_Loss(nn.MSELoss())\n",
    "model = PCAAutoencoder(encoder, decoder, 32)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 25\n",
    "print_every = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-10387bb2b67154a8\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-10387bb2b67154a8\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hidden dim: 1\n",
      "Epoch: 1/25, Step 40, Train loss: 0.045 Train reconstruction loss: 0.045 Train covariance loss: 0.000\n",
      "Epoch: 1/25, Step 80, Train loss: 0.025 Train reconstruction loss: 0.025 Train covariance loss: 0.000\n",
      "Epoch: 1/25, Step 120, Train loss: 0.024 Train reconstruction loss: 0.024 Train covariance loss: 0.000\n",
      "Epoch: 1/25, Step 160, Train loss: 0.023 Train reconstruction loss: 0.023 Train covariance loss: 0.000\n",
      "Epoch: 1/25, Step 200, Train loss: 0.023 Train reconstruction loss: 0.023 Train covariance loss: 0.000\n",
      "Epoch: 1/25, Step 240, Train loss: 0.023 Train reconstruction loss: 0.023 Train covariance loss: 0.000\n",
      "Epoch: 1/25, Step 280, Train loss: 0.023 Train reconstruction loss: 0.023 Train covariance loss: 0.000\n",
      "Epoch: 1/25, Step 320, Train loss: 0.023 Train reconstruction loss: 0.023 Train covariance loss: 0.000\n",
      "Epoch: 1/25, Step 360, Train loss: 0.023 Train reconstruction loss: 0.023 Train covariance loss: 0.000\n",
      "Epoch: 1/25, Step 400, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 1/25, Step 440, Train loss: 0.023 Train reconstruction loss: 0.023 Train covariance loss: 0.000\n",
      "Epoch: 1/25, Step 480, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Test loss decreased (inf --> 0.022488).  Saving model ...\n",
      "Epoch 1/25,\n",
      "Train Loss: 0.025 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.022 Test reconstruction loss: 0.022 Test covariance loss: 0.000\n",
      "Epoch: 2/25, Step 520, Train loss: 0.023 Train reconstruction loss: 0.023 Train covariance loss: 0.000\n",
      "Epoch: 2/25, Step 560, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 2/25, Step 600, Train loss: 0.023 Train reconstruction loss: 0.023 Train covariance loss: 0.000\n",
      "Epoch: 2/25, Step 640, Train loss: 0.023 Train reconstruction loss: 0.023 Train covariance loss: 0.000\n",
      "Epoch: 2/25, Step 680, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 2/25, Step 720, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 2/25, Step 760, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 2/25, Step 800, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 2/25, Step 840, Train loss: 0.023 Train reconstruction loss: 0.023 Train covariance loss: 0.000\n",
      "Epoch: 2/25, Step 880, Train loss: 0.023 Train reconstruction loss: 0.023 Train covariance loss: 0.000\n",
      "Epoch: 2/25, Step 920, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 2/25, Step 960, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Test loss decreased (0.022488 --> 0.021838).  Saving model ...\n",
      "Epoch 2/25,\n",
      "Train Loss: 0.022 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.022 Test reconstruction loss: 0.022 Test covariance loss: 0.000\n",
      "Epoch: 3/25, Step 1000, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 3/25, Step 1040, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 3/25, Step 1080, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 3/25, Step 1120, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 3/25, Step 1160, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 3/25, Step 1200, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 3/25, Step 1240, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 3/25, Step 1280, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 3/25, Step 1320, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 3/25, Step 1360, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 3/25, Step 1400, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 3/25, Step 1440, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Test loss decreased (0.021838 --> 0.021534).  Saving model ...\n",
      "Epoch 3/25,\n",
      "Train Loss: 0.022 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.022 Test reconstruction loss: 0.022 Test covariance loss: 0.000\n",
      "Epoch: 4/25, Step 1480, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 4/25, Step 1520, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 4/25, Step 1560, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 4/25, Step 1600, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 4/25, Step 1640, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 4/25, Step 1680, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 4/25, Step 1720, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 4/25, Step 1760, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 4/25, Step 1800, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 4/25, Step 1840, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 4/25, Step 1880, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 4/25, Step 1920, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Test loss decreased (0.021534 --> 0.021452).  Saving model ...\n",
      "Epoch 4/25,\n",
      "Train Loss: 0.022 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 5/25, Step 1960, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 5/25, Step 2000, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 5/25, Step 2040, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 5/25, Step 2080, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 5/25, Step 2120, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 5/25, Step 2160, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 5/25, Step 2200, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 5/25, Step 2240, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 5/25, Step 2280, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 5/25, Step 2320, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 5/25, Step 2360, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 5/25, Step 2400, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Test loss decreased (0.021452 --> 0.021245).  Saving model ...\n",
      "Epoch 5/25,\n",
      "Train Loss: 0.022 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 6/25, Step 2440, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 6/25, Step 2480, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 6/25, Step 2520, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 6/25, Step 2560, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 6/25, Step 2600, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 6/25, Step 2640, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 6/25, Step 2680, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 6/25, Step 2720, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 6/25, Step 2760, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 6/25, Step 2800, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 6/25, Step 2840, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 6/25, Step 2880, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Test loss decreased (0.021245 --> 0.020999).  Saving model ...\n",
      "Epoch 6/25,\n",
      "Train Loss: 0.022 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 7/25, Step 2920, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 7/25, Step 2960, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 7/25, Step 3000, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 7/25, Step 3040, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 7/25, Step 3080, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 7/25, Step 3120, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 7/25, Step 3160, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 7/25, Step 3200, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 7/25, Step 3240, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 7/25, Step 3280, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 7/25, Step 3320, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 7/25, Step 3360, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Test loss decreased (0.020999 --> 0.020984).  Saving model ...\n",
      "Epoch 7/25,\n",
      "Train Loss: 0.022 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 8/25, Step 3400, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 8/25, Step 3440, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 8/25, Step 3480, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 8/25, Step 3520, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 8/25, Step 3560, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 8/25, Step 3600, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 8/25, Step 3640, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 8/25, Step 3680, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 8/25, Step 3720, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 8/25, Step 3760, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 8/25, Step 3800, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 8/25, Step 3840, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Test loss decreased (0.020984 --> 0.020837).  Saving model ...\n",
      "Epoch 8/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 9/25, Step 3880, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 9/25, Step 3920, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 9/25, Step 3960, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 9/25, Step 4000, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 9/25, Step 4040, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 9/25, Step 4080, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 9/25, Step 4120, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 9/25, Step 4160, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 9/25, Step 4200, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 9/25, Step 4240, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 9/25, Step 4280, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 9/25, Step 4320, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Test loss decreased (0.020837 --> 0.020704).  Saving model ...\n",
      "Epoch 9/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 10/25, Step 4360, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 10/25, Step 4400, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 10/25, Step 4440, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 10/25, Step 4480, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 10/25, Step 4520, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 10/25, Step 4560, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 10/25, Step 4600, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 10/25, Step 4640, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 10/25, Step 4680, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 10/25, Step 4720, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 10/25, Step 4760, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 10/25, Step 4800, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Test loss decreased (0.020704 --> 0.020651).  Saving model ...\n",
      "Epoch 10/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 11/25, Step 4840, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 11/25, Step 4880, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 11/25, Step 4920, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 11/25, Step 4960, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 11/25, Step 5000, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 11/25, Step 5040, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 11/25, Step 5080, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 11/25, Step 5120, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 11/25, Step 5160, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 11/25, Step 5200, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 11/25, Step 5240, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 11/25, Step 5280, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch 11/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 12/25, Step 5320, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 12/25, Step 5360, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 12/25, Step 5400, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 12/25, Step 5440, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 12/25, Step 5480, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 12/25, Step 5520, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 12/25, Step 5560, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 12/25, Step 5600, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 12/25, Step 5640, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 12/25, Step 5680, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 12/25, Step 5720, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 12/25, Step 5760, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Test loss decreased (0.020651 --> 0.020623).  Saving model ...\n",
      "Epoch 12/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 13/25, Step 5800, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 13/25, Step 5840, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 13/25, Step 5880, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 13/25, Step 5920, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 13/25, Step 5960, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 13/25, Step 6000, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 13/25, Step 6040, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 13/25, Step 6080, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 13/25, Step 6120, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 13/25, Step 6160, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 13/25, Step 6200, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 13/25, Step 6240, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Test loss decreased (0.020623 --> 0.020623).  Saving model ...\n",
      "Epoch 13/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 14/25, Step 6280, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 14/25, Step 6320, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 14/25, Step 6360, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 14/25, Step 6400, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 14/25, Step 6440, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 14/25, Step 6480, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 14/25, Step 6520, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 14/25, Step 6560, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 14/25, Step 6600, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 14/25, Step 6640, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 14/25, Step 6680, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 14/25, Step 6720, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch 14/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 15/25, Step 6760, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 15/25, Step 6800, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 15/25, Step 6840, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 15/25, Step 6880, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 15/25, Step 6920, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 15/25, Step 6960, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 15/25, Step 7000, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 15/25, Step 7040, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 15/25, Step 7080, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 15/25, Step 7120, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 15/25, Step 7160, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 15/25, Step 7200, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch 15/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 16/25, Step 7240, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 16/25, Step 7280, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 16/25, Step 7320, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 16/25, Step 7360, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 16/25, Step 7400, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 16/25, Step 7440, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 16/25, Step 7480, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 16/25, Step 7520, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 16/25, Step 7560, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 16/25, Step 7600, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 16/25, Step 7640, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 16/25, Step 7680, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch 16/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 17/25, Step 7720, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 17/25, Step 7760, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 17/25, Step 7800, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 17/25, Step 7840, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 17/25, Step 7880, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 17/25, Step 7920, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 17/25, Step 7960, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 17/25, Step 8000, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 17/25, Step 8040, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 17/25, Step 8080, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 17/25, Step 8120, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 17/25, Step 8160, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch 17/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 18/25, Step 8200, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 18/25, Step 8240, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 18/25, Step 8280, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 18/25, Step 8320, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 18/25, Step 8360, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 18/25, Step 8400, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 18/25, Step 8440, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 18/25, Step 8480, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 18/25, Step 8520, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 18/25, Step 8560, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 18/25, Step 8600, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 18/25, Step 8640, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch 18/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 19/25, Step 8680, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 19/25, Step 8720, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 19/25, Step 8760, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 19/25, Step 8800, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 19/25, Step 8840, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 19/25, Step 8880, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 19/25, Step 8920, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 19/25, Step 8960, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 19/25, Step 9000, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 19/25, Step 9040, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 19/25, Step 9080, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 19/25, Step 9120, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch 19/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 20/25, Step 9160, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 20/25, Step 9200, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 20/25, Step 9240, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 20/25, Step 9280, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 20/25, Step 9320, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 20/25, Step 9360, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 20/25, Step 9400, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 20/25, Step 9440, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 20/25, Step 9480, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 20/25, Step 9520, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 20/25, Step 9560, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 20/25, Step 9600, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch 20/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 21/25, Step 9640, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 21/25, Step 9680, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 21/25, Step 9720, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 21/25, Step 9760, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 21/25, Step 9800, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 21/25, Step 9840, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 21/25, Step 9880, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 21/25, Step 9920, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 21/25, Step 9960, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 21/25, Step 10000, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 21/25, Step 10040, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 21/25, Step 10080, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch 21/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 22/25, Step 10120, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 22/25, Step 10160, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 22/25, Step 10200, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 22/25, Step 10240, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 22/25, Step 10280, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 22/25, Step 10320, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 22/25, Step 10360, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 22/25, Step 10400, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 22/25, Step 10440, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 22/25, Step 10480, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 22/25, Step 10520, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 22/25, Step 10560, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch 22/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 23/25, Step 10600, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 23/25, Step 10640, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 23/25, Step 10680, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 23/25, Step 10720, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 23/25, Step 10760, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 23/25, Step 10800, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 23/25, Step 10840, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 23/25, Step 10880, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 23/25, Step 10920, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 23/25, Step 10960, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 23/25, Step 11000, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 23/25, Step 11040, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch 23/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 24/25, Step 11080, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 24/25, Step 11120, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 24/25, Step 11160, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 24/25, Step 11200, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 24/25, Step 11240, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 24/25, Step 11280, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 24/25, Step 11320, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 24/25, Step 11360, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 24/25, Step 11400, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 24/25, Step 11440, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 24/25, Step 11480, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 24/25, Step 11520, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Test loss decreased (0.020623 --> 0.020534).  Saving model ...\n",
      "Epoch 24/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 25/25, Step 11560, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 25/25, Step 11600, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 25/25, Step 11640, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 25/25, Step 11680, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 25/25, Step 11720, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 25/25, Step 11760, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 25/25, Step 11800, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 25/25, Step 11840, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 25/25, Step 11880, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 25/25, Step 11920, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 25/25, Step 11960, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 25/25, Step 12000, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Test loss decreased (0.020534 --> 0.020101).  Saving model ...\n",
      "Epoch 25/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.020 Test reconstruction loss: 0.020 Test covariance loss: 0.000\n",
      "Training with hidden dim: 2\n",
      "Epoch: 1/25, Step 40, Train loss: 0.036 Train reconstruction loss: 0.026 Train covariance loss: 0.996\n",
      "Epoch: 1/25, Step 80, Train loss: 0.033 Train reconstruction loss: 0.022 Train covariance loss: 1.141\n",
      "Epoch: 1/25, Step 120, Train loss: 0.033 Train reconstruction loss: 0.022 Train covariance loss: 1.178\n",
      "Epoch: 1/25, Step 160, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 0.992\n",
      "Epoch: 1/25, Step 200, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 0.994\n",
      "Epoch: 1/25, Step 240, Train loss: 0.032 Train reconstruction loss: 0.021 Train covariance loss: 1.136\n",
      "Epoch: 1/25, Step 280, Train loss: 0.033 Train reconstruction loss: 0.021 Train covariance loss: 1.201\n",
      "Epoch: 1/25, Step 320, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 1.010\n",
      "Epoch: 1/25, Step 360, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 1.063\n",
      "Epoch: 1/25, Step 400, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 0.995\n",
      "Epoch: 1/25, Step 440, Train loss: 0.032 Train reconstruction loss: 0.021 Train covariance loss: 1.114\n",
      "Epoch: 1/25, Step 480, Train loss: 0.032 Train reconstruction loss: 0.021 Train covariance loss: 1.063\n",
      "Test loss decreased (inf --> 0.029883).  Saving model ...\n",
      "Epoch 1/25,\n",
      "Train Loss: 0.032 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.030 Test reconstruction loss: 0.020 Test covariance loss: 0.958\n",
      "Epoch: 2/25, Step 520, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 1.007\n",
      "Epoch: 2/25, Step 560, Train loss: 0.032 Train reconstruction loss: 0.021 Train covariance loss: 1.182\n",
      "Epoch: 2/25, Step 600, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 1.071\n",
      "Epoch: 2/25, Step 640, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 1.043\n",
      "Epoch: 2/25, Step 680, Train loss: 0.032 Train reconstruction loss: 0.021 Train covariance loss: 1.094\n",
      "Epoch: 2/25, Step 720, Train loss: 0.032 Train reconstruction loss: 0.021 Train covariance loss: 1.084\n",
      "Epoch: 2/25, Step 760, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 1.058\n",
      "Epoch: 2/25, Step 800, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 1.054\n",
      "Epoch: 2/25, Step 840, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.151\n",
      "Epoch: 2/25, Step 880, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 1.014\n",
      "Epoch: 2/25, Step 920, Train loss: 0.032 Train reconstruction loss: 0.021 Train covariance loss: 1.064\n",
      "Epoch: 2/25, Step 960, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.135\n",
      "Epoch 2/25,\n",
      "Train Loss: 0.032 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.031 Test reconstruction loss: 0.020 Test covariance loss: 1.051\n",
      "Epoch: 3/25, Step 1000, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.155\n",
      "Epoch: 3/25, Step 1040, Train loss: 0.032 Train reconstruction loss: 0.021 Train covariance loss: 1.074\n",
      "Epoch: 3/25, Step 1080, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 1.002\n",
      "Epoch: 3/25, Step 1120, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.222\n",
      "Epoch: 3/25, Step 1160, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.166\n",
      "Epoch: 3/25, Step 1200, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.041\n",
      "Epoch: 3/25, Step 1240, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 1.003\n",
      "Epoch: 3/25, Step 1280, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 1.001\n",
      "Epoch: 3/25, Step 1320, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 1.009\n",
      "Epoch: 3/25, Step 1360, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.047\n",
      "Epoch: 3/25, Step 1400, Train loss: 0.030 Train reconstruction loss: 0.021 Train covariance loss: 0.957\n",
      "Epoch: 3/25, Step 1440, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 1.077\n",
      "Test loss decreased (0.029883 --> 0.029587).  Saving model ...\n",
      "Epoch 3/25,\n",
      "Train Loss: 0.031 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.030 Test reconstruction loss: 0.020 Test covariance loss: 0.962\n",
      "Epoch: 4/25, Step 1480, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.092\n",
      "Epoch: 4/25, Step 1520, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.121\n",
      "Epoch: 4/25, Step 1560, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.111\n",
      "Epoch: 4/25, Step 1600, Train loss: 0.032 Train reconstruction loss: 0.021 Train covariance loss: 1.155\n",
      "Epoch: 4/25, Step 1640, Train loss: 0.032 Train reconstruction loss: 0.021 Train covariance loss: 1.154\n",
      "Epoch: 4/25, Step 1680, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 1.003\n",
      "Epoch: 4/25, Step 1720, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.990\n",
      "Epoch: 4/25, Step 1760, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 1.053\n",
      "Epoch: 4/25, Step 1800, Train loss: 0.030 Train reconstruction loss: 0.021 Train covariance loss: 0.989\n",
      "Epoch: 4/25, Step 1840, Train loss: 0.032 Train reconstruction loss: 0.021 Train covariance loss: 1.090\n",
      "Epoch: 4/25, Step 1880, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.147\n",
      "Epoch: 4/25, Step 1920, Train loss: 0.032 Train reconstruction loss: 0.021 Train covariance loss: 1.129\n",
      "Epoch 4/25,\n",
      "Train Loss: 0.031 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.031 Test reconstruction loss: 0.020 Test covariance loss: 1.141\n",
      "Epoch: 5/25, Step 1960, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.047\n",
      "Epoch: 5/25, Step 2000, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 1.042\n",
      "Epoch: 5/25, Step 2040, Train loss: 0.032 Train reconstruction loss: 0.021 Train covariance loss: 1.122\n",
      "Epoch: 5/25, Step 2080, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.142\n",
      "Epoch: 5/25, Step 2120, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.000\n",
      "Epoch: 5/25, Step 2160, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.017\n",
      "Epoch: 5/25, Step 2200, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.136\n",
      "Epoch: 5/25, Step 2240, Train loss: 0.032 Train reconstruction loss: 0.021 Train covariance loss: 1.137\n",
      "Epoch: 5/25, Step 2280, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 1.080\n",
      "Epoch: 5/25, Step 2320, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.071\n",
      "Epoch: 5/25, Step 2360, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.982\n",
      "Epoch: 5/25, Step 2400, Train loss: 0.030 Train reconstruction loss: 0.021 Train covariance loss: 0.983\n",
      "Test loss decreased (0.029587 --> 0.029314).  Saving model ...\n",
      "Epoch 5/25,\n",
      "Train Loss: 0.031 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.029 Test reconstruction loss: 0.020 Test covariance loss: 0.955\n",
      "Epoch: 6/25, Step 2440, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.055\n",
      "Epoch: 6/25, Step 2480, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.017\n",
      "Epoch: 6/25, Step 2520, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.065\n",
      "Epoch: 6/25, Step 2560, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.067\n",
      "Epoch: 6/25, Step 2600, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.965\n",
      "Epoch: 6/25, Step 2640, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.056\n",
      "Epoch: 6/25, Step 2680, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.993\n",
      "Epoch: 6/25, Step 2720, Train loss: 0.033 Train reconstruction loss: 0.021 Train covariance loss: 1.244\n",
      "Epoch: 6/25, Step 2760, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.082\n",
      "Epoch: 6/25, Step 2800, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.143\n",
      "Epoch: 6/25, Step 2840, Train loss: 0.032 Train reconstruction loss: 0.021 Train covariance loss: 1.106\n",
      "Epoch: 6/25, Step 2880, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.081\n",
      "Epoch 6/25,\n",
      "Train Loss: 0.031 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.030 Test reconstruction loss: 0.020 Test covariance loss: 1.049\n",
      "Epoch: 7/25, Step 2920, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.190\n",
      "Epoch: 7/25, Step 2960, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.929\n",
      "Epoch: 7/25, Step 3000, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.161\n",
      "Epoch: 7/25, Step 3040, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.939\n",
      "Epoch: 7/25, Step 3080, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.962\n",
      "Epoch: 7/25, Step 3120, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.125\n",
      "Epoch: 7/25, Step 3160, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.015\n",
      "Epoch: 7/25, Step 3200, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.016\n",
      "Epoch: 7/25, Step 3240, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.986\n",
      "Epoch: 7/25, Step 3280, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.136\n",
      "Epoch: 7/25, Step 3320, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.184\n",
      "Epoch: 7/25, Step 3360, Train loss: 0.032 Train reconstruction loss: 0.021 Train covariance loss: 1.179\n",
      "Epoch 7/25,\n",
      "Train Loss: 0.031 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.031 Test reconstruction loss: 0.020 Test covariance loss: 1.148\n",
      "Epoch: 8/25, Step 3400, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.138\n",
      "Epoch: 8/25, Step 3440, Train loss: 0.032 Train reconstruction loss: 0.021 Train covariance loss: 1.068\n",
      "Epoch: 8/25, Step 3480, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.089\n",
      "Epoch: 8/25, Step 3520, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.112\n",
      "Epoch: 8/25, Step 3560, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 1.070\n",
      "Epoch: 8/25, Step 3600, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.161\n",
      "Epoch: 8/25, Step 3640, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.185\n",
      "Epoch: 8/25, Step 3680, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.952\n",
      "Epoch: 8/25, Step 3720, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.982\n",
      "Epoch: 8/25, Step 3760, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.005\n",
      "Epoch: 8/25, Step 3800, Train loss: 0.032 Train reconstruction loss: 0.021 Train covariance loss: 1.101\n",
      "Epoch: 8/25, Step 3840, Train loss: 0.032 Train reconstruction loss: 0.021 Train covariance loss: 1.094\n",
      "Epoch 8/25,\n",
      "Train Loss: 0.031 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.030 Test reconstruction loss: 0.020 Test covariance loss: 1.035\n",
      "Epoch: 9/25, Step 3880, Train loss: 0.030 Train reconstruction loss: 0.021 Train covariance loss: 0.977\n",
      "Epoch: 9/25, Step 3920, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.153\n",
      "Epoch: 9/25, Step 3960, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.002\n",
      "Epoch: 9/25, Step 4000, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.074\n",
      "Epoch: 9/25, Step 4040, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.079\n",
      "Epoch: 9/25, Step 4080, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.182\n",
      "Epoch: 9/25, Step 4120, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.074\n",
      "Epoch: 9/25, Step 4160, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.955\n",
      "Epoch: 9/25, Step 4200, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.028\n",
      "Epoch: 9/25, Step 4240, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.192\n",
      "Epoch: 9/25, Step 4280, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.012\n",
      "Epoch: 9/25, Step 4320, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.066\n",
      "Epoch 9/25,\n",
      "Train Loss: 0.031 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.031 Test reconstruction loss: 0.020 Test covariance loss: 1.094\n",
      "Epoch: 10/25, Step 4360, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.060\n",
      "Epoch: 10/25, Step 4400, Train loss: 0.032 Train reconstruction loss: 0.021 Train covariance loss: 1.155\n",
      "Epoch: 10/25, Step 4440, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.099\n",
      "Epoch: 10/25, Step 4480, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.074\n",
      "Epoch: 10/25, Step 4520, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.070\n",
      "Epoch: 10/25, Step 4560, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.124\n",
      "Epoch: 10/25, Step 4600, Train loss: 0.029 Train reconstruction loss: 0.020 Train covariance loss: 0.876\n",
      "Epoch: 10/25, Step 4640, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.073\n",
      "Epoch: 10/25, Step 4680, Train loss: 0.033 Train reconstruction loss: 0.020 Train covariance loss: 1.234\n",
      "Epoch: 10/25, Step 4720, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.997\n",
      "Epoch: 10/25, Step 4760, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.139\n",
      "Epoch: 10/25, Step 4800, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.982\n",
      "Test loss decreased (0.029314 --> 0.028634).  Saving model ...\n",
      "Epoch 10/25,\n",
      "Train Loss: 0.031 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.029 Test reconstruction loss: 0.020 Test covariance loss: 0.903\n",
      "Epoch: 11/25, Step 4840, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.119\n",
      "Epoch: 11/25, Step 4880, Train loss: 0.029 Train reconstruction loss: 0.021 Train covariance loss: 0.859\n",
      "Epoch: 11/25, Step 4920, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.031\n",
      "Epoch: 11/25, Step 4960, Train loss: 0.033 Train reconstruction loss: 0.020 Train covariance loss: 1.241\n",
      "Epoch: 11/25, Step 5000, Train loss: 0.029 Train reconstruction loss: 0.020 Train covariance loss: 0.952\n",
      "Epoch: 11/25, Step 5040, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.165\n",
      "Epoch: 11/25, Step 5080, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.039\n",
      "Epoch: 11/25, Step 5120, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.118\n",
      "Epoch: 11/25, Step 5160, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.992\n",
      "Epoch: 11/25, Step 5200, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.184\n",
      "Epoch: 11/25, Step 5240, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.152\n",
      "Epoch: 11/25, Step 5280, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 1.014\n",
      "Epoch 11/25,\n",
      "Train Loss: 0.031 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.030 Test reconstruction loss: 0.020 Test covariance loss: 0.994\n",
      "Epoch: 12/25, Step 5320, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.205\n",
      "Epoch: 12/25, Step 5360, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.032\n",
      "Epoch: 12/25, Step 5400, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.084\n",
      "Epoch: 12/25, Step 5440, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.083\n",
      "Epoch: 12/25, Step 5480, Train loss: 0.029 Train reconstruction loss: 0.020 Train covariance loss: 0.956\n",
      "Epoch: 12/25, Step 5520, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.003\n",
      "Epoch: 12/25, Step 5560, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.133\n",
      "Epoch: 12/25, Step 5600, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.086\n",
      "Epoch: 12/25, Step 5640, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.056\n",
      "Epoch: 12/25, Step 5680, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.018\n",
      "Epoch: 12/25, Step 5720, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.115\n",
      "Epoch: 12/25, Step 5760, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.075\n",
      "Epoch 12/25,\n",
      "Train Loss: 0.031 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.030 Test reconstruction loss: 0.020 Test covariance loss: 1.000\n",
      "Epoch: 13/25, Step 5800, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.017\n",
      "Epoch: 13/25, Step 5840, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.115\n",
      "Epoch: 13/25, Step 5880, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.031\n",
      "Epoch: 13/25, Step 5920, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.059\n",
      "Epoch: 13/25, Step 5960, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.138\n",
      "Epoch: 13/25, Step 6000, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.081\n",
      "Epoch: 13/25, Step 6040, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.169\n",
      "Epoch: 13/25, Step 6080, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.209\n",
      "Epoch: 13/25, Step 6120, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.036\n",
      "Epoch: 13/25, Step 6160, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.977\n",
      "Epoch: 13/25, Step 6200, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.069\n",
      "Epoch: 13/25, Step 6240, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.020\n",
      "Epoch 13/25,\n",
      "Train Loss: 0.031 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.030 Test reconstruction loss: 0.020 Test covariance loss: 0.993\n",
      "Epoch: 14/25, Step 6280, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 1.047\n",
      "Epoch: 14/25, Step 6320, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.979\n",
      "Epoch: 14/25, Step 6360, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.048\n",
      "Epoch: 14/25, Step 6400, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.179\n",
      "Epoch: 14/25, Step 6440, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.009\n",
      "Epoch: 14/25, Step 6480, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.987\n",
      "Epoch: 14/25, Step 6520, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.142\n",
      "Epoch: 14/25, Step 6560, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.106\n",
      "Epoch: 14/25, Step 6600, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.041\n",
      "Epoch: 14/25, Step 6640, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.154\n",
      "Epoch: 14/25, Step 6680, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 1.041\n",
      "Epoch: 14/25, Step 6720, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.053\n",
      "Epoch 14/25,\n",
      "Train Loss: 0.031 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.029 Test reconstruction loss: 0.019 Test covariance loss: 0.973\n",
      "Epoch: 15/25, Step 6760, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.997\n",
      "Epoch: 15/25, Step 6800, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.066\n",
      "Epoch: 15/25, Step 6840, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.023\n",
      "Epoch: 15/25, Step 6880, Train loss: 0.032 Train reconstruction loss: 0.021 Train covariance loss: 1.136\n",
      "Epoch: 15/25, Step 6920, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.053\n",
      "Epoch: 15/25, Step 6960, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.031\n",
      "Epoch: 15/25, Step 7000, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.061\n",
      "Epoch: 15/25, Step 7040, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.170\n",
      "Epoch: 15/25, Step 7080, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.103\n",
      "Epoch: 15/25, Step 7120, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.157\n",
      "Epoch: 15/25, Step 7160, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.075\n",
      "Epoch: 15/25, Step 7200, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.057\n",
      "Epoch 15/25,\n",
      "Train Loss: 0.031 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.030 Test reconstruction loss: 0.020 Test covariance loss: 1.058\n",
      "Epoch: 16/25, Step 7240, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.985\n",
      "Epoch: 16/25, Step 7280, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.004\n",
      "Epoch: 16/25, Step 7320, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.035\n",
      "Epoch: 16/25, Step 7360, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.154\n",
      "Epoch: 16/25, Step 7400, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.154\n",
      "Epoch: 16/25, Step 7440, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.066\n",
      "Epoch: 16/25, Step 7480, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.042\n",
      "Epoch: 16/25, Step 7520, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.076\n",
      "Epoch: 16/25, Step 7560, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.199\n",
      "Epoch: 16/25, Step 7600, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.091\n",
      "Epoch: 16/25, Step 7640, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.945\n",
      "Epoch: 16/25, Step 7680, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.148\n",
      "Epoch 16/25,\n",
      "Train Loss: 0.031 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.029 Test reconstruction loss: 0.019 Test covariance loss: 0.925\n",
      "Epoch: 17/25, Step 7720, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.045\n",
      "Epoch: 17/25, Step 7760, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.135\n",
      "Epoch: 17/25, Step 7800, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.066\n",
      "Epoch: 17/25, Step 7840, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 1.026\n",
      "Epoch: 17/25, Step 7880, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.028\n",
      "Epoch: 17/25, Step 7920, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.114\n",
      "Epoch: 17/25, Step 7960, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.104\n",
      "Epoch: 17/25, Step 8000, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.139\n",
      "Epoch: 17/25, Step 8040, Train loss: 0.029 Train reconstruction loss: 0.020 Train covariance loss: 0.943\n",
      "Epoch: 17/25, Step 8080, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.170\n",
      "Epoch: 17/25, Step 8120, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.055\n",
      "Epoch: 17/25, Step 8160, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.124\n",
      "Epoch 17/25,\n",
      "Train Loss: 0.031 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.031 Test reconstruction loss: 0.019 Test covariance loss: 1.181\n",
      "Epoch: 18/25, Step 8200, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.079\n",
      "Epoch: 18/25, Step 8240, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.044\n",
      "Epoch: 18/25, Step 8280, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.986\n",
      "Epoch: 18/25, Step 8320, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.149\n",
      "Epoch: 18/25, Step 8360, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.039\n",
      "Epoch: 18/25, Step 8400, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.115\n",
      "Epoch: 18/25, Step 8440, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.987\n",
      "Epoch: 18/25, Step 8480, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.108\n",
      "Epoch: 18/25, Step 8520, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.200\n",
      "Epoch: 18/25, Step 8560, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 1.013\n",
      "Epoch: 18/25, Step 8600, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.136\n",
      "Epoch: 18/25, Step 8640, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.948\n",
      "Epoch 18/25,\n",
      "Train Loss: 0.031 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.030 Test reconstruction loss: 0.019 Test covariance loss: 1.027\n",
      "Epoch: 19/25, Step 8680, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.067\n",
      "Epoch: 19/25, Step 8720, Train loss: 0.029 Train reconstruction loss: 0.020 Train covariance loss: 0.921\n",
      "Epoch: 19/25, Step 8760, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.003\n",
      "Epoch: 19/25, Step 8800, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.150\n",
      "Epoch: 19/25, Step 8840, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.033\n",
      "Epoch: 19/25, Step 8880, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.978\n",
      "Epoch: 19/25, Step 8920, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.074\n",
      "Epoch: 19/25, Step 8960, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.081\n",
      "Epoch: 19/25, Step 9000, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.087\n",
      "Epoch: 19/25, Step 9040, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.054\n",
      "Epoch: 19/25, Step 9080, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.144\n",
      "Epoch: 19/25, Step 9120, Train loss: 0.033 Train reconstruction loss: 0.020 Train covariance loss: 1.254\n",
      "Epoch 19/25,\n",
      "Train Loss: 0.031 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.031 Test reconstruction loss: 0.019 Test covariance loss: 1.137\n",
      "Epoch: 20/25, Step 9160, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.977\n",
      "Epoch: 20/25, Step 9200, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.094\n",
      "Epoch: 20/25, Step 9240, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.039\n",
      "Epoch: 20/25, Step 9280, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.180\n",
      "Epoch: 20/25, Step 9320, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.133\n",
      "Epoch: 20/25, Step 9360, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.124\n",
      "Epoch: 20/25, Step 9400, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.016\n",
      "Epoch: 20/25, Step 9440, Train loss: 0.030 Train reconstruction loss: 0.021 Train covariance loss: 0.987\n",
      "Epoch: 20/25, Step 9480, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.039\n",
      "Epoch: 20/25, Step 9520, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.990\n",
      "Epoch: 20/25, Step 9560, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.042\n",
      "Epoch: 20/25, Step 9600, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.030\n",
      "Epoch 20/25,\n",
      "Train Loss: 0.031 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.029 Test reconstruction loss: 0.019 Test covariance loss: 0.954\n",
      "Epoch: 21/25, Step 9640, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.031\n",
      "Epoch: 21/25, Step 9680, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.031\n",
      "Epoch: 21/25, Step 9720, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.169\n",
      "Epoch: 21/25, Step 9760, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.173\n",
      "Epoch: 21/25, Step 9800, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.082\n",
      "Epoch: 21/25, Step 9840, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.143\n",
      "Epoch: 21/25, Step 9880, Train loss: 0.029 Train reconstruction loss: 0.020 Train covariance loss: 0.961\n",
      "Epoch: 21/25, Step 9920, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.087\n",
      "Epoch: 21/25, Step 9960, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.001\n",
      "Epoch: 21/25, Step 10000, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 1.018\n",
      "Epoch: 21/25, Step 10040, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.146\n",
      "Epoch: 21/25, Step 10080, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.065\n",
      "Epoch 21/25,\n",
      "Train Loss: 0.031 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.029 Test reconstruction loss: 0.019 Test covariance loss: 0.944\n",
      "Epoch: 22/25, Step 10120, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.149\n",
      "Epoch: 22/25, Step 10160, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.143\n",
      "Epoch: 22/25, Step 10200, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.933\n",
      "Epoch: 22/25, Step 10240, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.042\n",
      "Epoch: 22/25, Step 10280, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.018\n",
      "Epoch: 22/25, Step 10320, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.049\n",
      "Epoch: 22/25, Step 10360, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.092\n",
      "Epoch: 22/25, Step 10400, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.164\n",
      "Epoch: 22/25, Step 10440, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.099\n",
      "Epoch: 22/25, Step 10480, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.997\n",
      "Epoch: 22/25, Step 10520, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.213\n",
      "Epoch: 22/25, Step 10560, Train loss: 0.031 Train reconstruction loss: 0.021 Train covariance loss: 1.064\n",
      "Epoch 22/25,\n",
      "Train Loss: 0.031 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.029 Test reconstruction loss: 0.019 Test covariance loss: 0.951\n",
      "Epoch: 23/25, Step 10600, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.035\n",
      "Epoch: 23/25, Step 10640, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.039\n",
      "Epoch: 23/25, Step 10680, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.079\n",
      "Epoch: 23/25, Step 10720, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.065\n",
      "Epoch: 23/25, Step 10760, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 0.949\n",
      "Epoch: 23/25, Step 10800, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.133\n",
      "Epoch: 23/25, Step 10840, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.092\n",
      "Epoch: 23/25, Step 10880, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.134\n",
      "Epoch: 23/25, Step 10920, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.264\n",
      "Epoch: 23/25, Step 10960, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.075\n",
      "Epoch: 23/25, Step 11000, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.046\n",
      "Epoch: 23/25, Step 11040, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.028\n",
      "Epoch 23/25,\n",
      "Train Loss: 0.031 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.031 Test reconstruction loss: 0.019 Test covariance loss: 1.170\n",
      "Epoch: 24/25, Step 11080, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.089\n",
      "Epoch: 24/25, Step 11120, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.047\n",
      "Epoch: 24/25, Step 11160, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.099\n",
      "Epoch: 24/25, Step 11200, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.029\n",
      "Epoch: 24/25, Step 11240, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.118\n",
      "Epoch: 24/25, Step 11280, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.082\n",
      "Epoch: 24/25, Step 11320, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.140\n",
      "Epoch: 24/25, Step 11360, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.013\n",
      "Epoch: 24/25, Step 11400, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.074\n",
      "Epoch: 24/25, Step 11440, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.027\n",
      "Epoch: 24/25, Step 11480, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.112\n",
      "Epoch: 24/25, Step 11520, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.085\n",
      "Epoch 24/25,\n",
      "Train Loss: 0.031 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.029 Test reconstruction loss: 0.019 Test covariance loss: 0.935\n",
      "Epoch: 25/25, Step 11560, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.082\n",
      "Epoch: 25/25, Step 11600, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.131\n",
      "Epoch: 25/25, Step 11640, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.024\n",
      "Epoch: 25/25, Step 11680, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.018\n",
      "Epoch: 25/25, Step 11720, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.137\n",
      "Epoch: 25/25, Step 11760, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.023\n",
      "Epoch: 25/25, Step 11800, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.040\n",
      "Epoch: 25/25, Step 11840, Train loss: 0.033 Train reconstruction loss: 0.020 Train covariance loss: 1.255\n",
      "Epoch: 25/25, Step 11880, Train loss: 0.031 Train reconstruction loss: 0.020 Train covariance loss: 1.074\n",
      "Epoch: 25/25, Step 11920, Train loss: 0.030 Train reconstruction loss: 0.020 Train covariance loss: 1.023\n",
      "Epoch: 25/25, Step 11960, Train loss: 0.029 Train reconstruction loss: 0.020 Train covariance loss: 0.973\n",
      "Epoch: 25/25, Step 12000, Train loss: 0.032 Train reconstruction loss: 0.020 Train covariance loss: 1.190\n",
      "Epoch 25/25,\n",
      "Train Loss: 0.031 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.030 Test reconstruction loss: 0.019 Test covariance loss: 1.091\n",
      "Training with hidden dim: 3\n",
      "Epoch: 1/25, Step 40, Train loss: 0.063 Train reconstruction loss: 0.025 Train covariance loss: 3.791\n",
      "Epoch: 1/25, Step 80, Train loss: 0.057 Train reconstruction loss: 0.022 Train covariance loss: 3.580\n",
      "Epoch: 1/25, Step 120, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.830\n",
      "Epoch: 1/25, Step 160, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.830\n",
      "Epoch: 1/25, Step 200, Train loss: 0.061 Train reconstruction loss: 0.020 Train covariance loss: 4.105\n",
      "Epoch: 1/25, Step 240, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.750\n",
      "Epoch: 1/25, Step 280, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.824\n",
      "Epoch: 1/25, Step 320, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.669\n",
      "Epoch: 1/25, Step 360, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.944\n",
      "Epoch: 1/25, Step 400, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.737\n",
      "Epoch: 1/25, Step 440, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.797\n",
      "Epoch: 1/25, Step 480, Train loss: 0.061 Train reconstruction loss: 0.020 Train covariance loss: 4.076\n",
      "Test loss decreased (inf --> 0.056292).  Saving model ...\n",
      "Epoch 1/25,\n",
      "Train Loss: 0.059 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.056 Test reconstruction loss: 0.019 Test covariance loss: 3.685\n",
      "Epoch: 2/25, Step 520, Train loss: 0.060 Train reconstruction loss: 0.020 Train covariance loss: 3.968\n",
      "Epoch: 2/25, Step 560, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.727\n",
      "Epoch: 2/25, Step 600, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.869\n",
      "Epoch: 2/25, Step 640, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.821\n",
      "Epoch: 2/25, Step 680, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.894\n",
      "Epoch: 2/25, Step 720, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.809\n",
      "Epoch: 2/25, Step 760, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.910\n",
      "Epoch: 2/25, Step 800, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.839\n",
      "Epoch: 2/25, Step 840, Train loss: 0.060 Train reconstruction loss: 0.020 Train covariance loss: 4.082\n",
      "Epoch: 2/25, Step 880, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.663\n",
      "Epoch: 2/25, Step 920, Train loss: 0.056 Train reconstruction loss: 0.020 Train covariance loss: 3.534\n",
      "Epoch: 2/25, Step 960, Train loss: 0.060 Train reconstruction loss: 0.020 Train covariance loss: 3.967\n",
      "Test loss decreased (0.056292 --> 0.054270).  Saving model ...\n",
      "Epoch 2/25,\n",
      "Train Loss: 0.058 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.054 Test reconstruction loss: 0.019 Test covariance loss: 3.493\n",
      "Epoch: 3/25, Step 1000, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.784\n",
      "Epoch: 3/25, Step 1040, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.683\n",
      "Epoch: 3/25, Step 1080, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.846\n",
      "Epoch: 3/25, Step 1120, Train loss: 0.060 Train reconstruction loss: 0.020 Train covariance loss: 3.996\n",
      "Epoch: 3/25, Step 1160, Train loss: 0.061 Train reconstruction loss: 0.020 Train covariance loss: 4.075\n",
      "Epoch: 3/25, Step 1200, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.762\n",
      "Epoch: 3/25, Step 1240, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.784\n",
      "Epoch: 3/25, Step 1280, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.731\n",
      "Epoch: 3/25, Step 1320, Train loss: 0.060 Train reconstruction loss: 0.020 Train covariance loss: 3.973\n",
      "Epoch: 3/25, Step 1360, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.863\n",
      "Epoch: 3/25, Step 1400, Train loss: 0.056 Train reconstruction loss: 0.020 Train covariance loss: 3.665\n",
      "Epoch: 3/25, Step 1440, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.774\n",
      "Epoch 3/25,\n",
      "Train Loss: 0.058 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.057 Test reconstruction loss: 0.019 Test covariance loss: 3.776\n",
      "Epoch: 4/25, Step 1480, Train loss: 0.060 Train reconstruction loss: 0.020 Train covariance loss: 4.006\n",
      "Epoch: 4/25, Step 1520, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.880\n",
      "Epoch: 4/25, Step 1560, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.691\n",
      "Epoch: 4/25, Step 1600, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.901\n",
      "Epoch: 4/25, Step 1640, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.851\n",
      "Epoch: 4/25, Step 1680, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.732\n",
      "Epoch: 4/25, Step 1720, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.810\n",
      "Epoch: 4/25, Step 1760, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.893\n",
      "Epoch: 4/25, Step 1800, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.843\n",
      "Epoch: 4/25, Step 1840, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.790\n",
      "Epoch: 4/25, Step 1880, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.789\n",
      "Epoch: 4/25, Step 1920, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.827\n",
      "Epoch 4/25,\n",
      "Train Loss: 0.058 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.057 Test reconstruction loss: 0.019 Test covariance loss: 3.727\n",
      "Epoch: 5/25, Step 1960, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.745\n",
      "Epoch: 5/25, Step 2000, Train loss: 0.056 Train reconstruction loss: 0.020 Train covariance loss: 3.609\n",
      "Epoch: 5/25, Step 2040, Train loss: 0.060 Train reconstruction loss: 0.020 Train covariance loss: 4.081\n",
      "Epoch: 5/25, Step 2080, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.917\n",
      "Epoch: 5/25, Step 2120, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.879\n",
      "Epoch: 5/25, Step 2160, Train loss: 0.059 Train reconstruction loss: 0.019 Train covariance loss: 3.987\n",
      "Epoch: 5/25, Step 2200, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.840\n",
      "Epoch: 5/25, Step 2240, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.784\n",
      "Epoch: 5/25, Step 2280, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.724\n",
      "Epoch: 5/25, Step 2320, Train loss: 0.056 Train reconstruction loss: 0.020 Train covariance loss: 3.638\n",
      "Epoch: 5/25, Step 2360, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.910\n",
      "Epoch: 5/25, Step 2400, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.804\n",
      "Epoch 5/25,\n",
      "Train Loss: 0.058 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.054 Test reconstruction loss: 0.019 Test covariance loss: 3.527\n",
      "Epoch: 6/25, Step 2440, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.720\n",
      "Epoch: 6/25, Step 2480, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.829\n",
      "Epoch: 6/25, Step 2520, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.915\n",
      "Epoch: 6/25, Step 2560, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.858\n",
      "Epoch: 6/25, Step 2600, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.915\n",
      "Epoch: 6/25, Step 2640, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.705\n",
      "Epoch: 6/25, Step 2680, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.758\n",
      "Epoch: 6/25, Step 2720, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.771\n",
      "Epoch: 6/25, Step 2760, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.833\n",
      "Epoch: 6/25, Step 2800, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.974\n",
      "Epoch: 6/25, Step 2840, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.738\n",
      "Epoch: 6/25, Step 2880, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.841\n",
      "Epoch 6/25,\n",
      "Train Loss: 0.058 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.055 Test reconstruction loss: 0.019 Test covariance loss: 3.599\n",
      "Epoch: 7/25, Step 2920, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.838\n",
      "Epoch: 7/25, Step 2960, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.852\n",
      "Epoch: 7/25, Step 3000, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.717\n",
      "Epoch: 7/25, Step 3040, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.923\n",
      "Epoch: 7/25, Step 3080, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.765\n",
      "Epoch: 7/25, Step 3120, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.819\n",
      "Epoch: 7/25, Step 3160, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.871\n",
      "Epoch: 7/25, Step 3200, Train loss: 0.056 Train reconstruction loss: 0.020 Train covariance loss: 3.673\n",
      "Epoch: 7/25, Step 3240, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.870\n",
      "Epoch: 7/25, Step 3280, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.880\n",
      "Epoch: 7/25, Step 3320, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.769\n",
      "Epoch: 7/25, Step 3360, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.918\n",
      "Epoch 7/25,\n",
      "Train Loss: 0.058 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.057 Test reconstruction loss: 0.019 Test covariance loss: 3.781\n",
      "Epoch: 8/25, Step 3400, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.828\n",
      "Epoch: 8/25, Step 3440, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.765\n",
      "Epoch: 8/25, Step 3480, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.795\n",
      "Epoch: 8/25, Step 3520, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.839\n",
      "Epoch: 8/25, Step 3560, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.869\n",
      "Epoch: 8/25, Step 3600, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.742\n",
      "Epoch: 8/25, Step 3640, Train loss: 0.060 Train reconstruction loss: 0.020 Train covariance loss: 4.028\n",
      "Epoch: 8/25, Step 3680, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.711\n",
      "Epoch: 8/25, Step 3720, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.797\n",
      "Epoch: 8/25, Step 3760, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.785\n",
      "Epoch: 8/25, Step 3800, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.907\n",
      "Epoch: 8/25, Step 3840, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.875\n",
      "Test loss decreased (0.054270 --> 0.053687).  Saving model ...\n",
      "Epoch 8/25,\n",
      "Train Loss: 0.058 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.054 Test reconstruction loss: 0.019 Test covariance loss: 3.457\n",
      "Epoch: 9/25, Step 3880, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.812\n",
      "Epoch: 9/25, Step 3920, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.841\n",
      "Epoch: 9/25, Step 3960, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.882\n",
      "Epoch: 9/25, Step 4000, Train loss: 0.056 Train reconstruction loss: 0.020 Train covariance loss: 3.602\n",
      "Epoch: 9/25, Step 4040, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.662\n",
      "Epoch: 9/25, Step 4080, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.873\n",
      "Epoch: 9/25, Step 4120, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.909\n",
      "Epoch: 9/25, Step 4160, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.795\n",
      "Epoch: 9/25, Step 4200, Train loss: 0.059 Train reconstruction loss: 0.019 Train covariance loss: 3.992\n",
      "Epoch: 9/25, Step 4240, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.770\n",
      "Epoch: 9/25, Step 4280, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.904\n",
      "Epoch: 9/25, Step 4320, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.858\n",
      "Test loss decreased (0.053687 --> 0.052817).  Saving model ...\n",
      "Epoch 9/25,\n",
      "Train Loss: 0.058 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.053 Test reconstruction loss: 0.019 Test covariance loss: 3.371\n",
      "Epoch: 10/25, Step 4360, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.907\n",
      "Epoch: 10/25, Step 4400, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.756\n",
      "Epoch: 10/25, Step 4440, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.784\n",
      "Epoch: 10/25, Step 4480, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.898\n",
      "Epoch: 10/25, Step 4520, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.757\n",
      "Epoch: 10/25, Step 4560, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.829\n",
      "Epoch: 10/25, Step 4600, Train loss: 0.060 Train reconstruction loss: 0.020 Train covariance loss: 4.009\n",
      "Epoch: 10/25, Step 4640, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.821\n",
      "Epoch: 10/25, Step 4680, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.827\n",
      "Epoch: 10/25, Step 4720, Train loss: 0.060 Train reconstruction loss: 0.019 Train covariance loss: 4.017\n",
      "Epoch: 10/25, Step 4760, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.778\n",
      "Epoch: 10/25, Step 4800, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.809\n",
      "Epoch 10/25,\n",
      "Train Loss: 0.058 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.054 Test reconstruction loss: 0.019 Test covariance loss: 3.514\n",
      "Epoch: 11/25, Step 4840, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.764\n",
      "Epoch: 11/25, Step 4880, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.959\n",
      "Epoch: 11/25, Step 4920, Train loss: 0.059 Train reconstruction loss: 0.019 Train covariance loss: 3.921\n",
      "Epoch: 11/25, Step 4960, Train loss: 0.060 Train reconstruction loss: 0.020 Train covariance loss: 4.001\n",
      "Epoch: 11/25, Step 5000, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.723\n",
      "Epoch: 11/25, Step 5040, Train loss: 0.060 Train reconstruction loss: 0.020 Train covariance loss: 4.013\n",
      "Epoch: 11/25, Step 5080, Train loss: 0.056 Train reconstruction loss: 0.020 Train covariance loss: 3.606\n",
      "Epoch: 11/25, Step 5120, Train loss: 0.056 Train reconstruction loss: 0.019 Train covariance loss: 3.680\n",
      "Epoch: 11/25, Step 5160, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.916\n",
      "Epoch: 11/25, Step 5200, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.828\n",
      "Epoch: 11/25, Step 5240, Train loss: 0.056 Train reconstruction loss: 0.019 Train covariance loss: 3.702\n",
      "Epoch: 11/25, Step 5280, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.799\n",
      "Epoch 11/25,\n",
      "Train Loss: 0.058 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.053 Test reconstruction loss: 0.019 Test covariance loss: 3.434\n",
      "Epoch: 12/25, Step 5320, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.914\n",
      "Epoch: 12/25, Step 5360, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.922\n",
      "Epoch: 12/25, Step 5400, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.904\n",
      "Epoch: 12/25, Step 5440, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.691\n",
      "Epoch: 12/25, Step 5480, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.803\n",
      "Epoch: 12/25, Step 5520, Train loss: 0.056 Train reconstruction loss: 0.019 Train covariance loss: 3.703\n",
      "Epoch: 12/25, Step 5560, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.832\n",
      "Epoch: 12/25, Step 5600, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.765\n",
      "Epoch: 12/25, Step 5640, Train loss: 0.060 Train reconstruction loss: 0.019 Train covariance loss: 4.049\n",
      "Epoch: 12/25, Step 5680, Train loss: 0.061 Train reconstruction loss: 0.020 Train covariance loss: 4.098\n",
      "Epoch: 12/25, Step 5720, Train loss: 0.055 Train reconstruction loss: 0.019 Train covariance loss: 3.556\n",
      "Epoch: 12/25, Step 5760, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.782\n",
      "Test loss decreased (0.052817 --> 0.050924).  Saving model ...\n",
      "Epoch 12/25,\n",
      "Train Loss: 0.058 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.051 Test reconstruction loss: 0.019 Test covariance loss: 3.188\n",
      "Epoch: 13/25, Step 5800, Train loss: 0.059 Train reconstruction loss: 0.019 Train covariance loss: 3.933\n",
      "Epoch: 13/25, Step 5840, Train loss: 0.059 Train reconstruction loss: 0.019 Train covariance loss: 3.918\n",
      "Epoch: 13/25, Step 5880, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.869\n",
      "Epoch: 13/25, Step 5920, Train loss: 0.059 Train reconstruction loss: 0.019 Train covariance loss: 3.984\n",
      "Epoch: 13/25, Step 5960, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.742\n",
      "Epoch: 13/25, Step 6000, Train loss: 0.056 Train reconstruction loss: 0.020 Train covariance loss: 3.607\n",
      "Epoch: 13/25, Step 6040, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.853\n",
      "Epoch: 13/25, Step 6080, Train loss: 0.056 Train reconstruction loss: 0.019 Train covariance loss: 3.694\n",
      "Epoch: 13/25, Step 6120, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.809\n",
      "Epoch: 13/25, Step 6160, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.811\n",
      "Epoch: 13/25, Step 6200, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.865\n",
      "Epoch: 13/25, Step 6240, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.828\n",
      "Epoch 13/25,\n",
      "Train Loss: 0.058 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.057 Test reconstruction loss: 0.019 Test covariance loss: 3.816\n",
      "Epoch: 14/25, Step 6280, Train loss: 0.059 Train reconstruction loss: 0.019 Train covariance loss: 3.916\n",
      "Epoch: 14/25, Step 6320, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.852\n",
      "Epoch: 14/25, Step 6360, Train loss: 0.056 Train reconstruction loss: 0.020 Train covariance loss: 3.652\n",
      "Epoch: 14/25, Step 6400, Train loss: 0.059 Train reconstruction loss: 0.019 Train covariance loss: 3.909\n",
      "Epoch: 14/25, Step 6440, Train loss: 0.059 Train reconstruction loss: 0.019 Train covariance loss: 3.957\n",
      "Epoch: 14/25, Step 6480, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.768\n",
      "Epoch: 14/25, Step 6520, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.821\n",
      "Epoch: 14/25, Step 6560, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.927\n",
      "Epoch: 14/25, Step 6600, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.805\n",
      "Epoch: 14/25, Step 6640, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.691\n",
      "Epoch: 14/25, Step 6680, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.707\n",
      "Epoch: 14/25, Step 6720, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.836\n",
      "Epoch 14/25,\n",
      "Train Loss: 0.058 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.054 Test reconstruction loss: 0.019 Test covariance loss: 3.487\n",
      "Epoch: 15/25, Step 6760, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.791\n",
      "Epoch: 15/25, Step 6800, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.765\n",
      "Epoch: 15/25, Step 6840, Train loss: 0.059 Train reconstruction loss: 0.019 Train covariance loss: 3.952\n",
      "Epoch: 15/25, Step 6880, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.755\n",
      "Epoch: 15/25, Step 6920, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.820\n",
      "Epoch: 15/25, Step 6960, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.821\n",
      "Epoch: 15/25, Step 7000, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.676\n",
      "Epoch: 15/25, Step 7040, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.869\n",
      "Epoch: 15/25, Step 7080, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.846\n",
      "Epoch: 15/25, Step 7120, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.942\n",
      "Epoch: 15/25, Step 7160, Train loss: 0.055 Train reconstruction loss: 0.019 Train covariance loss: 3.617\n",
      "Epoch: 15/25, Step 7200, Train loss: 0.060 Train reconstruction loss: 0.019 Train covariance loss: 4.042\n",
      "Epoch 15/25,\n",
      "Train Loss: 0.058 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.056 Test reconstruction loss: 0.019 Test covariance loss: 3.697\n",
      "Epoch: 16/25, Step 7240, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.745\n",
      "Epoch: 16/25, Step 7280, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.798\n",
      "Epoch: 16/25, Step 7320, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.794\n",
      "Epoch: 16/25, Step 7360, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.685\n",
      "Epoch: 16/25, Step 7400, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.879\n",
      "Epoch: 16/25, Step 7440, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.936\n",
      "Epoch: 16/25, Step 7480, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.709\n",
      "Epoch: 16/25, Step 7520, Train loss: 0.056 Train reconstruction loss: 0.019 Train covariance loss: 3.736\n",
      "Epoch: 16/25, Step 7560, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.814\n",
      "Epoch: 16/25, Step 7600, Train loss: 0.061 Train reconstruction loss: 0.020 Train covariance loss: 4.143\n",
      "Epoch: 16/25, Step 7640, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.752\n",
      "Epoch: 16/25, Step 7680, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.764\n",
      "Epoch 16/25,\n",
      "Train Loss: 0.058 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.054 Test reconstruction loss: 0.019 Test covariance loss: 3.483\n",
      "Epoch: 17/25, Step 7720, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.777\n",
      "Epoch: 17/25, Step 7760, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.808\n",
      "Epoch: 17/25, Step 7800, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.735\n",
      "Epoch: 17/25, Step 7840, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.877\n",
      "Epoch: 17/25, Step 7880, Train loss: 0.060 Train reconstruction loss: 0.020 Train covariance loss: 4.012\n",
      "Epoch: 17/25, Step 7920, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.782\n",
      "Epoch: 17/25, Step 7960, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.885\n",
      "Epoch: 17/25, Step 8000, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.944\n",
      "Epoch: 17/25, Step 8040, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.789\n",
      "Epoch: 17/25, Step 8080, Train loss: 0.056 Train reconstruction loss: 0.020 Train covariance loss: 3.570\n",
      "Epoch: 17/25, Step 8120, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.751\n",
      "Epoch: 17/25, Step 8160, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.907\n",
      "Epoch 17/25,\n",
      "Train Loss: 0.058 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.055 Test reconstruction loss: 0.019 Test covariance loss: 3.580\n",
      "Epoch: 18/25, Step 8200, Train loss: 0.056 Train reconstruction loss: 0.019 Train covariance loss: 3.640\n",
      "Epoch: 18/25, Step 8240, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.889\n",
      "Epoch: 18/25, Step 8280, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.779\n",
      "Epoch: 18/25, Step 8320, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.749\n",
      "Epoch: 18/25, Step 8360, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.868\n",
      "Epoch: 18/25, Step 8400, Train loss: 0.059 Train reconstruction loss: 0.019 Train covariance loss: 3.958\n",
      "Epoch: 18/25, Step 8440, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.818\n",
      "Epoch: 18/25, Step 8480, Train loss: 0.055 Train reconstruction loss: 0.020 Train covariance loss: 3.568\n",
      "Epoch: 18/25, Step 8520, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.922\n",
      "Epoch: 18/25, Step 8560, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.894\n",
      "Epoch: 18/25, Step 8600, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.981\n",
      "Epoch: 18/25, Step 8640, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.897\n",
      "Epoch 18/25,\n",
      "Train Loss: 0.058 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.056 Test reconstruction loss: 0.019 Test covariance loss: 3.652\n",
      "Epoch: 19/25, Step 8680, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.895\n",
      "Epoch: 19/25, Step 8720, Train loss: 0.056 Train reconstruction loss: 0.019 Train covariance loss: 3.624\n",
      "Epoch: 19/25, Step 8760, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.862\n",
      "Epoch: 19/25, Step 8800, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.847\n",
      "Epoch: 19/25, Step 8840, Train loss: 0.061 Train reconstruction loss: 0.020 Train covariance loss: 4.106\n",
      "Epoch: 19/25, Step 8880, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.878\n",
      "Epoch: 19/25, Step 8920, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.740\n",
      "Epoch: 19/25, Step 8960, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.831\n",
      "Epoch: 19/25, Step 9000, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.841\n",
      "Epoch: 19/25, Step 9040, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.772\n",
      "Epoch: 19/25, Step 9080, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.957\n",
      "Epoch: 19/25, Step 9120, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.774\n",
      "Epoch 19/25,\n",
      "Train Loss: 0.058 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.056 Test reconstruction loss: 0.019 Test covariance loss: 3.704\n",
      "Epoch: 20/25, Step 9160, Train loss: 0.060 Train reconstruction loss: 0.019 Train covariance loss: 4.017\n",
      "Epoch: 20/25, Step 9200, Train loss: 0.061 Train reconstruction loss: 0.020 Train covariance loss: 4.147\n",
      "Epoch: 20/25, Step 9240, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.825\n",
      "Epoch: 20/25, Step 9280, Train loss: 0.056 Train reconstruction loss: 0.020 Train covariance loss: 3.642\n",
      "Epoch: 20/25, Step 9320, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.756\n",
      "Epoch: 20/25, Step 9360, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.748\n",
      "Epoch: 20/25, Step 9400, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.846\n",
      "Epoch: 20/25, Step 9440, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.773\n",
      "Epoch: 20/25, Step 9480, Train loss: 0.060 Train reconstruction loss: 0.020 Train covariance loss: 3.995\n",
      "Epoch: 20/25, Step 9520, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.751\n",
      "Epoch: 20/25, Step 9560, Train loss: 0.056 Train reconstruction loss: 0.019 Train covariance loss: 3.678\n",
      "Epoch: 20/25, Step 9600, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.860\n",
      "Epoch 20/25,\n",
      "Train Loss: 0.058 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.054 Test reconstruction loss: 0.019 Test covariance loss: 3.542\n",
      "Epoch: 21/25, Step 9640, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.886\n",
      "Epoch: 21/25, Step 9680, Train loss: 0.060 Train reconstruction loss: 0.019 Train covariance loss: 4.104\n",
      "Epoch: 21/25, Step 9720, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.859\n",
      "Epoch: 21/25, Step 9760, Train loss: 0.060 Train reconstruction loss: 0.020 Train covariance loss: 3.995\n",
      "Epoch: 21/25, Step 9800, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.824\n",
      "Epoch: 21/25, Step 9840, Train loss: 0.056 Train reconstruction loss: 0.019 Train covariance loss: 3.644\n",
      "Epoch: 21/25, Step 9880, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.880\n",
      "Epoch: 21/25, Step 9920, Train loss: 0.056 Train reconstruction loss: 0.019 Train covariance loss: 3.685\n",
      "Epoch: 21/25, Step 9960, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.731\n",
      "Epoch: 21/25, Step 10000, Train loss: 0.056 Train reconstruction loss: 0.020 Train covariance loss: 3.620\n",
      "Epoch: 21/25, Step 10040, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.828\n",
      "Epoch: 21/25, Step 10080, Train loss: 0.059 Train reconstruction loss: 0.019 Train covariance loss: 3.985\n",
      "Epoch 21/25,\n",
      "Train Loss: 0.058 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.057 Test reconstruction loss: 0.019 Test covariance loss: 3.765\n",
      "Epoch: 22/25, Step 10120, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.799\n",
      "Epoch: 22/25, Step 10160, Train loss: 0.059 Train reconstruction loss: 0.019 Train covariance loss: 4.024\n",
      "Epoch: 22/25, Step 10200, Train loss: 0.056 Train reconstruction loss: 0.019 Train covariance loss: 3.705\n",
      "Epoch: 22/25, Step 10240, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.855\n",
      "Epoch: 22/25, Step 10280, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.969\n",
      "Epoch: 22/25, Step 10320, Train loss: 0.059 Train reconstruction loss: 0.019 Train covariance loss: 3.966\n",
      "Epoch: 22/25, Step 10360, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.873\n",
      "Epoch: 22/25, Step 10400, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.819\n",
      "Epoch: 22/25, Step 10440, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.769\n",
      "Epoch: 22/25, Step 10480, Train loss: 0.056 Train reconstruction loss: 0.019 Train covariance loss: 3.692\n",
      "Epoch: 22/25, Step 10520, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.957\n",
      "Epoch: 22/25, Step 10560, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.729\n",
      "Epoch 22/25,\n",
      "Train Loss: 0.058 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.055 Test reconstruction loss: 0.019 Test covariance loss: 3.556\n",
      "Epoch: 23/25, Step 10600, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.934\n",
      "Epoch: 23/25, Step 10640, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.922\n",
      "Epoch: 23/25, Step 10680, Train loss: 0.056 Train reconstruction loss: 0.019 Train covariance loss: 3.703\n",
      "Epoch: 23/25, Step 10720, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.825\n",
      "Epoch: 23/25, Step 10760, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.810\n",
      "Epoch: 23/25, Step 10800, Train loss: 0.059 Train reconstruction loss: 0.019 Train covariance loss: 3.980\n",
      "Epoch: 23/25, Step 10840, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.905\n",
      "Epoch: 23/25, Step 10880, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.819\n",
      "Epoch: 23/25, Step 10920, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.728\n",
      "Epoch: 23/25, Step 10960, Train loss: 0.056 Train reconstruction loss: 0.020 Train covariance loss: 3.637\n",
      "Epoch: 23/25, Step 11000, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.730\n",
      "Epoch: 23/25, Step 11040, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.894\n",
      "Epoch 23/25,\n",
      "Train Loss: 0.058 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.056 Test reconstruction loss: 0.019 Test covariance loss: 3.702\n",
      "Epoch: 24/25, Step 11080, Train loss: 0.056 Train reconstruction loss: 0.019 Train covariance loss: 3.723\n",
      "Epoch: 24/25, Step 11120, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.766\n",
      "Epoch: 24/25, Step 11160, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.798\n",
      "Epoch: 24/25, Step 11200, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.908\n",
      "Epoch: 24/25, Step 11240, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.728\n",
      "Epoch: 24/25, Step 11280, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.905\n",
      "Epoch: 24/25, Step 11320, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.862\n",
      "Epoch: 24/25, Step 11360, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.715\n",
      "Epoch: 24/25, Step 11400, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.739\n",
      "Epoch: 24/25, Step 11440, Train loss: 0.056 Train reconstruction loss: 0.019 Train covariance loss: 3.705\n",
      "Epoch: 24/25, Step 11480, Train loss: 0.060 Train reconstruction loss: 0.019 Train covariance loss: 4.049\n",
      "Epoch: 24/25, Step 11520, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.806\n",
      "Epoch 24/25,\n",
      "Train Loss: 0.058 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.054 Test reconstruction loss: 0.019 Test covariance loss: 3.464\n",
      "Epoch: 25/25, Step 11560, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.868\n",
      "Epoch: 25/25, Step 11600, Train loss: 0.060 Train reconstruction loss: 0.020 Train covariance loss: 4.079\n",
      "Epoch: 25/25, Step 11640, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.875\n",
      "Epoch: 25/25, Step 11680, Train loss: 0.059 Train reconstruction loss: 0.020 Train covariance loss: 3.896\n",
      "Epoch: 25/25, Step 11720, Train loss: 0.058 Train reconstruction loss: 0.020 Train covariance loss: 3.826\n",
      "Epoch: 25/25, Step 11760, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.856\n",
      "Epoch: 25/25, Step 11800, Train loss: 0.058 Train reconstruction loss: 0.019 Train covariance loss: 3.850\n",
      "Epoch: 25/25, Step 11840, Train loss: 0.055 Train reconstruction loss: 0.019 Train covariance loss: 3.580\n",
      "Epoch: 25/25, Step 11880, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.740\n",
      "Epoch: 25/25, Step 11920, Train loss: 0.059 Train reconstruction loss: 0.019 Train covariance loss: 3.939\n",
      "Epoch: 25/25, Step 11960, Train loss: 0.056 Train reconstruction loss: 0.020 Train covariance loss: 3.631\n",
      "Epoch: 25/25, Step 12000, Train loss: 0.057 Train reconstruction loss: 0.019 Train covariance loss: 3.819\n",
      "Epoch 25/25,\n",
      "Train Loss: 0.058 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.054 Test reconstruction loss: 0.019 Test covariance loss: 3.522\n",
      "Training with hidden dim: 4\n",
      "Epoch: 1/25, Step 40, Train loss: 0.098 Train reconstruction loss: 0.026 Train covariance loss: 7.229\n",
      "Epoch: 1/25, Step 80, Train loss: 0.092 Train reconstruction loss: 0.021 Train covariance loss: 7.160\n",
      "Epoch: 1/25, Step 120, Train loss: 0.091 Train reconstruction loss: 0.020 Train covariance loss: 7.119\n",
      "Epoch: 1/25, Step 160, Train loss: 0.094 Train reconstruction loss: 0.020 Train covariance loss: 7.391\n",
      "Epoch: 1/25, Step 200, Train loss: 0.090 Train reconstruction loss: 0.020 Train covariance loss: 7.006\n",
      "Epoch: 1/25, Step 240, Train loss: 0.091 Train reconstruction loss: 0.020 Train covariance loss: 7.110\n",
      "Epoch: 1/25, Step 280, Train loss: 0.094 Train reconstruction loss: 0.020 Train covariance loss: 7.377\n",
      "Epoch: 1/25, Step 320, Train loss: 0.091 Train reconstruction loss: 0.020 Train covariance loss: 7.069\n",
      "Epoch: 1/25, Step 360, Train loss: 0.092 Train reconstruction loss: 0.020 Train covariance loss: 7.178\n",
      "Epoch: 1/25, Step 400, Train loss: 0.093 Train reconstruction loss: 0.020 Train covariance loss: 7.332\n",
      "Epoch: 1/25, Step 440, Train loss: 0.089 Train reconstruction loss: 0.020 Train covariance loss: 6.964\n",
      "Epoch: 1/25, Step 480, Train loss: 0.094 Train reconstruction loss: 0.019 Train covariance loss: 7.422\n",
      "Test loss decreased (inf --> 0.094104).  Saving model ...\n",
      "Epoch 1/25,\n",
      "Train Loss: 0.093 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.094 Test reconstruction loss: 0.020 Test covariance loss: 7.453\n",
      "Epoch: 2/25, Step 520, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.055\n",
      "Epoch: 2/25, Step 560, Train loss: 0.089 Train reconstruction loss: 0.020 Train covariance loss: 6.917\n",
      "Epoch: 2/25, Step 600, Train loss: 0.090 Train reconstruction loss: 0.020 Train covariance loss: 7.024\n",
      "Epoch: 2/25, Step 640, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.175\n",
      "Epoch: 2/25, Step 680, Train loss: 0.091 Train reconstruction loss: 0.020 Train covariance loss: 7.087\n",
      "Epoch: 2/25, Step 720, Train loss: 0.091 Train reconstruction loss: 0.020 Train covariance loss: 7.090\n",
      "Epoch: 2/25, Step 760, Train loss: 0.090 Train reconstruction loss: 0.020 Train covariance loss: 7.064\n",
      "Epoch: 2/25, Step 800, Train loss: 0.091 Train reconstruction loss: 0.020 Train covariance loss: 7.102\n",
      "Epoch: 2/25, Step 840, Train loss: 0.094 Train reconstruction loss: 0.020 Train covariance loss: 7.454\n",
      "Epoch: 2/25, Step 880, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.387\n",
      "Epoch: 2/25, Step 920, Train loss: 0.092 Train reconstruction loss: 0.020 Train covariance loss: 7.215\n",
      "Epoch: 2/25, Step 960, Train loss: 0.094 Train reconstruction loss: 0.020 Train covariance loss: 7.462\n",
      "Test loss decreased (0.094104 --> 0.088233).  Saving model ...\n",
      "Epoch 2/25,\n",
      "Train Loss: 0.091 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.088 Test reconstruction loss: 0.019 Test covariance loss: 6.906\n",
      "Epoch: 3/25, Step 1000, Train loss: 0.091 Train reconstruction loss: 0.020 Train covariance loss: 7.181\n",
      "Epoch: 3/25, Step 1040, Train loss: 0.090 Train reconstruction loss: 0.020 Train covariance loss: 7.064\n",
      "Epoch: 3/25, Step 1080, Train loss: 0.092 Train reconstruction loss: 0.020 Train covariance loss: 7.144\n",
      "Epoch: 3/25, Step 1120, Train loss: 0.090 Train reconstruction loss: 0.020 Train covariance loss: 6.996\n",
      "Epoch: 3/25, Step 1160, Train loss: 0.091 Train reconstruction loss: 0.020 Train covariance loss: 7.132\n",
      "Epoch: 3/25, Step 1200, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 6.916\n",
      "Epoch: 3/25, Step 1240, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.103\n",
      "Epoch: 3/25, Step 1280, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.063\n",
      "Epoch: 3/25, Step 1320, Train loss: 0.094 Train reconstruction loss: 0.019 Train covariance loss: 7.498\n",
      "Epoch: 3/25, Step 1360, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.094\n",
      "Epoch: 3/25, Step 1400, Train loss: 0.094 Train reconstruction loss: 0.019 Train covariance loss: 7.415\n",
      "Epoch: 3/25, Step 1440, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.099\n",
      "Epoch 3/25,\n",
      "Train Loss: 0.091 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.098 Test reconstruction loss: 0.019 Test covariance loss: 7.846\n",
      "Epoch: 4/25, Step 1480, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 6.979\n",
      "Epoch: 4/25, Step 1520, Train loss: 0.090 Train reconstruction loss: 0.020 Train covariance loss: 7.025\n",
      "Epoch: 4/25, Step 1560, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.310\n",
      "Epoch: 4/25, Step 1600, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.330\n",
      "Epoch: 4/25, Step 1640, Train loss: 0.091 Train reconstruction loss: 0.020 Train covariance loss: 7.145\n",
      "Epoch: 4/25, Step 1680, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.358\n",
      "Epoch: 4/25, Step 1720, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.148\n",
      "Epoch: 4/25, Step 1760, Train loss: 0.094 Train reconstruction loss: 0.019 Train covariance loss: 7.438\n",
      "Epoch: 4/25, Step 1800, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.048\n",
      "Epoch: 4/25, Step 1840, Train loss: 0.087 Train reconstruction loss: 0.019 Train covariance loss: 6.768\n",
      "Epoch: 4/25, Step 1880, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.132\n",
      "Epoch: 4/25, Step 1920, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.154\n",
      "Test loss decreased (0.088233 --> 0.084684).  Saving model ...\n",
      "Epoch 4/25,\n",
      "Train Loss: 0.091 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.085 Test reconstruction loss: 0.019 Test covariance loss: 6.572\n",
      "Epoch: 5/25, Step 1960, Train loss: 0.088 Train reconstruction loss: 0.020 Train covariance loss: 6.816\n",
      "Epoch: 5/25, Step 2000, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.390\n",
      "Epoch: 5/25, Step 2040, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.353\n",
      "Epoch: 5/25, Step 2080, Train loss: 0.087 Train reconstruction loss: 0.019 Train covariance loss: 6.845\n",
      "Epoch: 5/25, Step 2120, Train loss: 0.090 Train reconstruction loss: 0.020 Train covariance loss: 7.087\n",
      "Epoch: 5/25, Step 2160, Train loss: 0.095 Train reconstruction loss: 0.020 Train covariance loss: 7.490\n",
      "Epoch: 5/25, Step 2200, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 6.973\n",
      "Epoch: 5/25, Step 2240, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.212\n",
      "Epoch: 5/25, Step 2280, Train loss: 0.095 Train reconstruction loss: 0.019 Train covariance loss: 7.534\n",
      "Epoch: 5/25, Step 2320, Train loss: 0.091 Train reconstruction loss: 0.020 Train covariance loss: 7.181\n",
      "Epoch: 5/25, Step 2360, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.158\n",
      "Epoch: 5/25, Step 2400, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.150\n",
      "Epoch 5/25,\n",
      "Train Loss: 0.091 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.088 Test reconstruction loss: 0.019 Test covariance loss: 6.894\n",
      "Epoch: 6/25, Step 2440, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.239\n",
      "Epoch: 6/25, Step 2480, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 7.000\n",
      "Epoch: 6/25, Step 2520, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.187\n",
      "Epoch: 6/25, Step 2560, Train loss: 0.089 Train reconstruction loss: 0.020 Train covariance loss: 6.967\n",
      "Epoch: 6/25, Step 2600, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.246\n",
      "Epoch: 6/25, Step 2640, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.123\n",
      "Epoch: 6/25, Step 2680, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.163\n",
      "Epoch: 6/25, Step 2720, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.360\n",
      "Epoch: 6/25, Step 2760, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 7.025\n",
      "Epoch: 6/25, Step 2800, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.254\n",
      "Epoch: 6/25, Step 2840, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.382\n",
      "Epoch: 6/25, Step 2880, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.028\n",
      "Test loss decreased (0.084684 --> 0.083855).  Saving model ...\n",
      "Epoch 6/25,\n",
      "Train Loss: 0.091 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.084 Test reconstruction loss: 0.019 Test covariance loss: 6.498\n",
      "Epoch: 7/25, Step 2920, Train loss: 0.088 Train reconstruction loss: 0.019 Train covariance loss: 6.891\n",
      "Epoch: 7/25, Step 2960, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.318\n",
      "Epoch: 7/25, Step 3000, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.207\n",
      "Epoch: 7/25, Step 3040, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 6.985\n",
      "Epoch: 7/25, Step 3080, Train loss: 0.092 Train reconstruction loss: 0.020 Train covariance loss: 7.235\n",
      "Epoch: 7/25, Step 3120, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.407\n",
      "Epoch: 7/25, Step 3160, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.116\n",
      "Epoch: 7/25, Step 3200, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 6.942\n",
      "Epoch: 7/25, Step 3240, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.295\n",
      "Epoch: 7/25, Step 3280, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.094\n",
      "Epoch: 7/25, Step 3320, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.194\n",
      "Epoch: 7/25, Step 3360, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.411\n",
      "Epoch 7/25,\n",
      "Train Loss: 0.091 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.088 Test reconstruction loss: 0.019 Test covariance loss: 6.891\n",
      "Epoch: 8/25, Step 3400, Train loss: 0.087 Train reconstruction loss: 0.019 Train covariance loss: 6.796\n",
      "Epoch: 8/25, Step 3440, Train loss: 0.088 Train reconstruction loss: 0.019 Train covariance loss: 6.839\n",
      "Epoch: 8/25, Step 3480, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.330\n",
      "Epoch: 8/25, Step 3520, Train loss: 0.092 Train reconstruction loss: 0.020 Train covariance loss: 7.278\n",
      "Epoch: 8/25, Step 3560, Train loss: 0.088 Train reconstruction loss: 0.019 Train covariance loss: 6.856\n",
      "Epoch: 8/25, Step 3600, Train loss: 0.094 Train reconstruction loss: 0.020 Train covariance loss: 7.484\n",
      "Epoch: 8/25, Step 3640, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.164\n",
      "Epoch: 8/25, Step 3680, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.165\n",
      "Epoch: 8/25, Step 3720, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.151\n",
      "Epoch: 8/25, Step 3760, Train loss: 0.095 Train reconstruction loss: 0.019 Train covariance loss: 7.556\n",
      "Epoch: 8/25, Step 3800, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.248\n",
      "Epoch: 8/25, Step 3840, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.238\n",
      "Epoch 8/25,\n",
      "Train Loss: 0.091 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.091 Test reconstruction loss: 0.019 Test covariance loss: 7.183\n",
      "Epoch: 9/25, Step 3880, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.187\n",
      "Epoch: 9/25, Step 3920, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 6.987\n",
      "Epoch: 9/25, Step 3960, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 7.052\n",
      "Epoch: 9/25, Step 4000, Train loss: 0.090 Train reconstruction loss: 0.020 Train covariance loss: 7.060\n",
      "Epoch: 9/25, Step 4040, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 7.041\n",
      "Epoch: 9/25, Step 4080, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.248\n",
      "Epoch: 9/25, Step 4120, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 7.005\n",
      "Epoch: 9/25, Step 4160, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.190\n",
      "Epoch: 9/25, Step 4200, Train loss: 0.092 Train reconstruction loss: 0.020 Train covariance loss: 7.266\n",
      "Epoch: 9/25, Step 4240, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.067\n",
      "Epoch: 9/25, Step 4280, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.362\n",
      "Epoch: 9/25, Step 4320, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.218\n",
      "Test loss decreased (0.083855 --> 0.080030).  Saving model ...\n",
      "Epoch 9/25,\n",
      "Train Loss: 0.091 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.080 Test reconstruction loss: 0.019 Test covariance loss: 6.131\n",
      "Epoch: 10/25, Step 4360, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.257\n",
      "Epoch: 10/25, Step 4400, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.195\n",
      "Epoch: 10/25, Step 4440, Train loss: 0.095 Train reconstruction loss: 0.019 Train covariance loss: 7.632\n",
      "Epoch: 10/25, Step 4480, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.286\n",
      "Epoch: 10/25, Step 4520, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 7.015\n",
      "Epoch: 10/25, Step 4560, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.007\n",
      "Epoch: 10/25, Step 4600, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.197\n",
      "Epoch: 10/25, Step 4640, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.473\n",
      "Epoch: 10/25, Step 4680, Train loss: 0.094 Train reconstruction loss: 0.019 Train covariance loss: 7.410\n",
      "Epoch: 10/25, Step 4720, Train loss: 0.088 Train reconstruction loss: 0.019 Train covariance loss: 6.910\n",
      "Epoch: 10/25, Step 4760, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 7.017\n",
      "Epoch: 10/25, Step 4800, Train loss: 0.087 Train reconstruction loss: 0.019 Train covariance loss: 6.721\n",
      "Epoch 10/25,\n",
      "Train Loss: 0.091 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.086 Test reconstruction loss: 0.019 Test covariance loss: 6.725\n",
      "Epoch: 11/25, Step 4840, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 6.948\n",
      "Epoch: 11/25, Step 4880, Train loss: 0.088 Train reconstruction loss: 0.019 Train covariance loss: 6.905\n",
      "Epoch: 11/25, Step 4920, Train loss: 0.095 Train reconstruction loss: 0.019 Train covariance loss: 7.660\n",
      "Epoch: 11/25, Step 4960, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.094\n",
      "Epoch: 11/25, Step 5000, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.254\n",
      "Epoch: 11/25, Step 5040, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.082\n",
      "Epoch: 11/25, Step 5080, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.177\n",
      "Epoch: 11/25, Step 5120, Train loss: 0.087 Train reconstruction loss: 0.019 Train covariance loss: 6.778\n",
      "Epoch: 11/25, Step 5160, Train loss: 0.088 Train reconstruction loss: 0.019 Train covariance loss: 6.929\n",
      "Epoch: 11/25, Step 5200, Train loss: 0.094 Train reconstruction loss: 0.019 Train covariance loss: 7.464\n",
      "Epoch: 11/25, Step 5240, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.169\n",
      "Epoch: 11/25, Step 5280, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.351\n",
      "Epoch 11/25,\n",
      "Train Loss: 0.091 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.092 Test reconstruction loss: 0.019 Test covariance loss: 7.295\n",
      "Epoch: 12/25, Step 5320, Train loss: 0.088 Train reconstruction loss: 0.019 Train covariance loss: 6.905\n",
      "Epoch: 12/25, Step 5360, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.269\n",
      "Epoch: 12/25, Step 5400, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.201\n",
      "Epoch: 12/25, Step 5440, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 6.966\n",
      "Epoch: 12/25, Step 5480, Train loss: 0.095 Train reconstruction loss: 0.019 Train covariance loss: 7.538\n",
      "Epoch: 12/25, Step 5520, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.222\n",
      "Epoch: 12/25, Step 5560, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.336\n",
      "Epoch: 12/25, Step 5600, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.261\n",
      "Epoch: 12/25, Step 5640, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.143\n",
      "Epoch: 12/25, Step 5680, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 7.005\n",
      "Epoch: 12/25, Step 5720, Train loss: 0.088 Train reconstruction loss: 0.019 Train covariance loss: 6.836\n",
      "Epoch: 12/25, Step 5760, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 7.049\n",
      "Epoch 12/25,\n",
      "Train Loss: 0.091 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.087 Test reconstruction loss: 0.019 Test covariance loss: 6.860\n",
      "Epoch: 13/25, Step 5800, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.193\n",
      "Epoch: 13/25, Step 5840, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.079\n",
      "Epoch: 13/25, Step 5880, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.104\n",
      "Epoch: 13/25, Step 5920, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.164\n",
      "Epoch: 13/25, Step 5960, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.406\n",
      "Epoch: 13/25, Step 6000, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.268\n",
      "Epoch: 13/25, Step 6040, Train loss: 0.094 Train reconstruction loss: 0.019 Train covariance loss: 7.481\n",
      "Epoch: 13/25, Step 6080, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.162\n",
      "Epoch: 13/25, Step 6120, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.199\n",
      "Epoch: 13/25, Step 6160, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.151\n",
      "Epoch: 13/25, Step 6200, Train loss: 0.086 Train reconstruction loss: 0.019 Train covariance loss: 6.725\n",
      "Epoch: 13/25, Step 6240, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.241\n",
      "Epoch 13/25,\n",
      "Train Loss: 0.091 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.081 Test reconstruction loss: 0.019 Test covariance loss: 6.235\n",
      "Epoch: 14/25, Step 6280, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.280\n",
      "Epoch: 14/25, Step 6320, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.091\n",
      "Epoch: 14/25, Step 6360, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.124\n",
      "Epoch: 14/25, Step 6400, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.215\n",
      "Epoch: 14/25, Step 6440, Train loss: 0.094 Train reconstruction loss: 0.019 Train covariance loss: 7.447\n",
      "Epoch: 14/25, Step 6480, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.185\n",
      "Epoch: 14/25, Step 6520, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.213\n",
      "Epoch: 14/25, Step 6560, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.107\n",
      "Epoch: 14/25, Step 6600, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.188\n",
      "Epoch: 14/25, Step 6640, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.039\n",
      "Epoch: 14/25, Step 6680, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 7.014\n",
      "Epoch: 14/25, Step 6720, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.412\n",
      "Epoch 14/25,\n",
      "Train Loss: 0.091 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.081 Test reconstruction loss: 0.019 Test covariance loss: 6.221\n",
      "Epoch: 15/25, Step 6760, Train loss: 0.094 Train reconstruction loss: 0.019 Train covariance loss: 7.545\n",
      "Epoch: 15/25, Step 6800, Train loss: 0.087 Train reconstruction loss: 0.019 Train covariance loss: 6.833\n",
      "Epoch: 15/25, Step 6840, Train loss: 0.088 Train reconstruction loss: 0.019 Train covariance loss: 6.870\n",
      "Epoch: 15/25, Step 6880, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.240\n",
      "Epoch: 15/25, Step 6920, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.244\n",
      "Epoch: 15/25, Step 6960, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.139\n",
      "Epoch: 15/25, Step 7000, Train loss: 0.086 Train reconstruction loss: 0.019 Train covariance loss: 6.718\n",
      "Epoch: 15/25, Step 7040, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.038\n",
      "Epoch: 15/25, Step 7080, Train loss: 0.095 Train reconstruction loss: 0.019 Train covariance loss: 7.552\n",
      "Epoch: 15/25, Step 7120, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 7.000\n",
      "Epoch: 15/25, Step 7160, Train loss: 0.096 Train reconstruction loss: 0.019 Train covariance loss: 7.697\n",
      "Epoch: 15/25, Step 7200, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.310\n",
      "Epoch 15/25,\n",
      "Train Loss: 0.091 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.096 Test reconstruction loss: 0.019 Test covariance loss: 7.738\n",
      "Epoch: 16/25, Step 7240, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.375\n",
      "Epoch: 16/25, Step 7280, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 6.971\n",
      "Epoch: 16/25, Step 7320, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.298\n",
      "Epoch: 16/25, Step 7360, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.342\n",
      "Epoch: 16/25, Step 7400, Train loss: 0.087 Train reconstruction loss: 0.019 Train covariance loss: 6.803\n",
      "Epoch: 16/25, Step 7440, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.040\n",
      "Epoch: 16/25, Step 7480, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.178\n",
      "Epoch: 16/25, Step 7520, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.277\n",
      "Epoch: 16/25, Step 7560, Train loss: 0.091 Train reconstruction loss: 0.020 Train covariance loss: 7.176\n",
      "Epoch: 16/25, Step 7600, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.337\n",
      "Epoch: 16/25, Step 7640, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.266\n",
      "Epoch: 16/25, Step 7680, Train loss: 0.088 Train reconstruction loss: 0.019 Train covariance loss: 6.911\n",
      "Epoch 16/25,\n",
      "Train Loss: 0.091 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.085 Test reconstruction loss: 0.019 Test covariance loss: 6.659\n",
      "Epoch: 17/25, Step 7720, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 7.020\n",
      "Epoch: 17/25, Step 7760, Train loss: 0.088 Train reconstruction loss: 0.019 Train covariance loss: 6.936\n",
      "Epoch: 17/25, Step 7800, Train loss: 0.094 Train reconstruction loss: 0.019 Train covariance loss: 7.465\n",
      "Epoch: 17/25, Step 7840, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.063\n",
      "Epoch: 17/25, Step 7880, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.186\n",
      "Epoch: 17/25, Step 7920, Train loss: 0.094 Train reconstruction loss: 0.019 Train covariance loss: 7.468\n",
      "Epoch: 17/25, Step 7960, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.203\n",
      "Epoch: 17/25, Step 8000, Train loss: 0.088 Train reconstruction loss: 0.019 Train covariance loss: 6.907\n",
      "Epoch: 17/25, Step 8040, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.134\n",
      "Epoch: 17/25, Step 8080, Train loss: 0.088 Train reconstruction loss: 0.019 Train covariance loss: 6.889\n",
      "Epoch: 17/25, Step 8120, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.273\n",
      "Epoch: 17/25, Step 8160, Train loss: 0.095 Train reconstruction loss: 0.019 Train covariance loss: 7.611\n",
      "Epoch 17/25,\n",
      "Train Loss: 0.091 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.084 Test reconstruction loss: 0.019 Test covariance loss: 6.525\n",
      "Epoch: 18/25, Step 8200, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 6.997\n",
      "Epoch: 18/25, Step 8240, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.278\n",
      "Epoch: 18/25, Step 8280, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.061\n",
      "Epoch: 18/25, Step 8320, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.101\n",
      "Epoch: 18/25, Step 8360, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.111\n",
      "Epoch: 18/25, Step 8400, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.228\n",
      "Epoch: 18/25, Step 8440, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.316\n",
      "Epoch: 18/25, Step 8480, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.160\n",
      "Epoch: 18/25, Step 8520, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.223\n",
      "Epoch: 18/25, Step 8560, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 6.960\n",
      "Epoch: 18/25, Step 8600, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.237\n",
      "Epoch: 18/25, Step 8640, Train loss: 0.095 Train reconstruction loss: 0.019 Train covariance loss: 7.553\n",
      "Epoch 18/25,\n",
      "Train Loss: 0.091 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.088 Test reconstruction loss: 0.019 Test covariance loss: 6.901\n",
      "Epoch: 19/25, Step 8680, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.332\n",
      "Epoch: 19/25, Step 8720, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.276\n",
      "Epoch: 19/25, Step 8760, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.346\n",
      "Epoch: 19/25, Step 8800, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 7.092\n",
      "Epoch: 19/25, Step 8840, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.066\n",
      "Epoch: 19/25, Step 8880, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 6.997\n",
      "Epoch: 19/25, Step 8920, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.356\n",
      "Epoch: 19/25, Step 8960, Train loss: 0.094 Train reconstruction loss: 0.019 Train covariance loss: 7.491\n",
      "Epoch: 19/25, Step 9000, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.268\n",
      "Epoch: 19/25, Step 9040, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.150\n",
      "Epoch: 19/25, Step 9080, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 6.999\n",
      "Epoch: 19/25, Step 9120, Train loss: 0.087 Train reconstruction loss: 0.019 Train covariance loss: 6.801\n",
      "Epoch 19/25,\n",
      "Train Loss: 0.091 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.086 Test reconstruction loss: 0.019 Test covariance loss: 6.765\n",
      "Epoch: 20/25, Step 9160, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.130\n",
      "Epoch: 20/25, Step 9200, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 7.052\n",
      "Epoch: 20/25, Step 9240, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.209\n",
      "Epoch: 20/25, Step 9280, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.177\n",
      "Epoch: 20/25, Step 9320, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.116\n",
      "Epoch: 20/25, Step 9360, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.033\n",
      "Epoch: 20/25, Step 9400, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.238\n",
      "Epoch: 20/25, Step 9440, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.216\n",
      "Epoch: 20/25, Step 9480, Train loss: 0.088 Train reconstruction loss: 0.019 Train covariance loss: 6.918\n",
      "Epoch: 20/25, Step 9520, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.471\n",
      "Epoch: 20/25, Step 9560, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.084\n",
      "Epoch: 20/25, Step 9600, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.211\n",
      "Epoch 20/25,\n",
      "Train Loss: 0.091 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.088 Test reconstruction loss: 0.019 Test covariance loss: 6.913\n",
      "Epoch: 21/25, Step 9640, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 6.951\n",
      "Epoch: 21/25, Step 9680, Train loss: 0.088 Train reconstruction loss: 0.019 Train covariance loss: 6.911\n",
      "Epoch: 21/25, Step 9720, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.294\n",
      "Epoch: 21/25, Step 9760, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.441\n",
      "Epoch: 21/25, Step 9800, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.458\n",
      "Epoch: 21/25, Step 9840, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 7.042\n",
      "Epoch: 21/25, Step 9880, Train loss: 0.088 Train reconstruction loss: 0.019 Train covariance loss: 6.880\n",
      "Epoch: 21/25, Step 9920, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.383\n",
      "Epoch: 21/25, Step 9960, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.113\n",
      "Epoch: 21/25, Step 10000, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.184\n",
      "Epoch: 21/25, Step 10040, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 6.928\n",
      "Epoch: 21/25, Step 10080, Train loss: 0.088 Train reconstruction loss: 0.019 Train covariance loss: 6.932\n",
      "Epoch 21/25,\n",
      "Train Loss: 0.090 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.083 Test reconstruction loss: 0.019 Test covariance loss: 6.403\n",
      "Epoch: 22/25, Step 10120, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 7.009\n",
      "Epoch: 22/25, Step 10160, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.398\n",
      "Epoch: 22/25, Step 10200, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.388\n",
      "Epoch: 22/25, Step 10240, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 6.993\n",
      "Epoch: 22/25, Step 10280, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.192\n",
      "Epoch: 22/25, Step 10320, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.410\n",
      "Epoch: 22/25, Step 10360, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.243\n",
      "Epoch: 22/25, Step 10400, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 7.056\n",
      "Epoch: 22/25, Step 10440, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.260\n",
      "Epoch: 22/25, Step 10480, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.116\n",
      "Epoch: 22/25, Step 10520, Train loss: 0.086 Train reconstruction loss: 0.019 Train covariance loss: 6.761\n",
      "Epoch: 22/25, Step 10560, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.075\n",
      "Epoch 22/25,\n",
      "Train Loss: 0.091 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.089 Test reconstruction loss: 0.018 Test covariance loss: 7.072\n",
      "Epoch: 23/25, Step 10600, Train loss: 0.087 Train reconstruction loss: 0.019 Train covariance loss: 6.825\n",
      "Epoch: 23/25, Step 10640, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.220\n",
      "Epoch: 23/25, Step 10680, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.117\n",
      "Epoch: 23/25, Step 10720, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.180\n",
      "Epoch: 23/25, Step 10760, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 7.055\n",
      "Epoch: 23/25, Step 10800, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.238\n",
      "Epoch: 23/25, Step 10840, Train loss: 0.088 Train reconstruction loss: 0.019 Train covariance loss: 6.879\n",
      "Epoch: 23/25, Step 10880, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.359\n",
      "Epoch: 23/25, Step 10920, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 6.995\n",
      "Epoch: 23/25, Step 10960, Train loss: 0.094 Train reconstruction loss: 0.019 Train covariance loss: 7.518\n",
      "Epoch: 23/25, Step 11000, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.252\n",
      "Epoch: 23/25, Step 11040, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.224\n",
      "Epoch 23/25,\n",
      "Train Loss: 0.090 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.086 Test reconstruction loss: 0.018 Test covariance loss: 6.749\n",
      "Epoch: 24/25, Step 11080, Train loss: 0.088 Train reconstruction loss: 0.019 Train covariance loss: 6.942\n",
      "Epoch: 24/25, Step 11120, Train loss: 0.095 Train reconstruction loss: 0.019 Train covariance loss: 7.558\n",
      "Epoch: 24/25, Step 11160, Train loss: 0.093 Train reconstruction loss: 0.019 Train covariance loss: 7.340\n",
      "Epoch: 24/25, Step 11200, Train loss: 0.087 Train reconstruction loss: 0.019 Train covariance loss: 6.815\n",
      "Epoch: 24/25, Step 11240, Train loss: 0.087 Train reconstruction loss: 0.019 Train covariance loss: 6.808\n",
      "Epoch: 24/25, Step 11280, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.273\n",
      "Epoch: 24/25, Step 11320, Train loss: 0.088 Train reconstruction loss: 0.019 Train covariance loss: 6.959\n",
      "Epoch: 24/25, Step 11360, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.129\n",
      "Epoch: 24/25, Step 11400, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.366\n",
      "Epoch: 24/25, Step 11440, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.264\n",
      "Epoch: 24/25, Step 11480, Train loss: 0.094 Train reconstruction loss: 0.019 Train covariance loss: 7.507\n",
      "Epoch: 24/25, Step 11520, Train loss: 0.088 Train reconstruction loss: 0.019 Train covariance loss: 6.883\n",
      "Epoch 24/25,\n",
      "Train Loss: 0.090 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.091 Test reconstruction loss: 0.019 Test covariance loss: 7.291\n",
      "Epoch: 25/25, Step 11560, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.192\n",
      "Epoch: 25/25, Step 11600, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.208\n",
      "Epoch: 25/25, Step 11640, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 6.964\n",
      "Epoch: 25/25, Step 11680, Train loss: 0.091 Train reconstruction loss: 0.019 Train covariance loss: 7.177\n",
      "Epoch: 25/25, Step 11720, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 7.058\n",
      "Epoch: 25/25, Step 11760, Train loss: 0.088 Train reconstruction loss: 0.019 Train covariance loss: 6.914\n",
      "Epoch: 25/25, Step 11800, Train loss: 0.096 Train reconstruction loss: 0.019 Train covariance loss: 7.693\n",
      "Epoch: 25/25, Step 11840, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.089\n",
      "Epoch: 25/25, Step 11880, Train loss: 0.092 Train reconstruction loss: 0.019 Train covariance loss: 7.279\n",
      "Epoch: 25/25, Step 11920, Train loss: 0.089 Train reconstruction loss: 0.019 Train covariance loss: 7.066\n",
      "Epoch: 25/25, Step 11960, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.121\n",
      "Epoch: 25/25, Step 12000, Train loss: 0.090 Train reconstruction loss: 0.019 Train covariance loss: 7.147\n",
      "Epoch 25/25,\n",
      "Train Loss: 0.091 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.085 Test reconstruction loss: 0.018 Test covariance loss: 6.678\n",
      "Training with hidden dim: 5\n",
      "Epoch: 1/25, Step 40, Train loss: 0.153 Train reconstruction loss: 0.027 Train covariance loss: 12.602\n",
      "Epoch: 1/25, Step 80, Train loss: 0.145 Train reconstruction loss: 0.021 Train covariance loss: 12.384\n",
      "Epoch: 1/25, Step 120, Train loss: 0.142 Train reconstruction loss: 0.020 Train covariance loss: 12.187\n",
      "Epoch: 1/25, Step 160, Train loss: 0.145 Train reconstruction loss: 0.020 Train covariance loss: 12.515\n",
      "Epoch: 1/25, Step 200, Train loss: 0.146 Train reconstruction loss: 0.020 Train covariance loss: 12.621\n",
      "Epoch: 1/25, Step 240, Train loss: 0.145 Train reconstruction loss: 0.020 Train covariance loss: 12.542\n",
      "Epoch: 1/25, Step 280, Train loss: 0.142 Train reconstruction loss: 0.020 Train covariance loss: 12.241\n",
      "Epoch: 1/25, Step 320, Train loss: 0.147 Train reconstruction loss: 0.020 Train covariance loss: 12.675\n",
      "Epoch: 1/25, Step 360, Train loss: 0.143 Train reconstruction loss: 0.020 Train covariance loss: 12.381\n",
      "Epoch: 1/25, Step 400, Train loss: 0.142 Train reconstruction loss: 0.020 Train covariance loss: 12.234\n",
      "Epoch: 1/25, Step 440, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.454\n",
      "Epoch: 1/25, Step 480, Train loss: 0.145 Train reconstruction loss: 0.020 Train covariance loss: 12.479\n",
      "Test loss decreased (inf --> 0.144372).  Saving model ...\n",
      "Epoch 1/25,\n",
      "Train Loss: 0.145 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.144 Test reconstruction loss: 0.019 Test covariance loss: 12.511\n",
      "Epoch: 2/25, Step 520, Train loss: 0.145 Train reconstruction loss: 0.020 Train covariance loss: 12.541\n",
      "Epoch: 2/25, Step 560, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.432\n",
      "Epoch: 2/25, Step 600, Train loss: 0.141 Train reconstruction loss: 0.019 Train covariance loss: 12.190\n",
      "Epoch: 2/25, Step 640, Train loss: 0.142 Train reconstruction loss: 0.019 Train covariance loss: 12.279\n",
      "Epoch: 2/25, Step 680, Train loss: 0.147 Train reconstruction loss: 0.019 Train covariance loss: 12.785\n",
      "Epoch: 2/25, Step 720, Train loss: 0.151 Train reconstruction loss: 0.020 Train covariance loss: 13.083\n",
      "Epoch: 2/25, Step 760, Train loss: 0.145 Train reconstruction loss: 0.019 Train covariance loss: 12.578\n",
      "Epoch: 2/25, Step 800, Train loss: 0.144 Train reconstruction loss: 0.020 Train covariance loss: 12.448\n",
      "Epoch: 2/25, Step 840, Train loss: 0.142 Train reconstruction loss: 0.019 Train covariance loss: 12.293\n",
      "Epoch: 2/25, Step 880, Train loss: 0.142 Train reconstruction loss: 0.019 Train covariance loss: 12.249\n",
      "Epoch: 2/25, Step 920, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.484\n",
      "Epoch: 2/25, Step 960, Train loss: 0.142 Train reconstruction loss: 0.019 Train covariance loss: 12.277\n",
      "Test loss decreased (0.144372 --> 0.126775).  Saving model ...\n",
      "Epoch 2/25,\n",
      "Train Loss: 0.144 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.127 Test reconstruction loss: 0.019 Test covariance loss: 10.787\n",
      "Epoch: 3/25, Step 1000, Train loss: 0.143 Train reconstruction loss: 0.020 Train covariance loss: 12.392\n",
      "Epoch: 3/25, Step 1040, Train loss: 0.143 Train reconstruction loss: 0.019 Train covariance loss: 12.413\n",
      "Epoch: 3/25, Step 1080, Train loss: 0.142 Train reconstruction loss: 0.019 Train covariance loss: 12.334\n",
      "Epoch: 3/25, Step 1120, Train loss: 0.143 Train reconstruction loss: 0.019 Train covariance loss: 12.334\n",
      "Epoch: 3/25, Step 1160, Train loss: 0.151 Train reconstruction loss: 0.019 Train covariance loss: 13.169\n",
      "Epoch: 3/25, Step 1200, Train loss: 0.143 Train reconstruction loss: 0.019 Train covariance loss: 12.372\n",
      "Epoch: 3/25, Step 1240, Train loss: 0.139 Train reconstruction loss: 0.019 Train covariance loss: 12.026\n",
      "Epoch: 3/25, Step 1280, Train loss: 0.147 Train reconstruction loss: 0.019 Train covariance loss: 12.786\n",
      "Epoch: 3/25, Step 1320, Train loss: 0.140 Train reconstruction loss: 0.019 Train covariance loss: 12.136\n",
      "Epoch: 3/25, Step 1360, Train loss: 0.146 Train reconstruction loss: 0.019 Train covariance loss: 12.706\n",
      "Epoch: 3/25, Step 1400, Train loss: 0.142 Train reconstruction loss: 0.019 Train covariance loss: 12.287\n",
      "Epoch: 3/25, Step 1440, Train loss: 0.146 Train reconstruction loss: 0.019 Train covariance loss: 12.653\n",
      "Epoch 3/25,\n",
      "Train Loss: 0.144 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.138 Test reconstruction loss: 0.019 Test covariance loss: 11.917\n",
      "Epoch: 4/25, Step 1480, Train loss: 0.145 Train reconstruction loss: 0.019 Train covariance loss: 12.595\n",
      "Epoch: 4/25, Step 1520, Train loss: 0.150 Train reconstruction loss: 0.019 Train covariance loss: 13.030\n",
      "Epoch: 4/25, Step 1560, Train loss: 0.143 Train reconstruction loss: 0.019 Train covariance loss: 12.363\n",
      "Epoch: 4/25, Step 1600, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.524\n",
      "Epoch: 4/25, Step 1640, Train loss: 0.147 Train reconstruction loss: 0.019 Train covariance loss: 12.846\n",
      "Epoch: 4/25, Step 1680, Train loss: 0.139 Train reconstruction loss: 0.019 Train covariance loss: 12.074\n",
      "Epoch: 4/25, Step 1720, Train loss: 0.141 Train reconstruction loss: 0.019 Train covariance loss: 12.244\n",
      "Epoch: 4/25, Step 1760, Train loss: 0.143 Train reconstruction loss: 0.019 Train covariance loss: 12.441\n",
      "Epoch: 4/25, Step 1800, Train loss: 0.140 Train reconstruction loss: 0.019 Train covariance loss: 12.065\n",
      "Epoch: 4/25, Step 1840, Train loss: 0.142 Train reconstruction loss: 0.019 Train covariance loss: 12.243\n",
      "Epoch: 4/25, Step 1880, Train loss: 0.143 Train reconstruction loss: 0.019 Train covariance loss: 12.445\n",
      "Epoch: 4/25, Step 1920, Train loss: 0.147 Train reconstruction loss: 0.019 Train covariance loss: 12.775\n",
      "Epoch 4/25,\n",
      "Train Loss: 0.144 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.127 Test reconstruction loss: 0.019 Test covariance loss: 10.830\n",
      "Epoch: 5/25, Step 1960, Train loss: 0.142 Train reconstruction loss: 0.019 Train covariance loss: 12.364\n",
      "Epoch: 5/25, Step 2000, Train loss: 0.141 Train reconstruction loss: 0.019 Train covariance loss: 12.174\n",
      "Epoch: 5/25, Step 2040, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.528\n",
      "Epoch: 5/25, Step 2080, Train loss: 0.140 Train reconstruction loss: 0.019 Train covariance loss: 12.064\n",
      "Epoch: 5/25, Step 2120, Train loss: 0.140 Train reconstruction loss: 0.019 Train covariance loss: 12.082\n",
      "Epoch: 5/25, Step 2160, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.459\n",
      "Epoch: 5/25, Step 2200, Train loss: 0.148 Train reconstruction loss: 0.019 Train covariance loss: 12.899\n",
      "Epoch: 5/25, Step 2240, Train loss: 0.145 Train reconstruction loss: 0.018 Train covariance loss: 12.705\n",
      "Epoch: 5/25, Step 2280, Train loss: 0.147 Train reconstruction loss: 0.019 Train covariance loss: 12.824\n",
      "Epoch: 5/25, Step 2320, Train loss: 0.142 Train reconstruction loss: 0.019 Train covariance loss: 12.286\n",
      "Epoch: 5/25, Step 2360, Train loss: 0.146 Train reconstruction loss: 0.019 Train covariance loss: 12.674\n",
      "Epoch: 5/25, Step 2400, Train loss: 0.142 Train reconstruction loss: 0.019 Train covariance loss: 12.314\n",
      "Epoch 5/25,\n",
      "Train Loss: 0.143 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.151 Test reconstruction loss: 0.019 Test covariance loss: 13.251\n",
      "Epoch: 6/25, Step 2440, Train loss: 0.143 Train reconstruction loss: 0.019 Train covariance loss: 12.356\n",
      "Epoch: 6/25, Step 2480, Train loss: 0.141 Train reconstruction loss: 0.019 Train covariance loss: 12.183\n",
      "Epoch: 6/25, Step 2520, Train loss: 0.135 Train reconstruction loss: 0.019 Train covariance loss: 11.686\n",
      "Epoch: 6/25, Step 2560, Train loss: 0.136 Train reconstruction loss: 0.019 Train covariance loss: 11.709\n",
      "Epoch: 6/25, Step 2600, Train loss: 0.149 Train reconstruction loss: 0.019 Train covariance loss: 12.948\n",
      "Epoch: 6/25, Step 2640, Train loss: 0.141 Train reconstruction loss: 0.019 Train covariance loss: 12.272\n",
      "Epoch: 6/25, Step 2680, Train loss: 0.148 Train reconstruction loss: 0.019 Train covariance loss: 12.891\n",
      "Epoch: 6/25, Step 2720, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.561\n",
      "Epoch: 6/25, Step 2760, Train loss: 0.145 Train reconstruction loss: 0.019 Train covariance loss: 12.611\n",
      "Epoch: 6/25, Step 2800, Train loss: 0.147 Train reconstruction loss: 0.019 Train covariance loss: 12.794\n",
      "Epoch: 6/25, Step 2840, Train loss: 0.149 Train reconstruction loss: 0.019 Train covariance loss: 12.960\n",
      "Epoch: 6/25, Step 2880, Train loss: 0.142 Train reconstruction loss: 0.019 Train covariance loss: 12.341\n",
      "Epoch 6/25,\n",
      "Train Loss: 0.143 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.131 Test reconstruction loss: 0.018 Test covariance loss: 11.262\n",
      "Epoch: 7/25, Step 2920, Train loss: 0.144 Train reconstruction loss: 0.018 Train covariance loss: 12.510\n",
      "Epoch: 7/25, Step 2960, Train loss: 0.149 Train reconstruction loss: 0.019 Train covariance loss: 13.023\n",
      "Epoch: 7/25, Step 3000, Train loss: 0.145 Train reconstruction loss: 0.019 Train covariance loss: 12.620\n",
      "Epoch: 7/25, Step 3040, Train loss: 0.147 Train reconstruction loss: 0.019 Train covariance loss: 12.801\n",
      "Epoch: 7/25, Step 3080, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.540\n",
      "Epoch: 7/25, Step 3120, Train loss: 0.143 Train reconstruction loss: 0.019 Train covariance loss: 12.409\n",
      "Epoch: 7/25, Step 3160, Train loss: 0.141 Train reconstruction loss: 0.019 Train covariance loss: 12.230\n",
      "Epoch: 7/25, Step 3200, Train loss: 0.145 Train reconstruction loss: 0.019 Train covariance loss: 12.594\n",
      "Epoch: 7/25, Step 3240, Train loss: 0.140 Train reconstruction loss: 0.019 Train covariance loss: 12.123\n",
      "Epoch: 7/25, Step 3280, Train loss: 0.143 Train reconstruction loss: 0.019 Train covariance loss: 12.364\n",
      "Epoch: 7/25, Step 3320, Train loss: 0.142 Train reconstruction loss: 0.019 Train covariance loss: 12.309\n",
      "Epoch: 7/25, Step 3360, Train loss: 0.143 Train reconstruction loss: 0.019 Train covariance loss: 12.385\n",
      "Epoch 7/25,\n",
      "Train Loss: 0.144 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.138 Test reconstruction loss: 0.018 Test covariance loss: 11.959\n",
      "Epoch: 8/25, Step 3400, Train loss: 0.141 Train reconstruction loss: 0.019 Train covariance loss: 12.237\n",
      "Epoch: 8/25, Step 3440, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.506\n",
      "Epoch: 8/25, Step 3480, Train loss: 0.153 Train reconstruction loss: 0.019 Train covariance loss: 13.393\n",
      "Epoch: 8/25, Step 3520, Train loss: 0.139 Train reconstruction loss: 0.019 Train covariance loss: 12.054\n",
      "Epoch: 8/25, Step 3560, Train loss: 0.143 Train reconstruction loss: 0.019 Train covariance loss: 12.471\n",
      "Epoch: 8/25, Step 3600, Train loss: 0.141 Train reconstruction loss: 0.018 Train covariance loss: 12.223\n",
      "Epoch: 8/25, Step 3640, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.513\n",
      "Epoch: 8/25, Step 3680, Train loss: 0.147 Train reconstruction loss: 0.019 Train covariance loss: 12.772\n",
      "Epoch: 8/25, Step 3720, Train loss: 0.145 Train reconstruction loss: 0.019 Train covariance loss: 12.599\n",
      "Epoch: 8/25, Step 3760, Train loss: 0.141 Train reconstruction loss: 0.019 Train covariance loss: 12.225\n",
      "Epoch: 8/25, Step 3800, Train loss: 0.137 Train reconstruction loss: 0.019 Train covariance loss: 11.826\n",
      "Epoch: 8/25, Step 3840, Train loss: 0.145 Train reconstruction loss: 0.019 Train covariance loss: 12.593\n",
      "Epoch 8/25,\n",
      "Train Loss: 0.143 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.130 Test reconstruction loss: 0.018 Test covariance loss: 11.126\n",
      "Epoch: 9/25, Step 3880, Train loss: 0.145 Train reconstruction loss: 0.018 Train covariance loss: 12.680\n",
      "Epoch: 9/25, Step 3920, Train loss: 0.147 Train reconstruction loss: 0.019 Train covariance loss: 12.795\n",
      "Epoch: 9/25, Step 3960, Train loss: 0.143 Train reconstruction loss: 0.019 Train covariance loss: 12.431\n",
      "Epoch: 9/25, Step 4000, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.494\n",
      "Epoch: 9/25, Step 4040, Train loss: 0.139 Train reconstruction loss: 0.019 Train covariance loss: 11.970\n",
      "Epoch: 9/25, Step 4080, Train loss: 0.141 Train reconstruction loss: 0.018 Train covariance loss: 12.292\n",
      "Epoch: 9/25, Step 4120, Train loss: 0.142 Train reconstruction loss: 0.019 Train covariance loss: 12.291\n",
      "Epoch: 9/25, Step 4160, Train loss: 0.140 Train reconstruction loss: 0.019 Train covariance loss: 12.161\n",
      "Epoch: 9/25, Step 4200, Train loss: 0.141 Train reconstruction loss: 0.019 Train covariance loss: 12.249\n",
      "Epoch: 9/25, Step 4240, Train loss: 0.149 Train reconstruction loss: 0.019 Train covariance loss: 13.013\n",
      "Epoch: 9/25, Step 4280, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.531\n",
      "Epoch: 9/25, Step 4320, Train loss: 0.149 Train reconstruction loss: 0.019 Train covariance loss: 13.014\n",
      "Epoch 9/25,\n",
      "Train Loss: 0.144 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.140 Test reconstruction loss: 0.018 Test covariance loss: 12.192\n",
      "Epoch: 10/25, Step 4360, Train loss: 0.139 Train reconstruction loss: 0.018 Train covariance loss: 12.031\n",
      "Epoch: 10/25, Step 4400, Train loss: 0.145 Train reconstruction loss: 0.019 Train covariance loss: 12.647\n",
      "Epoch: 10/25, Step 4440, Train loss: 0.141 Train reconstruction loss: 0.019 Train covariance loss: 12.194\n",
      "Epoch: 10/25, Step 4480, Train loss: 0.146 Train reconstruction loss: 0.019 Train covariance loss: 12.769\n",
      "Epoch: 10/25, Step 4520, Train loss: 0.143 Train reconstruction loss: 0.018 Train covariance loss: 12.505\n",
      "Epoch: 10/25, Step 4560, Train loss: 0.146 Train reconstruction loss: 0.019 Train covariance loss: 12.693\n",
      "Epoch: 10/25, Step 4600, Train loss: 0.145 Train reconstruction loss: 0.019 Train covariance loss: 12.571\n",
      "Epoch: 10/25, Step 4640, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.513\n",
      "Epoch: 10/25, Step 4680, Train loss: 0.140 Train reconstruction loss: 0.018 Train covariance loss: 12.141\n",
      "Epoch: 10/25, Step 4720, Train loss: 0.143 Train reconstruction loss: 0.019 Train covariance loss: 12.435\n",
      "Epoch: 10/25, Step 4760, Train loss: 0.145 Train reconstruction loss: 0.019 Train covariance loss: 12.683\n",
      "Epoch: 10/25, Step 4800, Train loss: 0.146 Train reconstruction loss: 0.019 Train covariance loss: 12.684\n",
      "Epoch 10/25,\n",
      "Train Loss: 0.144 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.155 Test reconstruction loss: 0.018 Test covariance loss: 13.679\n",
      "Epoch: 11/25, Step 4840, Train loss: 0.134 Train reconstruction loss: 0.019 Train covariance loss: 11.508\n",
      "Epoch: 11/25, Step 4880, Train loss: 0.145 Train reconstruction loss: 0.019 Train covariance loss: 12.592\n",
      "Epoch: 11/25, Step 4920, Train loss: 0.140 Train reconstruction loss: 0.019 Train covariance loss: 12.142\n",
      "Epoch: 11/25, Step 4960, Train loss: 0.141 Train reconstruction loss: 0.019 Train covariance loss: 12.230\n",
      "Epoch: 11/25, Step 5000, Train loss: 0.143 Train reconstruction loss: 0.018 Train covariance loss: 12.456\n",
      "Epoch: 11/25, Step 5040, Train loss: 0.145 Train reconstruction loss: 0.019 Train covariance loss: 12.649\n",
      "Epoch: 11/25, Step 5080, Train loss: 0.146 Train reconstruction loss: 0.018 Train covariance loss: 12.801\n",
      "Epoch: 11/25, Step 5120, Train loss: 0.140 Train reconstruction loss: 0.019 Train covariance loss: 12.090\n",
      "Epoch: 11/25, Step 5160, Train loss: 0.147 Train reconstruction loss: 0.019 Train covariance loss: 12.801\n",
      "Epoch: 11/25, Step 5200, Train loss: 0.146 Train reconstruction loss: 0.018 Train covariance loss: 12.728\n",
      "Epoch: 11/25, Step 5240, Train loss: 0.150 Train reconstruction loss: 0.019 Train covariance loss: 13.185\n",
      "Epoch: 11/25, Step 5280, Train loss: 0.142 Train reconstruction loss: 0.019 Train covariance loss: 12.306\n",
      "Test loss decreased (0.126775 --> 0.124719).  Saving model ...\n",
      "Epoch 11/25,\n",
      "Train Loss: 0.143 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.125 Test reconstruction loss: 0.018 Test covariance loss: 10.646\n",
      "Epoch: 12/25, Step 5320, Train loss: 0.145 Train reconstruction loss: 0.019 Train covariance loss: 12.677\n",
      "Epoch: 12/25, Step 5360, Train loss: 0.145 Train reconstruction loss: 0.019 Train covariance loss: 12.580\n",
      "Epoch: 12/25, Step 5400, Train loss: 0.142 Train reconstruction loss: 0.018 Train covariance loss: 12.311\n",
      "Epoch: 12/25, Step 5440, Train loss: 0.148 Train reconstruction loss: 0.018 Train covariance loss: 12.917\n",
      "Epoch: 12/25, Step 5480, Train loss: 0.139 Train reconstruction loss: 0.019 Train covariance loss: 12.078\n",
      "Epoch: 12/25, Step 5520, Train loss: 0.137 Train reconstruction loss: 0.018 Train covariance loss: 11.906\n",
      "Epoch: 12/25, Step 5560, Train loss: 0.151 Train reconstruction loss: 0.018 Train covariance loss: 13.315\n",
      "Epoch: 12/25, Step 5600, Train loss: 0.144 Train reconstruction loss: 0.018 Train covariance loss: 12.530\n",
      "Epoch: 12/25, Step 5640, Train loss: 0.149 Train reconstruction loss: 0.019 Train covariance loss: 12.987\n",
      "Epoch: 12/25, Step 5680, Train loss: 0.140 Train reconstruction loss: 0.019 Train covariance loss: 12.068\n",
      "Epoch: 12/25, Step 5720, Train loss: 0.140 Train reconstruction loss: 0.019 Train covariance loss: 12.141\n",
      "Epoch: 12/25, Step 5760, Train loss: 0.142 Train reconstruction loss: 0.019 Train covariance loss: 12.309\n",
      "Epoch 12/25,\n",
      "Train Loss: 0.143 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.129 Test reconstruction loss: 0.018 Test covariance loss: 11.112\n",
      "Epoch: 13/25, Step 5800, Train loss: 0.138 Train reconstruction loss: 0.019 Train covariance loss: 11.961\n",
      "Epoch: 13/25, Step 5840, Train loss: 0.141 Train reconstruction loss: 0.018 Train covariance loss: 12.303\n",
      "Epoch: 13/25, Step 5880, Train loss: 0.142 Train reconstruction loss: 0.018 Train covariance loss: 12.378\n",
      "Epoch: 13/25, Step 5920, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.540\n",
      "Epoch: 13/25, Step 5960, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.514\n",
      "Epoch: 13/25, Step 6000, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.505\n",
      "Epoch: 13/25, Step 6040, Train loss: 0.140 Train reconstruction loss: 0.019 Train covariance loss: 12.183\n",
      "Epoch: 13/25, Step 6080, Train loss: 0.139 Train reconstruction loss: 0.019 Train covariance loss: 12.050\n",
      "Epoch: 13/25, Step 6120, Train loss: 0.148 Train reconstruction loss: 0.019 Train covariance loss: 12.889\n",
      "Epoch: 13/25, Step 6160, Train loss: 0.151 Train reconstruction loss: 0.018 Train covariance loss: 13.213\n",
      "Epoch: 13/25, Step 6200, Train loss: 0.142 Train reconstruction loss: 0.019 Train covariance loss: 12.308\n",
      "Epoch: 13/25, Step 6240, Train loss: 0.145 Train reconstruction loss: 0.019 Train covariance loss: 12.639\n",
      "Epoch 13/25,\n",
      "Train Loss: 0.143 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.144 Test reconstruction loss: 0.018 Test covariance loss: 12.607\n",
      "Epoch: 14/25, Step 6280, Train loss: 0.146 Train reconstruction loss: 0.019 Train covariance loss: 12.690\n",
      "Epoch: 14/25, Step 6320, Train loss: 0.147 Train reconstruction loss: 0.019 Train covariance loss: 12.808\n",
      "Epoch: 14/25, Step 6360, Train loss: 0.145 Train reconstruction loss: 0.019 Train covariance loss: 12.580\n",
      "Epoch: 14/25, Step 6400, Train loss: 0.141 Train reconstruction loss: 0.019 Train covariance loss: 12.221\n",
      "Epoch: 14/25, Step 6440, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.552\n",
      "Epoch: 14/25, Step 6480, Train loss: 0.142 Train reconstruction loss: 0.018 Train covariance loss: 12.323\n",
      "Epoch: 14/25, Step 6520, Train loss: 0.140 Train reconstruction loss: 0.018 Train covariance loss: 12.187\n",
      "Epoch: 14/25, Step 6560, Train loss: 0.143 Train reconstruction loss: 0.019 Train covariance loss: 12.439\n",
      "Epoch: 14/25, Step 6600, Train loss: 0.145 Train reconstruction loss: 0.018 Train covariance loss: 12.696\n",
      "Epoch: 14/25, Step 6640, Train loss: 0.141 Train reconstruction loss: 0.019 Train covariance loss: 12.264\n",
      "Epoch: 14/25, Step 6680, Train loss: 0.139 Train reconstruction loss: 0.019 Train covariance loss: 12.064\n",
      "Epoch: 14/25, Step 6720, Train loss: 0.146 Train reconstruction loss: 0.019 Train covariance loss: 12.698\n",
      "Epoch 14/25,\n",
      "Train Loss: 0.143 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.133 Test reconstruction loss: 0.018 Test covariance loss: 11.459\n",
      "Epoch: 15/25, Step 6760, Train loss: 0.145 Train reconstruction loss: 0.018 Train covariance loss: 12.628\n",
      "Epoch: 15/25, Step 6800, Train loss: 0.145 Train reconstruction loss: 0.019 Train covariance loss: 12.605\n",
      "Epoch: 15/25, Step 6840, Train loss: 0.149 Train reconstruction loss: 0.018 Train covariance loss: 13.040\n",
      "Epoch: 15/25, Step 6880, Train loss: 0.140 Train reconstruction loss: 0.019 Train covariance loss: 12.108\n",
      "Epoch: 15/25, Step 6920, Train loss: 0.136 Train reconstruction loss: 0.019 Train covariance loss: 11.657\n",
      "Epoch: 15/25, Step 6960, Train loss: 0.145 Train reconstruction loss: 0.019 Train covariance loss: 12.629\n",
      "Epoch: 15/25, Step 7000, Train loss: 0.143 Train reconstruction loss: 0.018 Train covariance loss: 12.459\n",
      "Epoch: 15/25, Step 7040, Train loss: 0.143 Train reconstruction loss: 0.019 Train covariance loss: 12.404\n",
      "Epoch: 15/25, Step 7080, Train loss: 0.139 Train reconstruction loss: 0.019 Train covariance loss: 11.990\n",
      "Epoch: 15/25, Step 7120, Train loss: 0.147 Train reconstruction loss: 0.019 Train covariance loss: 12.834\n",
      "Epoch: 15/25, Step 7160, Train loss: 0.145 Train reconstruction loss: 0.018 Train covariance loss: 12.662\n",
      "Epoch: 15/25, Step 7200, Train loss: 0.149 Train reconstruction loss: 0.018 Train covariance loss: 13.084\n",
      "Epoch 15/25,\n",
      "Train Loss: 0.144 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.144 Test reconstruction loss: 0.018 Test covariance loss: 12.566\n",
      "Epoch: 16/25, Step 7240, Train loss: 0.147 Train reconstruction loss: 0.019 Train covariance loss: 12.801\n",
      "Epoch: 16/25, Step 7280, Train loss: 0.141 Train reconstruction loss: 0.018 Train covariance loss: 12.312\n",
      "Epoch: 16/25, Step 7320, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.561\n",
      "Epoch: 16/25, Step 7360, Train loss: 0.140 Train reconstruction loss: 0.019 Train covariance loss: 12.141\n",
      "Epoch: 16/25, Step 7400, Train loss: 0.139 Train reconstruction loss: 0.018 Train covariance loss: 12.031\n",
      "Epoch: 16/25, Step 7440, Train loss: 0.143 Train reconstruction loss: 0.019 Train covariance loss: 12.408\n",
      "Epoch: 16/25, Step 7480, Train loss: 0.141 Train reconstruction loss: 0.018 Train covariance loss: 12.248\n",
      "Epoch: 16/25, Step 7520, Train loss: 0.145 Train reconstruction loss: 0.019 Train covariance loss: 12.609\n",
      "Epoch: 16/25, Step 7560, Train loss: 0.146 Train reconstruction loss: 0.019 Train covariance loss: 12.767\n",
      "Epoch: 16/25, Step 7600, Train loss: 0.145 Train reconstruction loss: 0.019 Train covariance loss: 12.603\n",
      "Epoch: 16/25, Step 7640, Train loss: 0.146 Train reconstruction loss: 0.018 Train covariance loss: 12.729\n",
      "Epoch: 16/25, Step 7680, Train loss: 0.141 Train reconstruction loss: 0.019 Train covariance loss: 12.234\n",
      "Epoch 16/25,\n",
      "Train Loss: 0.143 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.161 Test reconstruction loss: 0.018 Test covariance loss: 14.249\n",
      "Epoch: 17/25, Step 7720, Train loss: 0.147 Train reconstruction loss: 0.019 Train covariance loss: 12.754\n",
      "Epoch: 17/25, Step 7760, Train loss: 0.142 Train reconstruction loss: 0.019 Train covariance loss: 12.339\n",
      "Epoch: 17/25, Step 7800, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.502\n",
      "Epoch: 17/25, Step 7840, Train loss: 0.144 Train reconstruction loss: 0.018 Train covariance loss: 12.579\n",
      "Epoch: 17/25, Step 7880, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.485\n",
      "Epoch: 17/25, Step 7920, Train loss: 0.142 Train reconstruction loss: 0.019 Train covariance loss: 12.356\n",
      "Epoch: 17/25, Step 7960, Train loss: 0.141 Train reconstruction loss: 0.018 Train covariance loss: 12.279\n",
      "Epoch: 17/25, Step 8000, Train loss: 0.146 Train reconstruction loss: 0.018 Train covariance loss: 12.771\n",
      "Epoch: 17/25, Step 8040, Train loss: 0.138 Train reconstruction loss: 0.018 Train covariance loss: 11.968\n",
      "Epoch: 17/25, Step 8080, Train loss: 0.142 Train reconstruction loss: 0.018 Train covariance loss: 12.390\n",
      "Epoch: 17/25, Step 8120, Train loss: 0.143 Train reconstruction loss: 0.019 Train covariance loss: 12.486\n",
      "Epoch: 17/25, Step 8160, Train loss: 0.144 Train reconstruction loss: 0.018 Train covariance loss: 12.554\n",
      "Epoch 17/25,\n",
      "Train Loss: 0.143 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.129 Test reconstruction loss: 0.018 Test covariance loss: 11.039\n",
      "Epoch: 18/25, Step 8200, Train loss: 0.143 Train reconstruction loss: 0.018 Train covariance loss: 12.464\n",
      "Epoch: 18/25, Step 8240, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.489\n",
      "Epoch: 18/25, Step 8280, Train loss: 0.141 Train reconstruction loss: 0.019 Train covariance loss: 12.258\n",
      "Epoch: 18/25, Step 8320, Train loss: 0.146 Train reconstruction loss: 0.019 Train covariance loss: 12.739\n",
      "Epoch: 18/25, Step 8360, Train loss: 0.143 Train reconstruction loss: 0.019 Train covariance loss: 12.409\n",
      "Epoch: 18/25, Step 8400, Train loss: 0.142 Train reconstruction loss: 0.018 Train covariance loss: 12.398\n",
      "Epoch: 18/25, Step 8440, Train loss: 0.143 Train reconstruction loss: 0.018 Train covariance loss: 12.495\n",
      "Epoch: 18/25, Step 8480, Train loss: 0.140 Train reconstruction loss: 0.018 Train covariance loss: 12.186\n",
      "Epoch: 18/25, Step 8520, Train loss: 0.143 Train reconstruction loss: 0.019 Train covariance loss: 12.462\n",
      "Epoch: 18/25, Step 8560, Train loss: 0.141 Train reconstruction loss: 0.019 Train covariance loss: 12.207\n",
      "Epoch: 18/25, Step 8600, Train loss: 0.141 Train reconstruction loss: 0.019 Train covariance loss: 12.191\n",
      "Epoch: 18/25, Step 8640, Train loss: 0.151 Train reconstruction loss: 0.018 Train covariance loss: 13.257\n",
      "Epoch 18/25,\n",
      "Train Loss: 0.143 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.140 Test reconstruction loss: 0.018 Test covariance loss: 12.231\n",
      "Epoch: 19/25, Step 8680, Train loss: 0.145 Train reconstruction loss: 0.019 Train covariance loss: 12.654\n",
      "Epoch: 19/25, Step 8720, Train loss: 0.144 Train reconstruction loss: 0.018 Train covariance loss: 12.555\n",
      "Epoch: 19/25, Step 8760, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.526\n",
      "Epoch: 19/25, Step 8800, Train loss: 0.147 Train reconstruction loss: 0.019 Train covariance loss: 12.867\n",
      "Epoch: 19/25, Step 8840, Train loss: 0.136 Train reconstruction loss: 0.018 Train covariance loss: 11.723\n",
      "Epoch: 19/25, Step 8880, Train loss: 0.146 Train reconstruction loss: 0.019 Train covariance loss: 12.735\n",
      "Epoch: 19/25, Step 8920, Train loss: 0.146 Train reconstruction loss: 0.018 Train covariance loss: 12.765\n",
      "Epoch: 19/25, Step 8960, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.514\n",
      "Epoch: 19/25, Step 9000, Train loss: 0.147 Train reconstruction loss: 0.018 Train covariance loss: 12.840\n",
      "Epoch: 19/25, Step 9040, Train loss: 0.140 Train reconstruction loss: 0.018 Train covariance loss: 12.148\n",
      "Epoch: 19/25, Step 9080, Train loss: 0.142 Train reconstruction loss: 0.019 Train covariance loss: 12.372\n",
      "Epoch: 19/25, Step 9120, Train loss: 0.138 Train reconstruction loss: 0.018 Train covariance loss: 11.956\n",
      "Epoch 19/25,\n",
      "Train Loss: 0.143 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.134 Test reconstruction loss: 0.018 Test covariance loss: 11.554\n",
      "Epoch: 20/25, Step 9160, Train loss: 0.143 Train reconstruction loss: 0.018 Train covariance loss: 12.426\n",
      "Epoch: 20/25, Step 9200, Train loss: 0.142 Train reconstruction loss: 0.018 Train covariance loss: 12.318\n",
      "Epoch: 20/25, Step 9240, Train loss: 0.143 Train reconstruction loss: 0.019 Train covariance loss: 12.409\n",
      "Epoch: 20/25, Step 9280, Train loss: 0.141 Train reconstruction loss: 0.018 Train covariance loss: 12.287\n",
      "Epoch: 20/25, Step 9320, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.506\n",
      "Epoch: 20/25, Step 9360, Train loss: 0.145 Train reconstruction loss: 0.018 Train covariance loss: 12.625\n",
      "Epoch: 20/25, Step 9400, Train loss: 0.146 Train reconstruction loss: 0.018 Train covariance loss: 12.741\n",
      "Epoch: 20/25, Step 9440, Train loss: 0.140 Train reconstruction loss: 0.018 Train covariance loss: 12.133\n",
      "Epoch: 20/25, Step 9480, Train loss: 0.149 Train reconstruction loss: 0.019 Train covariance loss: 12.970\n",
      "Epoch: 20/25, Step 9520, Train loss: 0.142 Train reconstruction loss: 0.019 Train covariance loss: 12.338\n",
      "Epoch: 20/25, Step 9560, Train loss: 0.141 Train reconstruction loss: 0.019 Train covariance loss: 12.257\n",
      "Epoch: 20/25, Step 9600, Train loss: 0.146 Train reconstruction loss: 0.018 Train covariance loss: 12.783\n",
      "Epoch 20/25,\n",
      "Train Loss: 0.143 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.137 Test reconstruction loss: 0.018 Test covariance loss: 11.880\n",
      "Epoch: 21/25, Step 9640, Train loss: 0.142 Train reconstruction loss: 0.018 Train covariance loss: 12.317\n",
      "Epoch: 21/25, Step 9680, Train loss: 0.141 Train reconstruction loss: 0.018 Train covariance loss: 12.283\n",
      "Epoch: 21/25, Step 9720, Train loss: 0.145 Train reconstruction loss: 0.018 Train covariance loss: 12.663\n",
      "Epoch: 21/25, Step 9760, Train loss: 0.142 Train reconstruction loss: 0.018 Train covariance loss: 12.307\n",
      "Epoch: 21/25, Step 9800, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.551\n",
      "Epoch: 21/25, Step 9840, Train loss: 0.141 Train reconstruction loss: 0.018 Train covariance loss: 12.276\n",
      "Epoch: 21/25, Step 9880, Train loss: 0.149 Train reconstruction loss: 0.019 Train covariance loss: 13.047\n",
      "Epoch: 21/25, Step 9920, Train loss: 0.142 Train reconstruction loss: 0.019 Train covariance loss: 12.321\n",
      "Epoch: 21/25, Step 9960, Train loss: 0.140 Train reconstruction loss: 0.019 Train covariance loss: 12.078\n",
      "Epoch: 21/25, Step 10000, Train loss: 0.145 Train reconstruction loss: 0.018 Train covariance loss: 12.637\n",
      "Epoch: 21/25, Step 10040, Train loss: 0.140 Train reconstruction loss: 0.018 Train covariance loss: 12.210\n",
      "Epoch: 21/25, Step 10080, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.508\n",
      "Epoch 21/25,\n",
      "Train Loss: 0.143 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.140 Test reconstruction loss: 0.018 Test covariance loss: 12.149\n",
      "Epoch: 22/25, Step 10120, Train loss: 0.142 Train reconstruction loss: 0.018 Train covariance loss: 12.366\n",
      "Epoch: 22/25, Step 10160, Train loss: 0.140 Train reconstruction loss: 0.018 Train covariance loss: 12.192\n",
      "Epoch: 22/25, Step 10200, Train loss: 0.143 Train reconstruction loss: 0.018 Train covariance loss: 12.413\n",
      "Epoch: 22/25, Step 10240, Train loss: 0.142 Train reconstruction loss: 0.019 Train covariance loss: 12.368\n",
      "Epoch: 22/25, Step 10280, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.542\n",
      "Epoch: 22/25, Step 10320, Train loss: 0.144 Train reconstruction loss: 0.018 Train covariance loss: 12.607\n",
      "Epoch: 22/25, Step 10360, Train loss: 0.146 Train reconstruction loss: 0.019 Train covariance loss: 12.725\n",
      "Epoch: 22/25, Step 10400, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.516\n",
      "Epoch: 22/25, Step 10440, Train loss: 0.139 Train reconstruction loss: 0.019 Train covariance loss: 12.070\n",
      "Epoch: 22/25, Step 10480, Train loss: 0.144 Train reconstruction loss: 0.018 Train covariance loss: 12.506\n",
      "Epoch: 22/25, Step 10520, Train loss: 0.145 Train reconstruction loss: 0.019 Train covariance loss: 12.679\n",
      "Epoch: 22/25, Step 10560, Train loss: 0.143 Train reconstruction loss: 0.018 Train covariance loss: 12.516\n",
      "Epoch 22/25,\n",
      "Train Loss: 0.143 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.144 Test reconstruction loss: 0.018 Test covariance loss: 12.605\n",
      "Epoch: 23/25, Step 10600, Train loss: 0.141 Train reconstruction loss: 0.018 Train covariance loss: 12.279\n",
      "Epoch: 23/25, Step 10640, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.483\n",
      "Epoch: 23/25, Step 10680, Train loss: 0.139 Train reconstruction loss: 0.019 Train covariance loss: 11.994\n",
      "Epoch: 23/25, Step 10720, Train loss: 0.141 Train reconstruction loss: 0.019 Train covariance loss: 12.175\n",
      "Epoch: 23/25, Step 10760, Train loss: 0.143 Train reconstruction loss: 0.018 Train covariance loss: 12.506\n",
      "Epoch: 23/25, Step 10800, Train loss: 0.143 Train reconstruction loss: 0.018 Train covariance loss: 12.484\n",
      "Epoch: 23/25, Step 10840, Train loss: 0.139 Train reconstruction loss: 0.018 Train covariance loss: 12.113\n",
      "Epoch: 23/25, Step 10880, Train loss: 0.145 Train reconstruction loss: 0.018 Train covariance loss: 12.618\n",
      "Epoch: 23/25, Step 10920, Train loss: 0.142 Train reconstruction loss: 0.019 Train covariance loss: 12.304\n",
      "Epoch: 23/25, Step 10960, Train loss: 0.143 Train reconstruction loss: 0.019 Train covariance loss: 12.481\n",
      "Epoch: 23/25, Step 11000, Train loss: 0.151 Train reconstruction loss: 0.018 Train covariance loss: 13.287\n",
      "Epoch: 23/25, Step 11040, Train loss: 0.142 Train reconstruction loss: 0.019 Train covariance loss: 12.374\n",
      "Epoch 23/25,\n",
      "Train Loss: 0.143 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.135 Test reconstruction loss: 0.018 Test covariance loss: 11.659\n",
      "Epoch: 24/25, Step 11080, Train loss: 0.140 Train reconstruction loss: 0.018 Train covariance loss: 12.189\n",
      "Epoch: 24/25, Step 11120, Train loss: 0.143 Train reconstruction loss: 0.019 Train covariance loss: 12.479\n",
      "Epoch: 24/25, Step 11160, Train loss: 0.141 Train reconstruction loss: 0.019 Train covariance loss: 12.244\n",
      "Epoch: 24/25, Step 11200, Train loss: 0.139 Train reconstruction loss: 0.018 Train covariance loss: 12.045\n",
      "Epoch: 24/25, Step 11240, Train loss: 0.146 Train reconstruction loss: 0.019 Train covariance loss: 12.723\n",
      "Epoch: 24/25, Step 11280, Train loss: 0.134 Train reconstruction loss: 0.019 Train covariance loss: 11.548\n",
      "Epoch: 24/25, Step 11320, Train loss: 0.144 Train reconstruction loss: 0.018 Train covariance loss: 12.589\n",
      "Epoch: 24/25, Step 11360, Train loss: 0.140 Train reconstruction loss: 0.018 Train covariance loss: 12.187\n",
      "Epoch: 24/25, Step 11400, Train loss: 0.146 Train reconstruction loss: 0.018 Train covariance loss: 12.746\n",
      "Epoch: 24/25, Step 11440, Train loss: 0.147 Train reconstruction loss: 0.018 Train covariance loss: 12.860\n",
      "Epoch: 24/25, Step 11480, Train loss: 0.144 Train reconstruction loss: 0.018 Train covariance loss: 12.582\n",
      "Epoch: 24/25, Step 11520, Train loss: 0.146 Train reconstruction loss: 0.018 Train covariance loss: 12.746\n",
      "Epoch 24/25,\n",
      "Train Loss: 0.143 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.142 Test reconstruction loss: 0.018 Test covariance loss: 12.423\n",
      "Epoch: 25/25, Step 11560, Train loss: 0.144 Train reconstruction loss: 0.018 Train covariance loss: 12.547\n",
      "Epoch: 25/25, Step 11600, Train loss: 0.143 Train reconstruction loss: 0.018 Train covariance loss: 12.424\n",
      "Epoch: 25/25, Step 11640, Train loss: 0.144 Train reconstruction loss: 0.018 Train covariance loss: 12.537\n",
      "Epoch: 25/25, Step 11680, Train loss: 0.142 Train reconstruction loss: 0.018 Train covariance loss: 12.325\n",
      "Epoch: 25/25, Step 11720, Train loss: 0.147 Train reconstruction loss: 0.018 Train covariance loss: 12.868\n",
      "Epoch: 25/25, Step 11760, Train loss: 0.145 Train reconstruction loss: 0.019 Train covariance loss: 12.616\n",
      "Epoch: 25/25, Step 11800, Train loss: 0.142 Train reconstruction loss: 0.018 Train covariance loss: 12.382\n",
      "Epoch: 25/25, Step 11840, Train loss: 0.140 Train reconstruction loss: 0.018 Train covariance loss: 12.140\n",
      "Epoch: 25/25, Step 11880, Train loss: 0.145 Train reconstruction loss: 0.018 Train covariance loss: 12.686\n",
      "Epoch: 25/25, Step 11920, Train loss: 0.140 Train reconstruction loss: 0.019 Train covariance loss: 12.173\n",
      "Epoch: 25/25, Step 11960, Train loss: 0.142 Train reconstruction loss: 0.019 Train covariance loss: 12.292\n",
      "Epoch: 25/25, Step 12000, Train loss: 0.144 Train reconstruction loss: 0.019 Train covariance loss: 12.556\n",
      "Epoch 25/25,\n",
      "Train Loss: 0.143 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.128 Test reconstruction loss: 0.018 Test covariance loss: 11.019\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs/ --port=6006\n",
    "logs = train_model(model=model, goal_hidden_dim=5, \n",
    "                                         optimizer=optimizer, loss_func=criterion, epochs=epochs,\n",
    "                                         trainloader=trainloader, testloader=testloader, print_every=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKMAAAGGCAYAAACno0IzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAD6AklEQVR4nOzdd3hUxfoH8O/WbHojIQkkJCBC6EgAQRGQJiBi4UpREBEV0auAXqWIIChcgauxARcEkSsgFkR/ikhHlF6lhB4IhISQQHrbcn5/nD1bsrthEzbZZPP9PA/P7p7MOWc2mp2dd+adkQmCIICIiIiIiIiIiKgayN1dASIiIiIiIiIiqjsYjCIiIiIiIiIiomrDYBQREREREREREVUbBqOIiIiIiIiIiKjaMBhFRERERERERETVhsEoIiIiIiIiIiKqNgxGERERERERERFRtWEwioiIiIiIiIiIqg2DUUREREREREREVG0YjCK3+Pvvv/Hss88iLi4OGo0Gfn5+uOeeezBv3jzcvHmz2uszc+ZMyGQyZGZm3rZsjx490KNHj6qvlB0rVqyATCbDpUuXyi0nvR8iouomfU5J/5RKJSIjIzFs2DCcO3fO3dVzuYULF2LFihVurcPq1auRmJho92cymQwzZ86s1voAzrdXRESuUNP6FhUxevRoxMbGursad4z9D6oopbsrQHXP0qVLMX78eDRr1gz/+te/0KJFC2i1Whw8eBCLFy/Gnj178OOPP7q7mg4tXLjQ3VUgIqrxvvzySzRv3hzFxcX466+/8P7772P79u04ffo0goOD3V09l1m4cCHq1auH0aNHu60Oq1evxokTJzBhwgSbn+3ZswcNGzas/koREVWT2t63mD59Ol577TV3V4Oo2jEYRdVqz549eOmll9CnTx+sX78eXl5epp/16dMHr7/+OjZu3OjGGt5eixYt3F0FIqIar1WrVkhISAAgzijV6/WYMWMG1q9fj2effdbNtXMPrVZrmi1WXe69995quxcRUXWrzX2LwsJC+Pj4oEmTJu6uCpFbME2PqtWcOXMgk8mwZMkSq8ZColar8cgjj5heGwwGzJs3D82bN4eXlxfCw8MxatQoXL161eq8Hj16oFWrVtizZw+6du0Kb29vxMbG4ssvvwQA/Prrr7jnnnvg4+OD1q1bO2yUrly5gscffxwBAQEIDAzE008/jRs3btjcyzJN79KlS5DJZFiwYAE+/PBDxMXFwc/PD126dMHevXtt7nHw4EE88sgjCAkJgUajQfv27fHtt9/alNu7dy/uu+8+aDQaREVFYcqUKdBqtY5/ubfh7O/yyJEjePjhhxEeHg4vLy9ERUVh4MCBVuW+++47dO7cGYGBgfDx8UHjxo0xZsyYSteNiDyfFJi6fv261XFnPxNTU1PxwgsvIDo6Gmq1GlFRURgyZIjV9VJSUvD000+bPr/i4+Pxn//8BwaDwVSmIp/ZFy9exLBhwxAVFQUvLy/Ur18fvXr1wtGjRwEAsbGxOHnyJHbu3GlKS5RSLXbs2AGZTIb//e9/eP3119GgQQN4eXnh/PnzDlMZHKW2rV69Gl26dIGfnx/8/PzQrl07LFu2DIDYJv3666+4fPmyVXqkxF6a3okTJzB48GAEBwdDo9GgXbt2+Oqrr6zKSPVfs2YNpk2bhqioKAQEBKB37944c+aMTd2dtXz5crRt2xYajQYhISF47LHHkJSUZFXmdr93ANi2bRt69OiB0NBQeHt7IyYmBk888QQKCwsrXTciqn2qom8xYcIE+Pr6Ijc31+Z6Q4cORf369U3fydeuXYu+ffsiMjIS3t7eiI+Px+TJk1FQUGB13ujRo+Hn54fjx4+jb9++8Pf3R69evUw/K5um9/nnn+OBBx5AeHg4fH190bp1a8ybN8+mLyD1gQ4cOIBu3bqZvpf/+9//tmr7ACA7Oxuvv/46GjdubHrvAwYMwOnTp01lSktL8d5775l+P2FhYXj22Wdt+kPOYv+DysOZUVRt9Ho9tm3bhg4dOiA6Otqpc1566SUsWbIEr7zyCh5++GFcunQJ06dPx44dO3D48GHUq1fPVDY9PR3PPvss3nzzTTRs2BCffvopxowZgytXruD777/H1KlTERgYiFmzZuHRRx/FxYsXERUVZXW/xx57DE8++STGjRuHkydPYvr06Th16hT27dsHlUpVbl0///xzNG/e3LRux/Tp0zFgwAAkJycjMDAQALB9+3Y89NBD6Ny5MxYvXozAwEB88803GDp0KAoLC01pHqdOnUKvXr0QGxuLFStWwMfHBwsXLsTq1aud/G1X7ndZUFCAPn36IC4uDp9//jnq16+P9PR0bN++HXl5eQDEEaihQ4di6NChmDlzJjQaDS5fvoxt27ZVum5E5PmSk5MBAHfffbfpmLOfiampqejYsSO0Wi2mTp2KNm3aICsrC7///jtu3bqF+vXr48aNG+jatStKS0sxe/ZsxMbG4pdffsEbb7yBCxcu2KRYO/OZPWDAAOj1esybNw8xMTHIzMzE7t27kZ2dDQD48ccfMWTIEAQGBpquX7YzNGXKFHTp0gWLFy+GXC5HeHh4hX5v77zzDmbPno3HH38cr7/+OgIDA3HixAlcvnwZgJgm+MILL+DChQtOpaGcOXMGXbt2RXh4OD755BOEhobi66+/xujRo3H9+nW8+eabVuWnTp2K++67D1988QVyc3Px1ltvYdCgQUhKSoJCoajQe5k7dy6mTp2K4cOHY+7cucjKysLMmTPRpUsXHDhwAE2bNgVw+9/7pUuXMHDgQHTr1g3Lly9HUFAQUlNTsXHjRpSWlsLHx6dC9SKi2qmq+hZjxozBxx9/jG+//RZjx441nZudnY2ffvoJL7/8sqlfcO7cOQwYMMAUwDp9+jQ++OAD7N+/3+a7cWlpKR555BG8+OKLmDx5MnQ6ncN6XrhwASNGjEBcXBzUajWOHTuG999/H6dPn8by5cutyqanp+Opp57C66+/jhkzZuDHH3/ElClTEBUVhVGjRgEA8vLycP/99+PSpUt466230LlzZ+Tn5+OPP/5AWloamjdvDoPBgMGDB2PXrl1488030bVrV1y+fBkzZsxAjx49cPDgQXh7ezv1e67I75v9jzpMIKom6enpAgBh2LBhTpVPSkoSAAjjx4+3Or5v3z4BgDB16lTTse7duwsAhIMHD5qOZWVlCQqFQvD29hZSU1NNx48ePSoAED755BPTsRkzZggAhIkTJ1rda9WqVQIA4euvv7a6V/fu3U2vk5OTBQBC69atBZ1OZzq+f/9+AYCwZs0a07HmzZsL7du3F7RardV9Hn74YSEyMlLQ6/WCIAjC0KFDBW9vbyE9Pd1URqfTCc2bNxcACMnJyeX+7qT3I3H2d3nw4EEBgLB+/XqH116wYIEAQMjOzi63DkRUN3355ZcCAGHv3r2CVqsV8vLyhI0bNwoRERHCAw88YPX55+xn4pgxYwSVSiWcOnXK4X0nT54sABD27dtndfyll14SZDKZcObMGUEQnP/MzszMFAAIiYmJ5b7fli1bWrUJku3btwsAhAceeMDmZ2U/oyXS7076jL948aKgUCiEp556qtw6DBw4UGjUqJHdnwEQZsyYYXo9bNgwwcvLS0hJSbEq179/f8HHx8f02S7Vf8CAAVblvv32WwGAsGfPnnLrVPa93Lp1S/D29ra5XkpKiuDl5SWMGDFCEATnfu/ff/+9AEA4evRouXUgIs9WlX2Le+65R+jatatVuYULFwoAhOPHj9u9vsFgELRarbBz504BgHDs2DHTz5555hkBgLB8+XKb85555hmHn+GCIAh6vV7QarXCypUrBYVCIdy8edP0M6kPVLbta9GihdCvXz/T61mzZgkAhM2bNzu8z5o1awQAwg8//GB1/MCBAwIAYeHChQ7PFQT2P6jimKZHNdb27dsBwGZR2E6dOiE+Ph5bt261Oh4ZGYkOHTqYXoeEhCA8PBzt2rWzmgEVHx8PAKZRZUtPPfWU1esnn3wSSqXSVJfyDBw40GqUuE2bNlb3OX/+PE6fPm26h06nM/0bMGAA0tLSTKkP27dvR69evVC/fn3T9RQKBYYOHXrbetjj7O/yrrvuQnBwMN566y0sXrwYp06dsrlWx44dAYi/m2+//RapqamVqhMRebZ7770XKpUK/v7+eOihhxAcHIyffvrJtF5SRT4Tf/vtN/Ts2dP0+W3Ptm3b0KJFC3Tq1Mnq+OjRoyEIgs3o6e0+s0NCQtCkSRPMnz8fH374IY4cOWKT8uCMJ554osLnSDZv3gy9Xo+XX3650tcoa9u2bejVq5fNLILRo0ejsLAQe/bssTpumd4C2P6enLVnzx4UFRXZtEPR0dF48MEHTe2QM7/3du3aQa1W44UXXsBXX32FixcvVqguRFQ3VaRv8eyzz2L37t1WaclffvklOnbsiFatWpmOXbx4ESNGjEBERAQUCgVUKhW6d+8OADYpyIDzbcKRI0fwyCOPIDQ01HTdUaNGQa/X4+zZs1ZlIyIibNq+Nm3aWH1O//bbb7j77rvRu3dvh/f85ZdfEBQUhEGDBlm1ye3atUNERAR27NjhVN0l7H/Q7TAYRdWmXr168PHxMaVq3E5WVhYAMchUVlRUlOnnkpCQEJtyarXa5rharQYAFBcX25SPiIiweq1UKhEaGmpzL3tCQ0OtXkupGkVFRQDM66S88cYbUKlUVv/Gjx8PAMjMzAQgvveydbFXP2c5+7sMDAzEzp070a5dO0ydOhUtW7ZEVFQUZsyYYcpRf+CBB7B+/XrodDqMGjUKDRs2RKtWrbBmzZpK1Y2IPNPKlStx4MABbNu2DS+++CKSkpIwfPhw088r8pl448aN2+4Il5WV5fAzTvq5pdt9ZstkMmzduhX9+vXDvHnzcM899yAsLAyvvvqqKW3AGfbq5CxpjQ5X7obn6t9TRe4L3L4dcub33qRJE2zZsgXh4eF4+eWX0aRJEzRp0gQff/xxhepERLVbVfYtnnrqKXh5eWHFihUAxCU0Dhw4YLUBR35+Prp164Z9+/bhvffew44dO3DgwAGsW7cOgO3npI+PDwICAm5bz5SUFHTr1g2pqan4+OOPsWvXLhw4cACff/653euW/ZwGxM9qy3LOtKPXr19HdnY21Gq1Tbucnp5uapOdxf4H3Q7XjKJqo1Ao0KtXL/z222+4evXqbT8QpQ/WtLQ0m7LXrl2zWi/KVdLT09GgQQPTa51Oh6ysLLsf8hUl1XfKlCl4/PHH7ZZp1qwZAPG9p6en261fZVTkd9m6dWt88803EAQBf//9N1asWIFZs2bB29sbkydPBgAMHjwYgwcPRklJCfbu3Yu5c+dixIgRiI2NRZcuXSpVRyLyLPHx8aZFy3v27Am9Xo8vvvgC33//PYYMGVKhz8SwsDCbxU7LCg0NRVpams3xa9euAUCl2oxGjRqZFgo/e/Ysvv32W8ycOROlpaVYvHixU9ewt1C5RqMBAJSUlFitMVX2i35YWBgA4OrVq06vh3I7VfF7cva+ABze2/K+zvzeu3Xrhm7dukGv1+PgwYP49NNPMWHCBNSvXx/Dhg2rkvdARDVLVfYtgoODMXjwYKxcuRLvvfcevvzyS2g0GqtBlW3btuHatWvYsWOHaTYUANP6dmXZaw/sWb9+PQoKCrBu3To0atTIdNxyE4eKcqYdrVevHkJDQx1u9OTv71+he7L/QbfDmVFUraZMmQJBEPD888+jtLTU5udarRb/93//BwB48MEHAQBff/21VZkDBw4gKSnJtAOFK61atcrq9bfffgudTme1e15lNWvWDE2bNsWxY8eQkJBg95/0Id+zZ09s3brVapcovV6PtWvXVurelfldymQytG3bFh999BGCgoJw+PBhmzJeXl7o3r07PvjgAwDilGIiInvmzZuH4OBgvPPOOzAYDBX6TOzfvz+2b99e7i5uvXr1wqlTp2w+q1auXAmZTIaePXveUf3vvvtuvP3222jdurXVPcqOPjtD2jXp77//tjoutX+Svn37QqFQYNGiReVeryJ16NWrl6kDZWnlypXw8fHBvffe69R1KqpLly7w9va2aYeuXr1qSh20x9HvXaJQKNC5c2fTjAF7ZYjIc1Vl3+LZZ5/FtWvXsGHDBnz99dd47LHHEBQUZPq5FFwqu3HFf//73zt6T/auKwgCli5dWulr9u/fH2fPni13we+HH34YWVlZ0Ov1dttkaYDIWex/0O1wZhRVqy5dumDRokUYP348OnTogJdeegktW7aEVqvFkSNHsGTJErRq1QqDBg1Cs2bN8MILL+DTTz+FXC5H//79TTswREdHY+LEiS6v37p166BUKtGnTx/Tbnpt27bFk08+6ZLr//e//0X//v3Rr18/jB49Gg0aNMDNmzeRlJSEw4cP47vvvgMAvP322/j555/x4IMP4p133oGPjw8+//xzm21ineXs7/KXX37BwoUL8eijj6Jx48YQBAHr1q1DdnY2+vTpA0Dc2enq1avo1asXGjZsiOzsbHz88cdWOfJERGUFBwdjypQpePPNN7F69Wo8/fTTTn8mzpo1C7/99hseeOABTJ06Fa1bt0Z2djY2btyISZMmoXnz5pg4cSJWrlyJgQMHYtasWWjUqBF+/fVXLFy4EC+99JLVLn7O+Pvvv/HKK6/gH//4B5o2bQq1Wo1t27bh77//No3SAubR3LVr16Jx48bQaDRo3bp1udceMGAAQkJC8Nxzz2HWrFlQKpVYsWIFrly5YlUuNjYWU6dOxezZs1FUVIThw4cjMDAQp06dQmZmJt59911THdatW4dFixahQ4cOkMvlpllpZc2YMQO//PILevbsiXfeeQchISFYtWoVfv31V8ybN8+0k6CrBQUFYfr06Zg6dSpGjRqF4cOHIysrC++++y40Gg1mzJgBwLnf++LFi7Ft2zYMHDgQMTExKC4uNu0uVd56KETkeaqyb9G3b180bNgQ48ePN+3abalr164IDg7GuHHjMGPGDKhUKqxatQrHjh27o/fUp08fqNVqDB8+HG+++SaKi4uxaNEi3Lp1q9LXnDBhAtauXYvBgwdj8uTJ6NSpE4qKirBz5048/PDD6NmzJ4YNG4ZVq1ZhwIABeO2119CpUyeoVCpcvXoV27dvx+DBg/HYY485fU/2P+i23Ld2OtVlR48eFZ555hkhJiZGUKvVgq+vr9C+fXvhnXfeETIyMkzl9Hq98MEHHwh33323oFKphHr16glPP/20cOXKFavrde/eXWjZsqXNfRo1aiQMHDjQ5jgA4eWXXza9lnZ/OHTokDBo0CDBz89P8Pf3F4YPHy5cv37d5l72dtObP3++3ftY7mIkCIJw7Ngx4cknnxTCw8MFlUolRERECA8++KCwePFiq3J//fWXcO+99wpeXl5CRESE8K9//UtYsmRJpXbTEwTnfpenT58Whg8fLjRp0kTw9vYWAgMDhU6dOgkrVqwwlfnll1+E/v37Cw0aNBDUarUQHh4uDBgwQNi1a1e5dSKiukHaRe3AgQM2PysqKhJiYmKEpk2bmnayc/Yz8cqVK8KYMWOEiIgIQaVSCVFRUcKTTz5p9Rl9+fJlYcSIEUJoaKigUqmEZs2aCfPnzzftyicIzn9mX79+XRg9erTQvHlzwdfXV/Dz8xPatGkjfPTRR1a78F26dEno27ev4O/vLwAw7Ygk7Ub33Xff2f097d+/X+jatavg6+srNGjQQJgxY4bwxRdf2P2MX7lypdCxY0dBo9EIfn5+Qvv27YUvv/zS9PObN28KQ4YMEYKCggSZTGb1+W+vHTp+/LgwaNAgITAwUFCr1ULbtm2trlde/aXfX9nyZZXdTU/yxRdfCG3atBHUarUQGBgoDB48WDh58qTp58783vfs2SM89thjQqNGjQQvLy8hNDRU6N69u/Dzzz+XWyci8lyu7ltIpk6dKgAQoqOjrdoSye7du4UuXboIPj4+QlhYmDB27Fjh8OHDNp+TzzzzjODr62v3HvZ20/u///s/oW3btoJGoxEaNGgg/Otf/xJ+++03AYCwfft2UzlHfSB717x165bw2muvCTExMYJKpRLCw8OFgQMHCqdPnzaV0Wq1woIFC0z39vPzE5o3by68+OKLwrlz5+zWX8L+B1WUTBAEoVqjX0REREREREREVGdxzSgiIiIiIiIiIqo2DEYREREREREREVG1YTCKiIiIiIiIiIiqDYNRRERERERERERUbRiMIiIiIiIiIiKiasNgFBERERERERERVRuluyvgKgaDAdeuXYO/vz9kMpm7q0NEVOMIgoC8vDxERUVBLudYBNsNIqLysd2wxnaDiKh8FWk3PCYYde3aNURHR7u7GkRENd6VK1fQsGFDd1fD7dhuEBE5h+2GiO0GEZFznGk3PCYY5e/vD0B80wEBAW6uDRFRzZObm4vo6GjT52Vdx3aDiKh8bDessd0gIipfRdoNjwlGSVNlAwIC2DgQEZWDqQUithtERM5huyFiu0FE5Bxn2g0mfxMRERERERERUbVhMIqIiIiIiIiIiKoNg1FERERERERERFRtPGbNKGcYDAaUlpa6uxrkIiqVCgqFwt3VICIiqlP0ej20Wq27q0EuwO9Srsf+hmdRq9W33Z6eiCqnzgSjSktLkZycDIPB4O6qkAsFBQUhIiKCC2sSERFVMUEQkJ6ejuzsbHdXhVyI36Vch/0NzyOXyxEXFwe1Wu3uqhB5nDoRjBIEAWlpaVAoFIiOjmZ02wMIgoDCwkJkZGQAACIjI91cIyIiIs8mBaLCw8Ph4+PD4EUtx+9SrsX+hucxGAy4du0a0tLSEBMTw888IherE8EonU6HwsJCREVFwcfHx93VIRfx9vYGAGRkZCA8PJzTzIncZOHChZg/fz7S0tLQsmVLJCYmolu3bg7L79y5E5MmTcLJkycRFRWFN998E+PGjTP9fOnSpVi5ciVOnDgBAOjQoQPmzJmDTp06mcrMnDkT7777rtV169evj/T0dBe/OyICxNQ8KRAVGhrq7uqQi/C7lOuwv+GZwsLCcO3aNeh0OqhUKndXh8ij1ImQvV6vBwBOr/RAUmPPtSuI3GPt2rWYMGECpk2bhiNHjqBbt27o378/UlJS7JZPTk7GgAED0K1bNxw5cgRTp07Fq6++ih9++MFUZseOHRg+fDi2b9+OPXv2ICYmBn379kVqaqrVtVq2bIm0tDTTv+PHj1fpeyWqy6R2lp1sz8PvUq7B/oZnkv57Sv99ich16sTMKAmnVnoe/jclcq8PP/wQzz33HMaOHQsASExMxO+//45FixZh7ty5NuUXL16MmJgYJCYmAgDi4+Nx8OBBLFiwAE888QQAYNWqVVbnLF26FN9//z22bt2KUaNGmY4rlUpERERU0TsjInvY7noe/jd1Lf4+PQv/exJVnUrNjFq4cCHi4uKg0WjQoUMH7Nq1y2HZtLQ0jBgxAs2aNYNcLseECRPslsvOzsbLL7+MyMhIaDQaxMfHY8OGDZWpHhERVYPS0lIcOnQIffv2tTret29f7N692+45e/bssSnfr18/HDx40OGofGFhIbRaLUJCQqyOnzt3DlFRUYiLi8OwYcNw8eLFcutbUlKC3Nxcq39ERERERFT9KhyMqmhKRklJCcLCwjBt2jS0bdvWbpnS0lL06dMHly5dwvfff48zZ85g6dKlaNCgQUWrR7fRo0cPhwFBIqKKyMzMhF6vR/369a2Ol7d2U3p6ut3yOp0OmZmZds+ZPHkyGjRogN69e5uOde7cGStXrsTvv/+OpUuXIj09HV27dkVWVpbD+s6dOxeBgYGmf9HR0c6+VSIiK/w+ReQY/z6IyBkVDkZZpmTEx8cjMTER0dHRWLRokd3ysbGx+PjjjzFq1CgEBgbaLbN8+XLcvHkT69evx3333YdGjRrh/vvvdxi8qgtkMlm5/0aPHl2p665btw6zZ892bWWJyNapn4GlDwJZF9xdkypXdgq7IAjlTmu3V97ecQCYN28e1qxZg3Xr1kGj0ZiO9+/fH0888QRat26N3r1749dffwUAfPXVVw7vO2XKFOTk5Jj+Xbly5fZvzo7fT6bj3jlbMX7VoUqdT0TVh9+niBzj3wdRLXd4JfBFHyA/w901qZQKrRklpWRMnjzZ6nh5KRnO+Pnnn9GlSxe8/PLL+OmnnxAWFoYRI0bgrbfeqrO7eqSlpZmer127Fu+88w7OnDljOibtfiLRarVO7fBQNs2FiKrI0VVA6iHg/BYgtIm7a1Ml6tWrB4VCYTMLKiMjw2b2kyQiIsJueaVSabND14IFCzBnzhxs2bIFbdq0Kbcuvr6+aN26Nc6dO+ewjJeXF7y8vMq9jjO0egPSc4uRmV96x9cioqrF71NEjvHvg6iWO/QVkHoQuLQLaPWEu2tTYRWaGVWZlAxnXLx4Ed9//z30ej02bNiAt99+G//5z3/w/vvvOzzH09f+iIiIMP0LDAyETCYzvS4uLkZQUBC+/fZb9OjRAxqNBl9//TWysrIwfPhwNGzYED4+PmjdujXWrFljdd2y02ZjY2MxZ84cjBkzBv7+/oiJicGSJUuq+d0SeaCiW+KjttC99ahCarUaHTp0wObNm62Ob968GV27drV7TpcuXWzKb9q0CQkJCVZfcOfPn4/Zs2dj48aNSEhIuG1dSkpKkJSUhMjIyEq8k4pRKcSmU6c3VPm9iOjO8PtU3fHHH39g0KBBiIqKgkwmw/r16x2WffHFFyGTyUybadRV/PsgquVM/Y0i99ajkiq1gHlFUzJux2AwIDw8HEuWLEGHDh0wbNgwTJs2zWHqH3Bna38IgoDCUp1b/knpKK7w1ltv4dVXX0VSUhL69euH4uJidOjQAb/88gtOnDiBF154ASNHjsS+ffvKvc5//vMfJCQk4MiRIxg/fjxeeuklnD592mX1JKqTirLFR22xW6tR1SZNmoQvvvgCy5cvR1JSEiZOnIiUlBSMGzcOgJgaZ7kD3rhx43D58mVMmjQJSUlJWL58OZYtW4Y33njDVGbevHl4++23sXz5csTGxiI9PR3p6enIz883lXnjjTewc+dOJCcnY9++fRgyZAhyc3PxzDPPVPl7VinE9k6rd93nOVFtxO9T1vh9yr0KCgrQtm1bfPbZZ+WWW79+Pfbt24eoqKgqrQ//Pqzx74OoCtTyYFSF0vQqk5LhjMjISKhUKquUvPj4eKSnp6O0tBRqtdrmnClTpmDSpEmm17m5uU4HpIq0erR45/dK1/dOnJrVDz7qCv3aHZowYQIef/xxq2OWHbp//vOf2LhxI7777jt07tzZ4XUGDBiA8ePHAxAbnI8++gg7duxA8+bNXVJPojpJahx0tbNxcNbQoUORlZWFWbNmIS0tDa1atcKGDRvQqFEjAGIKgOUGF3FxcdiwYQMmTpyIzz//HFFRUfjkk0/wxBPmqcULFy5EaWkphgwZYnWvGTNmYObMmQCAq1evYvjw4cjMzERYWBjuvfde7N2713TfqiTNjNJyZhTVcfw+ZY3fp9yrf//+6N+/f7llUlNT8corr+D333/HwIEDq7Q+/Puwxr8PIhczGIDibPG5rnYOflfoU8oyJeOxxx4zHd+8eTMGDx5c6Urcd999WL16NQwGA+Ry8Uv+2bNnERkZaTcQBbhu7Y/arGzqil6vx7///W+sXbsWqampKCkpQUlJCXx9fcu9juVaLNL03IyM2rkIGlGNIAjmxsHDZ0YBwPjx401fMMtasWKFzbHu3bvj8OHDDq936dKl297zm2++cbZ6LsdgFJFn4fepusFgMGDkyJH417/+hZYtWzp1jvTfXuJpy4I4g38fRDVUaR4gGL+L1oWZUYCYkjFy5EgkJCSgS5cuWLJkiU1KRmpqKlauXGk65+jRowCA/Px83LhxA0ePHoVarUaLFi0AAC+99BI+/fRTvPbaa/jnP/+Jc+fOYc6cOXj11Vdd8BZteasUODWrX5Vc25l7u0rZD/3//Oc/+Oijj5CYmIjWrVvD19cXEyZMQGlp+Yvsll2IUCaTwWBgJ4uo0rSFgN74d+fhM6PqIqbpEYn4fcoav0/VbB988AGUSmWF+hdz587Fu+++W6n78e/DGv8+iFxMysIA6k4wqqIpGQDQvn170/NDhw5h9erVaNSokWn0Ozo6Gps2bcLEiRPRpk0bNGjQAK+99hreeuutO3hrjslkMpdNXa1Jdu3ahcGDB+Ppp58GII4AnTt3DvHx8W6uGVEdI60XBdSJmVF1DRcwJxLx+xTVFocOHcLHH3+Mw4cPV2id2ztZFoR/H0RUpSz7G3UhTU9S0ZQMZxbR69KlC/bu3VuZ6pDRXXfdhR9++AG7d+9GcHAwPvzwQ6Snp7NxIKpuViMVnrubXl2lNKaTl3JmFJFH4vcpz7Nr1y5kZGQgJibGdEyv1+P1119HYmKiw/RwLgtii38fRDWEB/Q3PC9cX4dNnz4dycnJ6NevH3x8fPDCCy/g0UcfRU5OjrurRlS3SOtFAbV2pIIcUyulND3OjCLyRPw+5XlGjhyJ3r17Wx3r168fRo4ciWeffdZNtaqd+PdBVENYBaNqZ3+DwahaYPTo0Rg9erTpdWxsrN3ZZiEhIVi/fn2519qxY4fVa3sjQdIaX0RUSR7QOJBjTNMjqp34fcqz5efn4/z586bXycnJOHr0KEJCQhATE4PQ0FCr8iqVChEREWjWrFl1V7VG4t8HUS1j2d+opWvUMhhFRFSewpuAlz+gUN2+rMQqh7t2Ng7kmNK0mx7T9IiIaoqDBw+iZ8+eptfSWk/PPPOM3WVEiIhqDEEAKrCeHQDrTIxaOvjNYBQRkSN514GP2wCN7gNGrnP+PM6M8mim3fQMBgiCUKHFcImIqGr06NHDqXVqJY7WiSIiqlY5qcCS7kD7p4HeM50/zwPWjJK7uwJERDXWjSRxzafrJyt2ntWaUZwZ5WnUxplRggDoDZwdRURERESVdGUfUHADOLelYudZpenVzsFvBqOIiBwpzBIftRUMKFmm6VX0XKrxpDQ9gKl6RERERHQHTP2NCs5usupvMBhFRORZCm+KjxVuHCynzTIY5WmkND1ATNUjIiIiIqoUqb9R0dlNVsEopukREXkWaaTCoAX0OufPs0rTq50jFeSYSm4xM0rHYBQRERERVVKlZ0YxTY+IyHNJIxVAxdZ+Kts4VGBBVar55HIZFHLjIuZM0yMiIiKiyqr0siC1PxODwSgiIkekxgGo2Ie85bRZoNaOVpBjph319JwZRURERESVJPU3dMVARZZ/sMzEYDCKiMjDVDoYdcv6dS1tIMgxKVWPwSgiIiIiqrTCTPNzZzMxtMXWaX26olqZicFglAfr0aMHJkyYYHodGxuLxMTEcs+RyWRYv379Hd/bVdchcqmSPGDdi8DZ350rX5lglMEAFOdYH+PMKI+jUorNp85Q+xp+IqoYfp8icox/H0R2lOQ7X9ZyWRBn+xuWs6IkuhLn71lDMBhVQw0aNAi9e/e2+7M9e/ZAJpPh8OHDFbrmgQMH8MILL7iieiYzZ85Eu3btbI6npaWhf//+Lr0X0R27sA34+xtg14fOlbdqHJxcVLAkB4AxQKHwMp7LmVGeRkrTK+UC5kQ1Gr9PETnGvw+iKpCyF/h3DLBz3u3LCkLlBr+lLAyvAPOxiqxvW0MwGFVDPffcc9i2bRsuX75s87Ply5ejXbt2uOeeeyp0zbCwMPj4+LiqiuWKiIiAl5dXtdyLyGnFucbHbOfKWzYOzs5uktaLUvkAGmMDwWCUx1EyTY+oVuD3KSLH+PdBVAVSDwOCHriy7/ZltYXWfQyng1HZ4qNvPUCurNi5NQiDUTXUww8/jPDwcKxYscLqeGFhIdauXYtHH30Uw4cPR8OGDeHj44PWrVtjzZo15V6z7LTZc+fO4YEHHoBGo0GLFi2wefNmm3Peeust3H333fDx8UHjxo0xffp0aLVaAMCKFSvw7rvv4tixY5DJZJDJZKb6lp02e/z4cTz44IPw9vZGaGgoXnjhBeTnm6cvjh49Go8++igWLFiAyMhIhIaG4uWXXzbdi8glSgvERykoVW7ZQusRBmdnRkkjFZogQOktPmeansdRM02PqFbg9yl+nyLH+PfBvw+qAhXpb1gOfAMV7294B5v7G7UwGKV0dwXcQhCc/w/taiofQCa7bTGlUolRo0ZhxYoVeOeddyAznvPdd9+htLQUY8eOxZo1a/DWW28hICAAv/76K0aOHInGjRujc+fOt72+wWDA448/jnr16mHv3r3Izc21yveW+Pv7Y8WKFYiKisLx48fx/PPPw9/fH2+++SaGDh2KEydOYOPGjdiyZQsAIDAw0OYahYWFeOihh3DvvffiwIEDyMjIwNixY/HKK69YNX7bt29HZGQktm/fjvPnz2Po0KFo164dnn/++du+HyKnlBq/kJQ40TgU3bR+XdEcbu9gwKCt2LlUayjlxt30mKZHdRm/T/H7FDnGvw/+fVDdVJH+hk0wqoJpet7BgEoDlObVysHvuhmM0hYCc6Lcc++p1wC1r1NFx4wZg/nz52PHjh3o2bMnAHHK7OOPP44GDRrgjTfeMJX95z//iY0bN+K7775zqnHYsmULkpKScOnSJTRs2BAAMGfOHJu867ffftv0PDY2Fq+//jrWrl2LN998E97e3vDz84NSqURERITDe61atQpFRUVYuXIlfH3F9/7ZZ59h0KBB+OCDD1C/fn0AQHBwMD777DMoFAo0b94cAwcOxNatW9k4kOtIIxWl+YBBD8gVjsvaNA7OpulJjUOQuTGqhY0DlU+lMKbpcWYU1WX8PsXvU+QY/z7490F1k/T9v7pmRqk4M4qqQPPmzdG1a1csX74cPXv2xIULF7Br1y5s2rQJer0e//73v7F27VqkpqaipKQEJSUlpg/f20lKSkJMTIypYQCALl262JT7/vvvkZiYiPPnzyM/Px86nQ4BAQE25W53r7Zt21rV7b777oPBYMCZM2dMjUPLli2hUJiDA5GRkTh+/HiF7kVUrlKLnS1K8sSAkSOVbhyyxUfvYDHgBdTKxoHKJ+2mx5lRRDUfv0/x+xQ5xr8P/n2Qi0mD307NjLrDTAzLZUFqYX+jbgajVD7iiIG77l0Bzz33HF555RV8/vnn+PLLL9GoUSP06tUL8+fPx0cffYTExES0bt0avr6+mDBhAkpLS526riDYjubLykzn3bt3L4YNG4Z3330X/fr1Q2BgIL755hv85z//qdB7EATB5tr27qlSqWx+ZjCwo0cuJDUOgNhAlBuMqmTjYLlmlBT8qoWNA5VPJaXpcQFzqsv4fYrfp8gx/n3w74PqJun7f2UyMZzeMKlMml5Fzq1B6mYwSiZzeuqquz355JN47bXXsHr1anz11Vd4/vnnIZPJsGvXLgwePBhPP/00ADEn+9y5c4iPj3fqui1atEBKSgquXbuGqChxCvGePXusyvz1119o1KgRpk2bZjpWdrcNtVoNvV5/23t99dVXKCgoMI1W/PXXX5DL5bj77rudqi+RS1jOjLrd1FmbxqGia0YFma9RC7dapfIxTY8I/D4Ffp+icvDvg38fVDfZDH4HOy5bxxcw5256NZyfnx+GDh2KqVOn4tq1axg9ejQA4K677sLmzZuxe/duJCUl4cUXX0R6errT1+3duzeaNWuGUaNG4dixY9i1a5dVIyDdIyUlBd988w0uXLiATz75BD/++KNVmdjYWCQnJ+Po0aPIzMxESUmJzb2eeuopaDQaPPPMMzhx4gS2b9+Of/7znxg5cqRpyixRtbBqHPLKL3unM6O8g8wjFc6uN0W1BtP0iGoXfp8icox/H0QuVHIHg99O9zeyxcdavmYUg1G1wHPPPYdbt26hd+/eiImJAQBMnz4d99xzD/r164cePXogIiICjz76qNPXlMvl+PHHH1FSUoJOnTph7NixeP/9963KDB48GBMnTsQrr7yCdu3aYffu3Zg+fbpVmSeeeAIPPfQQevbsibCwMLvbvfr4+OD333/HzZs30bFjRwwZMgS9evXCZ599VvFfBtGdKDtSUR5XrBkljVRwZpTHYZoeUe3D71NEjvHvg8hFqqW/YWcB81rY35AJ9pJ5a6Hc3FwEBgYiJyfHZsG74uJiJCcnIy4uDhqNxk01pKrA/7ZUIYvvB9KNi1Q+/gXQ5h+Oy373LHByHeAVCJTkAB2fBwYuuP09vhwIXP4TeGIZcPkv4OByoPtkoOcU17yHO1De52RddCe/j3H/O4SNJ9Mx+9FWGHlvoyqqIVHNwfbWc5X335bthjX2N+oe/nelCktsA2QbU01HbwBi73NcdsXDwKVdYlCp6BbQ/S2g59Tb3+PjdsCtZGDM78C+/4p9loc+AO4d55K3cCcq0m5wZhQR1R2W02ZLcsovK41UBDYQHyu6u4V3sHkB0Vo4UkHlUyqMM6OYpkdEREREEqvdu52cGRVg3HHyTmZGOXtuDcJgFBF5hM+3n8es/zuF/BKd40KVWTMqsLKNQxCglNaMYjDK06iNC5jruAMPEREREUks+xvOrhll6m84sc6swQAUGwfVrdL0at8atQxGEVGtp9MbcGzLKqTvWYNHP/8L5zMcBJrupHGw9wGfkwpcP2V9zGpBQQajPJVpNz29R2S6ExEREdGd0uus+wzlzYwSBDvBKDt9hj8/AnZ8YHHNHADG75+aoMoNfhv0wLb3gNMbnD+nCijdenciIhfQanX4RPkplNCjXUYbPPLZX7jvrnpoERmA2Ho+CPPToEGQF+K09hcUzCnSIkCjhEwmpl4JBgNQmAUZAARIaXp2ZkZ9NQjIuQJMPAX4hQG6UkC6hybIYgHzCoxUlOQDy/oCoU2Aof9z/jyqVlKaXinT9IiIiIgIsE7RA8wzmOwpzgEMxoyOQAf9jdICYMtM8XnHsYBvqDkLQ+ULKNWV203v/Bbgj/liemDzAc6f52IMRhFRrVdaWoxAmRYA0LOhHP93VY/Np65j86nrpjI+KMYpi3UnU69n4Nc/LmDd4VScTs9DXD1f/CNBHJX45eB5bNCL2wZP23YL7wNIz7yFk0nXkZSWi7PX8xEXosbEmxcAADmpSbjsq8KWA8cxCYABMqw+egtPyrygBqwaB0EQUKw1IK9Yi2s5xbh6qxBB3mp0bRIKuVwGXPoTyDgp/tOVAEovm/dbotPDS6lw6e+QKkbFND0iIiKiumXLTMCnHtD1Ffs/t8zCAEyD33nFWhxPzUHLyEAE+qgAAOcvX8ZdAHQKb5y5pURLAIK2EDKIg50pNwvRUJYJU/cl7xrgG4oLyZfQBECeIgC6glIE32Y3vaJSPa7lFCHER41gX7V4MPkP8TE31WF/QxAE00B9ValTwSgP2TiQLBjYESQAem2p6Xnio3EYqY3FidQcJKXl4lpOEW7klSA/y3qa7Knkq5hz9rTpdXJmAeZtPAMAaIAbgAYoEVS4qvUF1EBWdjae++qgqXwocjDR2DpM/moLfjPkoaUsGZO8gCwhAG//fBon1ecxVw78kXQFY9/+DYCYUmiw81F0V7gfRnSKQeuTP6Gj8di2/YfRuUNH+HqJH9XnM/Kx7M+L2HwqAzv+1QN+XjXjI3zhwoWYP38+0tLS0LJlSyQmJqJbt24Oy+/cuROTJk3CyZMnERUVhTfffBPjxpl3/1i6dClWrlyJEydOAAA6dOiAOXPmoFOnTnavN3fuXEydOhWvvfYaEhMTXfreHFFJC5gzTY/qGLa7nof/TV2L/Q3Pwv+eZJKfAfz5EQxQ4LnTHZCcVQy5XAa1Qg6dQUBRqR53ya/hK4tTLqWm44v1x/Hj4VQUlOqhUshw/131kJFXAnXaIfzoBaTrfPHfPWn4RA0cPHcN73/+F06l5aJUZ0BbRTJ+EmNX+OynXfitJBsx6TuwSA2cKfTH0//eijkRWXgcwMHzafjif4dQqjcgv1iHm4WlyMovwa1CccBepZBhUJsoPNq+AVqd3IoQAICAs2dPo2l8G1PgKSWrEF/tuYS9F7Pw8yv3QyGvuoBUzejJVDGVSgWZTIYbN24gLCysyiN8VPUEQUBpaSlu3LgBuVwOtVrt7iqRG2ktglGKkmx0ahKCTnEhVmWK088Ci82vozSl6BIdiofbRqJns3D8eS4TPx5JhUwGPBunAP4EVP718G7PBOD/gBC1AU2D/BAfGYC76/vh5uUTgHHX1vqyW/DzUmJgFIA0QB4QhWi9N3Kz1YAaUAulNulcMhlQ31+DBsHeOJueh/MZ+Zj1yyn8n3q3aTW/L375A8//cgsRARrU9zHg8LViQEwexOZT6XisfUNX/yorbO3atZgwYQIWLlyI++67D//973/Rv39/nDp1CjExMTblk5OTMWDAADz//PP4+uuv8ddff2H8+PEICwvDE088AQDYsWMHhg8fjq5du0Kj0WDevHno27cvTp48iQYNGlhd78CBA1iyZAnatGlTLe9XIs2MYpoe1RVqtRpyuRzXrl1DWFgY1Go1v0/Vcvwu5Vrsb3geQRBw48YNyGQyqFQqd1eH3KygIB++AOTQ4/DZFOTAz6ZMqOwmYDHJ6O8LKfhamwIACPJRIbtQi+1nbgAA+irFlL5SdTAiAoKAPECmL8bRK9kAALVSjkCDeTA9JeUiTuoboYtKTNMr0oSjONeAg9eK8bgKyMrOwcYb6Xbr7q1SoEirx7ojqdh65AyOeJ2WuhR49+vfcNo7A/cEZGN63mx8VtQP3+p7AAB2nbuBHs3CK/kbu706EYxSKBRo2LAhrl69ikuXLrm7OuRCPj4+iImJgVzOtfjrMp1FMMpRbrZGsJ662jJEhjUv3Gt6/WTHaDzZMVp8cX4L8Ccg962H2Ih6AIBIHwGbJ3U3X+DyDeBL8ek73UMws28/4GAq8AsQGhmL7UN74MahbGAD0D5Sg93DHwQAKOQy+Hop4aNSiGl5EKfurtmfgn2nLqBl+mXTLdr65WJ3rgBFziV8XTQZP6rux86mU/HCA43RoVFwZX5VLvfhhx/iueeew9ixYwEAiYmJ+P3337Fo0SLMnTvXpvzixYsRExNjmsEUHx+PgwcPYsGCBaZg1KpVq6zOWbp0Kb7//nts3boVo0aNMh3Pz8/HU089haVLl+K9996rondoH9P0qK6Ry+WIi4tDWloarl275u7qkAvxu5RrsL/hmWQyGRo2bAiFgssj1HV5hUXwNT6f0ScKUXEtIIM4S14hl0GjkkN+WQ9sNZ8T7aPDoNgoDO8YjS5NQnHhRj42n8qAn0aJx2WZwG9A45gYTO1yD/A10DxUgY+7t0PrBoGIq+eLm3szgd/Fa42IV6FzfFsMSP8LOADc37411tx9L/L2nQXOAi3DVJjdqRW8FHJ4qxUI9VUjxE+NyEBvBGiUOHY1B1/+lQzv8xsg15ln/MUpb+KvglLEFG9HjOoyHpP/ifQm/8CY+2LxQNOwKv2dVioYVZGUjLS0NLz++us4dOgQzp07h1dffbXcNIpvvvkGw4cPx+DBg7F+/frKVM8uPz8/NG3aFFqt1mXXJPdSKBRQKpUceSLotCXmF9JudmU5yOG2q/Cm+OgTAqh8xOdlFxSUdr8AIM83jkLkpomPAZFQKuSIDBUDRl5CCaKCvB3ezl+jwgsPNMEL4WeAb8yNw5v3+uCZDr1QvP9L+PxVgn+EJuOpUQmO613NSktLcejQIUyePNnqeN++fbF792675+zZswd9+/a1OtavXz8sW7YMWq3W7shjYWEhtFotQkKsZ7u9/PLLGDhwIHr37u2GYJQxTU/H6ftUd6jVasTExECn00Gv17u7OuQC/C7lWuxveB6VSsVAFAGwXhbk8eY+QINQ20JF1t9j24fL8enw9qbXd4X7465wf/HFX8YBdJ9QU3/DT67F4HbmLIBQmXlB9HZBxWjXoSHwQwYAQBYQhS5NQoHiOOAs0NBPhpH3NnJY/3bRQfh4WHtgwxpgv/n4zG5+eDL+PoRs+wm4CNwTpsfKMfaXxnC1CgejKpqSUVJSgrCwMEybNg0fffRRude+fPky3njjjXLXGrkTCoWCHyZEHsigt/jSV5xtv5AUjFJqxN3tyg1GGQNNPqGAyrgwVNkd8SyCUZCCUXnG2QL+keJjRXe3uLRLfJQpAEEPWc5VRARqAEG8rrr4pnPXqSaZmZnQ6/WoX7++1fH69esjPd3+NOH09HS75XU6HTIzMxEZGWlzzuTJk9GgQQP07t3bdOybb77B4cOHceDAAafrW1JSgpISc+AyN7ec/wduQ5oZpeXMKKpjpHQVpqwQ2cf+BpFncmrwu8QYPDJ+l0exs/0NB30Gy/5GXtnB7yjx8TYLmNuQFi+Pag9cOwJlXiraNAwC9KkAAK+S6utvVHg+rmVKRnx8PBITExEdHY1FixbZLR8bG4uPP/4Yo0aNQmBgoMPr6vV6PPXUU3j33XfRuHHjilaLiOowqzQ9hzOjjI2DFCgqzgUcLUrpaGaUZflCiw9qqXGQHqV7KMsEskoLgZvJjt+IFIxq2kd8zLkiPmZdMNY5G9DXvNHWsiPqt9t9w155e8cBYN68eVizZg3WrVsHjUb8fV65cgWvvfYavv76a9MxZ8ydOxeBgYGmf9HR0U6fW5YpGMUFzImIiIg8nt5qWZBs+4VM/Y0I8dHpwe/bZ2IgzxiEKjv4LfU3pEDWxqnAsn72B8PzbwA3ksTnbUeIj9nimlbIOme+ZzUNtlYoGCWlZJRNsSgvJcNZs2bNQlhYGJ577rk7ug4R1T16y+nwDtaMMs2MkkYRBL3jGUv2RioA69lR9hoHizQ9ALajHN89A3zSHrhxxs49bwLp4u5xaDtcfDQFo85Zl6sh6tWrB4VCYTMLKiMjw2b2kyQiIsJueaVSidBQ6+nOCxYswJw5c7Bp0yarBcoPHTqEjIwMdOjQAUqlEkqlEjt37sQnn3wCpVLpMH1oypQpyMnJMf27cuVKZd42AMs0Pc6MIiKqCf744w8MGjQIUVFRkMlkVst9aLVavPXWW2jdujV8fX0RFRWFUaNGcf0zInKaXmc5+H3LfiGpv2E5+O2I1eC3kzOjBOH2/Y1DK4Are4ErFrl4Emngu35rcWYUIPY3inOB/Ovia8Hg+P25WIWCUZVJyXDGX3/9hWXLlmHp0qVOn1NSUoLc3Fyrf0RUN1k1Do5GKqRps75hgMz40edotEL6MPYNA5QWwSjLBsIyKFScI/7MNFJRdtqsMYiVdgyAAKTssb3n5d3iz+o1Axp0EI/lpAK6UuvZVIWZ9uvsBmq1Gh06dMDmzZutjm/evBldu3a1e06XLl1sym/atAkJCQlWaT/z58/H7NmzsXHjRiQkWK+T1atXLxw/fhxHjx41/UtISMBTTz2Fo0ePOkyP8PLyQkBAgNW/yuIC5kRENUtBQQHatm2Lzz77zOZnhYWFOHz4MKZPn47Dhw9j3bp1OHv2LB555BE31JSIaiPrYFS2/ULSzCgpUFSaBxgcrLEoDWb7hZv7G7pi61lJlv2N/Oviaykdr+yyILpioCQP0BoDYhlJtvc8b1xdPa4bEGTMEMhNtS1bTf2NSi1gXtGUjPLk5eXh6aefxtKlS1GvXj2nz5s7dy7efffdSt2TiDxLhRoHLz/Ay18MIBXnmqfRWso1BpUCogCFEpCrAIO2TDAqy/qcW5fMowjSNS0bFr0WKBC3ckXGadt7nv1NfIy9X2xcZArxnlcPiI+SgpoTjAKASZMmYeTIkUhISECXLl2wZMkSpKSkYNy4cQDE2UipqalYuXIlAGDcuHH47LPPMGnSJDz//PPYs2cPli1bhjVr1piuOW/ePEyfPh2rV69GbGysabDDz88Pfn5+8Pf3R6tWrazq4evri9DQUJvjVUVpDEaVMk2PiKhG6N+/P/r372/3Z4GBgTYDIZ9++ik6deqElJQUu+veEhFZMuicWaNWStOLMh8ryQO8g2zLSsGogAa2mRhqY9qeZTBKMADpf4vPvYPN50j9DW0xkHfdXD7jlPX9Cm8CJ34Qnzd/GPANBxRegL7EvI6UpOAGENbM/nt0oQoFoyqTknE7Fy5cwKVLlzBo0CDTMYMxGqhUKnHmzBk0adLE5rwpU6Zg0qRJpte5ubl3tP4HEdVezjUOxlECtT/gFSgGo0ry7Je1DEYBYh53SU75wahrR8VHpUZsIADz4ucAkHNVbEQAc662pCALOP69+Lz1P8QAWEADICcFuLjdumwNmhkFAEOHDkVWVhZmzZqFtLQ0tGrVChs2bECjRuJuHmlpaUhJSTGVj4uLw4YNGzBx4kR8/vnniIqKwieffIInnnjCVGbhwoUoLS3FkCFDrO41Y8YMzJw5s1re1+1IaXo6PWdGERHVRjk5OZDJZAgKCnJ3VYioFtBb9jdul6bnE2IO9JTk2gaj9FrzWrNlg1HaIotgVNn+xmHx0TLYJfU3tIXmTZUA29lOh1eKs6rqtwYadQVkMiCwIXDzAnBhq3XZahr8rlAwyjIl47HHHjMd37x5MwYPHlypCjRv3hzHjx+3Ovb2228jLy8PH3/8scMAk5eXF7y8vCp1TyLyLAarND2LNaP0WkCuFD9sTcEoX3FmFCAGmAAxhc/Lz3yOlKYXYNxaVaURy1ruUlFkHKmQZk2ZGodI8X6AdYpf9mXzc5vGYYU4ChLZFoi5VzwWFC0Goy5ssy5bUKZRqgHGjx+P8ePH2/3ZihUrbI51794dhw8fdni9S5cuVbgOO3bsqPA5d0JtWsCcwSgiotqmuLgYkydPxogRI8pN2XblLqxEVLsZnMnEkJYFUfsBmgBxhlFxLqDXARkngfqtALnC2NcQxH6Kbxggl5uDV9pCAKHi+lBSMMo3HCjIAFKN35+lNEDAvPi5QWseUAfE/oYgiP0SvQ7Yb1wS6d5x5r5KUIwYjCq7vlQ1DX5XeDe9SZMm4YsvvsDy5cuRlJSEiRMn2qRkjBo1yuocaU2P/Px83LhxA0ePHsWpU+K0MY1Gg1atWln9CwoKMqVhqNVqF7xNIvJk1iMV2eJjSR6Q2BpYY1wM3DIYpTF+8SzOBU5vAOY2BPb9VzxmahxUgI8xddjeooJS4yBNYb12RHwMsBipUCjFRgYQ0/gkUs43IAa/9n8hPu/8krlxCIy2vq7pvjVrZlRdxTQ9IqLaSavVYtiwYTAYDFi4cGG5ZV25CysR1W7WmRgWg9/nt5p3pLMa/Db2N0pygT2fAv99ADiwTDyWa7HOrNwYkinb3yjJMy/VUb+F+Cj1C/wtglFKi0wMy/5GaZ6YmQEAp38Bcq+KfZtWFpkH0rpRgt5cH6DaBr8rHIwaOnQoEhMTMWvWLLRr1w5//PFHuSkZANC+fXu0b98ehw4dwurVq9G+fXsMGDDANe+AiOo8QV9mZpQgANdPirnY57eIr0uNKXlqP+vG4fxmAIJ5BlKuxXappsahzHareq25EarfUnxMP24+z5I0O8qycQCAG8Z1o5J+Fhc+9w0DWj1u/rmpcTDOvJGCUzVszai6iml6RES1j1arxZNPPonk5GRs3rz5thtZuHIXViKq3Qx6O7vppf0NfP048MNY8XVpmZlRgDj4fdm4eVHqQfExN1V8tBzELtvfkAa+VT5ASGPr8xwFoyw3PQLM2Rj7FouPCc9aLyMSVGa9PClDQ1rntopVagHziqZkCELFRo7tXYOIyBGrkQpBL44kSIsCGrTih7ndNL0882Li0oe3vcZB+pDXGnfFM+WJy8wzo6Qd88ouiK7yFgNhty5bH89IEvO1pRlZCWMApUXqcWBD6/LRncWtV8vmjpNbME2PiKh2kQJR586dw/bt2xEaGnrbc7gsCBFJBHtpeplnxccbZ8RHqw2TLAa/pUHomxfFx7Lr0wLmIJHUp5CyKHxCbQe7LdP0LFP8yg5+Z5wCghuJO3nLlUDCc9Y/D7QIRslVQIN7gJPravZuekRENYlVMAoQZy3lWSzgl5dmDkZ5lRmpkBYTv3VJ3ErVbuNQdqTC2Dh4BwEBZYJGlucB5oblljRSIQMgiI1S5nngyj5x57yEMdbnBZZJBYi5FzjxPYNRNYTSFIximh4RUU2Qn5+P8+fPm14nJyfj6NGjCAkJQVRUFIYMGYLDhw/jl19+gV6vN23IFBISwmVBiOi2BHsbJkn9huJsoLTQ/rIgeenmtWPLDUY5mBnlE2I72O1ftr/hbQxGGfsb9e4WA2UZSeYNm+7qbR3EAqxnRoU0BvyM96mJC5gTEdVEgr5sMCrbPDMKAHLTLKbNWuRwZ503z3LSl4jpcnYbhzI53KbGIdRO43CbNL2odmK+d0aSGFwCgCY9ba9j2Tj4hAKhd4nPmaZXI0hpepwZRURUMxw8eBA9e/Y0vZZ23X7mmWcwc+ZM/PzzzwCAdu3aWZ23fft29OjRo7qqSUS1lMGyv1Gab70jHmA9+K32FXfvBoCrB8xlCrPEQXNTJkYD88/K7W+UMzNKOtey/9O4pzEYdRJI2S0ea/Ok7ZsKshj8rtcU8A21vncVYzCKiGo9Q9lgVFG2GICS5F2zaBwsZkZdLbNzxM3k20ybdaZxcDAzSgp6Ne5hDkZJDUbrf9i+Kcs0vdC7AF/jYupcwLxGUDFNj4ioRunRo0e5S4NUdNkQIiJLNoPfRdllBr9TzbOQ1P7m/kbZneoc9jcqMvhdpr9huW4UIA507/+veU1btR9wd3/bN+UfKabvGXRif0PavKma1oyq8ALmREQ1jdUC5oDtzKi8dPu7W2Rbb7aAW44aB2nabJnGwTsE8K9vfY2yjYU0M0oS9wAAmRhUyjovNh7NB9q+KZW3uKg5AIQ2NTcOhTfFdEJyKykYpWOaHhEREZHns5uJYTEzKrfszChjfyM/3fq8mxct+huWM6McpemVGfyWq8RjllRl+hvRna37IPGPAGof2/ckV5gHwOs1Nfc9qqm/wWAUEdV6gk5nfaDsmlG514ASO2l6ZTlsHMqMVBRZLCjoFWBuPADbmVKqMiMVwXHiQoKSux8yL6helrRuVGgTc6Mj6M156uQ2UppeKWdGEREREXk820yMW2L2heTWJXHjJMB6zSiJ3JiUlnXBPGhud2aUtIC5RTDKO0QMQgHWO36XPRcQFzP3DgbCm5uPtbGThSGJf0S8R1z3au9vMBhFRLVf2ZlRNtNmrwFaaaTC37ZxiGovPmZdMDcqVrvplZ02KwWjQgCZzDwbyifUekc8wDpQBQB+9YGwePPr1kMcv6+7eosNSpOegFJtzj3nulFuxzQ9IiIiojrEbpqexeC3tLMeIKbFlR38bnSf+Hhln5gWJ5OL/QKJqb9hZwFzudzc3yi7XpTluYCYtSGTAeEtxNd+9cVAkyN9ZwNvnBfXj6rm/gaDUURU6wmGMjOjcq6aFywHgJsXzM/VvrYzkZoNEB+vHrTfOJSXww2YZ0OVzd8GrHO4vQLEKbLSSIVXIHBXH8dv7MFpwJQr5mCZaVFBBqPcjWl6RERERHVI2f7GrUuArtj8WgpGKTWAQmk7+C31N1L2iI9+EWI5iU1/wyITAzAHo8pmYQDWmRjSjnhNHhQfE54T0/HKYznTSupvVMO6UQxGEVHtV3ak4kaS9etbxu1UIRM/6C1HKmRyoGlf8bk0K8o3HFCozGXKy+EGzIGrsutFAdbTZqVy0v0SRtum8ZVlOdPKtKggg1HuJqXp6QwCF8UlIiIi8nRl+xsZp6xfZxkHv9W+4qNlf8M3DGjYUXwuDZjbbHrkaGZUmWBU2fMszwXM69m2egJ49SjQ/U27b8ch07pRVd/f4G56RFT7GcoGo86Ijz6h4ge5oBdfq/3EaauWIxXBsUBYM+vzHTUOurI53CHiozRCYXfarEWwSWpEGnUF3rpkngbrLO6oV2MoFeaxHK1egFopc2NtiIiIiKgqyQxllgXJMA5+yxRiX0NrsXM3YN3fCGsOhMRZn2/T3yizYZK0Rq23sb/RoAOQ9H/iY1mWaXrSzCiZzPaezqjGwW/OjCKi2k8vTpvVyoyziKT1osJbAAq1uZy9kYqweDHYZLlguU3jYAwomUYqykybbTsMiO0GtB9lWzd7M6MAcWHBsosP3o50v4Ksip1HLqe2CkZx3SgiIiIij6Yvk6YnZWJIazNJpGCU5aBzeLw4iK0JMh+z7HsA1ml6BoNtf+O+CcCEE/bXm7XMtCi703dFmZYFqfr+BoNRRFT7GWdGFamDrI8HNLBOnfOSGgeLNaOk9ZuC46zPs1R2pKJs4xDZBhj9CxDd0bZuljOj/O60ceDMqJpCqTDPhGIwioiIiMizyQSxv6GTGQe6i3PEx4jW5p3yAPPgt9XMKGMWRkhj8zFHM6N0RUBJjjmzQ8rEkMnERcbtsTczqrJMM6O4ZhQR0W3JjMGoYlWI9Q/8I6wXFZcaB4XK/IEfZgxGhcSay5VNt7PcalWvFRsIwByMKo8rRyq4ZlSNoZRbBqO4ZhQRERGRRzPOjCpSl+lvBDawXlTcNPhdJhMDuE0wymJmlDTwrfa33anbHqs1o+4wGCWtGcU0PSKi25MZG4dir7LBqEjrD2Rp2ixgbgAi24qPVo1DmZlRllutSo2DTA5onFjzSQp6AXc+UsGZUTWGTCYzpepxZhQRERGRZzMNftv0NyKsg1HS4LdKAwQ0FPsf9VuKx0LKy8Sw7G+UWZ/2dhwtC1IZ1djf4ALmRFT7CWIwqkQdbH3cP8J61EFqHADgHyuA7CvmabNWaXrljFRIiwlqgm6/TSpQZgFzV82M4ppRNYFSIUOpnsEoIiIiIk8nM/U3ymRG+EeV6W9YDH6P3Sz2H7yDxNdOz4wqs5Pe7djbMKmyTGvUMhhFRHRbMuNWq6VeZT6wA6Lsj1QAYn53RGvz65DyglEWOdwVbRxULszhNi0oyJlRNYFKIQegZ5oeERERkYeTGcRgVKmmbDCq7OC3nUwMiWUwyt/RsiCFle9vyBTmwevK8q2+ZUEYjCKiWk9uHKnQqYPE9DnBOFPFZtqsn+3JkpAm4s57Mrn1OlOAxW56dzhS4Rfu3DmOWK4ZJQjiQobkNiqm6RERERHVCXJTMKpMsMc/0nEmRln1W4prMoU0AZRq659Zbph067L43NmUOykY5Rde8d26y5LWjCrMEnf1u9PrlYPBKCKq9aSRCijV4jpORbfE134R1ouRlxeM0gQAw78Rg1GWi44D1o1D+gnxeVCMc5WTGgeFF+AdXH7Z25FGKgxaoCTXuTWrqMqojDvq6TgzioiIiMijyY276WktZ0bJ5GIAyNnBby9/YMJxQK6y/ZnlhkmX/hSfR3dyrnLS+rZ3ul4UYB5wF/RAcbbz61ZVAoNRRFTrSVutyhVKczDKp54YnHKUpmfPXb3sH7fM4b78l/i8UVfnKqeyaBzudCaTyhtQ+QLaAnF2FINRbiXNjCrlzCgiIiIijybNjDJogs2ZGH71xTVkLRcj9yonGAVYL+Fhddw4+F2cDaRmiM9j73euco26ijuEtxvhXPnyKL3EnQBLcsX+BoNRRESOSY2DTKEWFxYHzEGoigSjHJFS7Qxa4OoB8bmzjUODBCCmC9Csf+XuXZZvKJBdIE6dDW3immtSpSiNM6OYpkdERETk2aRlQWSWmRhSPyPAhf2N0nzx0T/Keo2p8gQ2AF7eV7n72jPwP2JQ6k43X7oNBqOIqNaTCXoAgFypMu9WIe0kofYRG4zinPKnzZZHGqkAAH0p4BsOhN7l3LlefsCYjZW7rz0dnhVnaN3p+lN0x9TGmVFM0yMiIiLybFIwSq5UiYPflsEoVwx+W/Y3AHHg213rw7Z5slpuw2AUEdV6ppEKhcqcuma5ral/pBiMut20WUeUXgBkAIxBh9j73Nc4dJvknvuSDS5gTkRERFQ3KIz9DYVCLa4DeyvZ3N9QeolLhBRmAmr/yt2gbPqes1kYtVjVLY1ORFRNFMY0PblCbV64L6iRuUBEG/HR2amuZclk1g1Eo/sqdx3yKFKaHteMIiIiIvJsCtPMKLU5E8MyPS/yDvsbZYNRcd0qd51ahDOjiKjWk8Ni2mzHl8WdKjqMNhcYlAjc95q4nWplqbwBbaH4vA6MVNDtqZimR0RERFQnWKXpRbUHLmwDGnY0F/jHV0D+daCek0t52NxAIe6+rS8RF0QPjnNBrWs2BqOIqNZTmBYUVAHBsUCvd6wLqH2BiFZ3dhOVD4AscbvTsOZ3di3yCGqm6RERERHVCQrjGrUKlRfw4HSg80uAX5i5gCZA/HcnVN5iMMqd60VVI6bpEVGtJ41UKJXqqruJtMNFo651onGg2+NuekRERER1g9IyE0Mmsw5EuYqUqldHsjAYjCKiWk9huZteVZEah0Z1o3Gg2zMvYM40PSIiIiJPpjAGo5SqKhz8ju4EeAUCTftW3T1qEKbpEVGtJ41UKFRVGIxqPQTQlQAtH626e1CtouLMKCIiIqI6QSnoAFkVZ2IMWQHoSwGVpuruUYMwGEVEtZ5C0AMyQFGVjcN9r4n/iIxUXDOKiIiIqE5QQlozqgoHv+VyQF43AlEA0/SIyAMoTDncXm6uCdUlTNMjIiIi8nyCIFgEo9jfcBUGo4io1pMaB2VVjlSQQwsXLkRcXBw0Gg06dOiAXbt2lVt+586d6NChAzQaDRo3bozFixdb/Xzp0qXo1q0bgoODERwcjN69e2P//v1WZRYtWoQ2bdogICAAAQEB6NKlC3777TeXv7fySGl6Os6MIiIiIvJYWr0AVXWsGVXHMBhFRLWa3iCY1oxSKhiMqm5r167FhAkTMG3aNBw5cgTdunVD//79kZKSYrd8cnIyBgwYgG7duuHIkSOYOnUqXn31Vfzwww+mMjt27MDw4cOxfft27NmzBzExMejbty9SU1NNZRo2bIh///vfOHjwIA4ePIgHH3wQgwcPxsmTJ6v8PUuYpkdERETk+XQGg2nwW8XBb5epVDCqIqPgaWlpGDFiBJo1awa5XI4JEybYlHFmFJyIyB6t3gCVadosRyqq24cffojnnnsOY8eORXx8PBITExEdHY1FixbZLb948WLExMQgMTER8fHxGDt2LMaMGYMFCxaYyqxatQrjx49Hu3bt0Lx5cyxduhQGgwFbt241lRk0aBAGDBiAu+++G3fffTfef/99+Pn5Ye/evVX+niVSMKqUaXpEREREHkurNUApEwcflXVkcfHqUOFgVEVHwUtKShAWFoZp06ahbdu2dss4MwpORGSPVm+wSNNjMKo6lZaW4tChQ+jb13r72b59+2L37t12z9mzZ49N+X79+uHgwYPQarV2zyksLIRWq0VISIjdn+v1enzzzTcoKChAly5dKvFOKkfJND0iIiIij6fVlZiec1kQ16lwMKqio+CxsbH4+OOPMWrUKAQGBtot48woOBGRPTq9YJoZxWBU9crMzIRer0f9+vWtjtevXx/p6el2z0lPT7dbXqfTITMz0+45kydPRoMGDdC7d2+r48ePH4efnx+8vLwwbtw4/Pjjj2jRooXD+paUlCA3N9fq351QM02PiIiIyOPptOZglEzB/oarVCgYVZlR8Mq43Sg4EZFEnBklrhmlULJxcAeZTGb1WhAEm2O3K2/vOADMmzcPa9aswbp166DRWE+LbtasGY4ePYq9e/fipZdewjPPPINTp045vO/cuXMRGBho+hcdHX3b91YepZxpekRENcUff/yBQYMGISoqCjKZDOvXr7f6uSAImDlzJqKiouDt7Y0ePXpU6zqDRFR7aUstZu/LOTPKVSoUjKrMKHhlOBoFt+TqEW4iqp20ej0UMmMwgAuYV6t69epBoVDYfP5nZGTYtBOSiIgIu+WVSiVCQ0Otji9YsABz5szBpk2b0KZNG5trqdVq3HXXXUhISMDcuXPRtm1bfPzxxw7rO2XKFOTk5Jj+Xblyxdm3apdKyTQ9IqKaoqCgAG3btsVnn31m9+fz5s3Dhx9+iM8++wwHDhxAREQE+vTpg7y8vGquKRHVNnqLmVHsb7hOpRYwr+goeEWUNwpuydUj3ERUO2lLLRoHudJ9FamD1Go1OnTogM2bN1sd37x5M7p27Wr3nC5dutiU37RpExISEqx2J5k/fz5mz56NjRs3IiEhwan6CIKAkpIShz/38vJCQECA1b87wTQ9IqKao3///njvvffw+OOP2/xMEAQkJiZi2rRpePzxx9GqVSt89dVXKCwsxOrVq91QWyKqTaQ0PR3kgIviHlTBYFRlRsEr4naj4JZcPcJNRLWTXldqfsGRimo3adIkfPHFF1i+fDmSkpIwceJEpKSkYNy4cQDEz+pRo0aZyo8bNw6XL1/GpEmTkJSUhOXLl2PZsmV44403TGXmzZuHt99+G8uXL0dsbCzS09ORnp6O/Px8U5mpU6di165duHTpEo4fP45p06Zhx44deOqpp6rtvSvl4pcRrYFpekRENVlycjLS09Otlhrx8vJC9+7dXbrUCBF5Jp1xkx09OPDtShX6bVqOgj/22GOm45s3b8bgwYPvqCLz58/He++9h99//92pUXAvLy94eXnd0T2JqPbTaS2CUczhrnZDhw5FVlYWZs2ahbS0NLRq1QobNmxAo0aNAABpaWlWu63GxcVhw4YNmDhxIj7//HNERUXhk08+wRNPPGEqs3DhQpSWlmLIkCFW95oxYwZmzpwJALh+/TpGjhyJtLQ0BAYGok2bNti4cSP69OlT9W/aSKU0zozScWYUEVFNJg2k21tq5PLlyw7PKykpsZpxy2VBiOomafBbBwUYgXCdCof2Jk2ahJEjRyIhIQFdunTBkiVLbEbBU1NTsXLlStM5R48eBQDk5+fjxo0bOHr0KNRqtWnXo3nz5mH69OlYvXq1aRQcAPz8/ODn53en75GIPJhVMIozo9xi/PjxGD9+vN2frVixwuZY9+7dcfjwYYfXu3Tp0m3vuWzZMmerV2VUTNMjIqpVKrrUyNy5c/Huu+9WdbWIqIbTa6VgFGdGuVKFf5sVHQUHgPbt25ueHzp0CKtXr0ajRo1MHQ5nRsGJiOzRG6fN6iCHkjncVI1UCuMC5kzTIyKq0SIiIgCIM6QiIyNNx2+31MiUKVMwadIk0+vc3FyuU0tUB+l1xjQ9GYNRrlSp32ZFR8GlbbsdcWYUnIjIHmnarB5KjlVQtZJmRpUyTY+IqEaLi4tDREQENm/ebBokLy0txc6dO/HBBx84PI/LghARYJGmx2CUS/G3SUS1mnnaLHO4qXop5UzTIyKqKfLz83H+/HnT6+TkZBw9ehQhISGIiYnBhAkTMGfOHDRt2hRNmzbFnDlz4OPjgxEjRrix1kRUG0jBKAMUbq6JZ2EwiohqNb3eODOKIxVUzdRKpukREdUUBw8eRM+ePU2vpfS6Z555BitWrMCbb76JoqIijB8/Hrdu3ULnzp2xadMm+Pv7u6vKRFRLGJimVyX42ySiWk1aM4qNA1U3pukREdUcPXr0KHdpEJlMhpkzZ3I9WiKqMEEn7qppYH/DpeTurgAR0Z0QpJlRnDZL1UxK0+PMKCIiIiLPZVrAXM5glCsxGEVEtZrUOHCkgqqblKbHNaOIiIiIPJegZ3+jKjAYRUS1GnO4yV2kND0t0/SIiIiIPJaBg99VgsEoIqrVDNLuFmwcqJqZdtNjmh4RERGRxzL1N+QqN9fEszAYRUS1msCRCnITpukREREReT7BIPY3BPY3XIrBKCKq1QxSDjcXFKRqZlrAXM+ZUURERESeShr8FtjfcCkGo4ioVpN20+PMKKpuKqXYhJZyZhQRERGRxzItYM40PZdiMIqIajVBrwPAYBRVP5WCaXpEREREHs8g9jfAmVEuxWAUEdVq0oKCnDZL1U1lTNMTBEDPRcyJiIiIPBP7G1WCv00iqt2kBQU5bZaqS8o+4PBX8AmMA9ACgDg7SiFXuLdeREREROR67G9UCc6MIqLazZimx5EKqja5V4Gjq6BK3mY6xHWjiIiIiDyUMRgFBYNRrsRgFBHVatKCggxGUbXxDQcAyAozTYe4ox4RERGRh9JzzaiqwGAUEdVuek6bpWrmGwYAkOVnQCHnIuZEREREHs00M0rt3np4GAajiKh2kxoHjlRQdTEGo1CcDW+5HgCDUURERESeSmbaTY+D367EYBQR1W7SmlHM4abq4h0MyMTFysMV+QAALdP0iIiIiDyTXpoZxcFvV2IwiohqNZnAmVFUzeRywLceACBSlQcAKCjRubNGRERERFRF5IL4PU/GwW+XYjCKiGo340gFGweqVsZUvaa+xQCAq7eK3FkbIiIiIqoiMgP7G1WBwSgiqtWYw01uYQxGNfEuBABcvVXoztoQERERURVhMKpqMBhFRLWbFIxi40DVyRiMaqgW14xKuclgFBEREZEnMqXpKbmbnisxGEVEtZrcwBxucgNjMCpCyWAUERERkSeT+htyLmDuUgxGEVGtZlrAnMEoqk5+YjAqFNkAgCsMRhERERF5JPPMKC8318SzMBhFRLWajDOjyB2MM6P89dkAgCu3imAwCG6sEBERERFVBSkYJWd/w6UYjCKiWk0u6MVHNg5UnYzBKE3JTSjkMpTqDLiRX+LmShERERGRq5mCUUr2N1yJwSgiqtXMu1swh5uqkTEYJSu4gaggDQCuG0VERETkiRSmYBQXMHclBqOIqFYzT5tl40DVyBiMQsENxAR7AwBSshiMIiIiIvI0UiaGgsEol2IwiohqNYVpQUFOm6VqJAWjDFo0DTQAAK7cYjCKiIiIyNMojRsmMU3PtRiMIqJazTxSwcaBqpFKA3gFAACa+hYBYJoeERERkSdScGZUlWAwiohqNdNWq1zA3G0WLlyIuLg4aDQadOjQAbt27Sq3/M6dO9GhQwdoNBo0btwYixcvtvr50qVL0a1bNwQHByM4OBi9e/fG/v37rcrMnTsXHTt2hL+/P8LDw/Hoo4/izJkzLn9v5fKtBwBopBGDUFdvFlXv/YmIiIioyikg9jcUKgajXInBKCKq1aQ0PY5UuMfatWsxYcIETJs2DUeOHEG3bt3Qv39/pKSk2C2fnJyMAQMGoFu3bjhy5AimTp2KV199FT/88IOpzI4dOzB8+HBs374de/bsQUxMDPr27YvU1FRTmZ07d+Lll1/G3r17sXnzZuh0OvTt2xcFBQVV/p5NjKl6DVR5ADgzioiIiMgTKU39DQ5+u1KlglEVGQVPS0vDiBEj0KxZM8jlckyYMMFuuR9++AEtWrSAl5cXWrRogR9//LEyVSOiOoa7W7jXhx9+iOeeew5jx45FfHw8EhMTER0djUWLFtktv3jxYsTExCAxMRHx8fEYO3YsxowZgwULFpjKrFq1CuPHj0e7du3QvHlzLF26FAaDAVu3bjWV2bhxI0aPHo2WLVuibdu2+PLLL5GSkoJDhw5V+Xs2MQajwmS5AIDrecUo1uqr7/5EREREVKX0BgFKiN/vlCovN9fGs1Q4GFXRUfCSkhKEhYVh2rRpaNu2rd0ye/bswdChQzFy5EgcO3YMI0eOxJNPPol9+/ZVtHpEVMdI02a5oGD1Ky0txaFDh9C3b1+r43379sXu3bvtnrNnzx6b8v369cPBgweh1WrtnlNYWAitVouQkBCHdcnJyQGAcsuUlJQgNzfX6t8dMQajfHW34KtWQBCA1Gym6hERERF5Cq3eAKVMCkZx8NuVKhyMqugoeGxsLD7++GOMGjUKgYGBdsskJiaiT58+mDJlCpo3b44pU6agV69eSExMrGj1iKiOkRYUZONQ/TIzM6HX61G/fn2r4/Xr10d6errdc9LT0+2W1+l0yMzMtHvO5MmT0aBBA/Tu3dvuzwVBwKRJk3D//fejVatWDus7d+5cBAYGmv5FR0eX9/ZuzxiMkhXcQHSIDwCm6hER1VQ6nQ5vv/024uLi4O3tjcaNG2PWrFkwGAzurhoR1WBavQEq48worhnlWhUKRlVmFNwZjkbKy7umy0e4iajWMVhMm2UOt/vIZDKr14Ig2By7XXl7xwFg3rx5WLNmDdatWweNRmP3eq+88gr+/vtvrFmzptx6TpkyBTk5OaZ/V65cKbf8bfmFi48WwairDEYREdVIH3zwARYvXozPPvsMSUlJmDdvHubPn49PP/3U3VUjohpMqxegNGZiKLksiEspK1K4MqPgznA0Ul7eNefOnYt333230vckotpPazBAxd0t3KZevXpQKBQ2n9UZGRk2n+mSiIgIu+WVSiVCQ0Otji9YsABz5szBli1b0KZNG7vX++c//4mff/4Zf/zxBxo2bFhufb28vODl5cJcf+NueijIREy4GIy6cKMaF1AnIiKn7dmzB4MHD8bAgQMBiNkba9aswcGDB91cMyKqybR6A7yNg99co9a1KrWAeUVHwavimi4f4SaiWkent1hQkI1DtVOr1ejQoQM2b95sdXzz5s3o2rWr3XO6dOliU37Tpk1ISEiASmWe3TZ//nzMnj0bGzduREJCgs11BEHAK6+8gnXr1mHbtm2Ii4tzwTuqIGOaHvIzkNAoGADw6/E0aPVM+SAiqmnuv/9+bN26FWfPngUAHDt2DH/++ScGDBjg8BxmYhCRVm+A2jj4DXmF5vLQbVTot1mZUXBnOBopL++aLh/hJqJax3JBQc6Mco9JkyZh5MiRSEhIQJcuXbBkyRKkpKRg3LhxAMSBg9TUVKxcuRIAMG7cOHz22WeYNGkSnn/+eezZswfLli2zSrGbN28epk+fjtWrVyM2NtbUPvj5+cHPzw8A8PLLL2P16tX46aef4O/vbyoTGBgIb2/v6nnzvlKaXiZ6t6iPMH8v3MgrwaaT1zGwTWT11IGIiJzy1ltvIScnB82bN4dCoYBer8f777+P4cOHOzyHmRhEpLUY/IaCy4K4UoVmRlVmFNwZjkbK7+SaROT5tHrBvKAg14xyi6FDhyIxMRGzZs1Cu3bt8Mcff2DDhg1o1KgRACAtLc1qt9W4uDhs2LABO3bsQLt27TB79mx88skneOKJJ0xlFi5ciNLSUgwZMgSRkZGmfwsWLDCVWbRoEXJyctCjRw+rMmvXrq2+Ny+l6ZXkQGUoxbCO4oLo/9t7qfrqQERETlm7di2+/vprrF69GocPH8ZXX32FBQsW4KuvvnJ4DjMxiEir00MpM856l7O/4UoVnmdW0VFwADh69CgAID8/Hzdu3MDRo0ehVqvRokULAMBrr72GBx54AB988AEGDx6Mn376CVu2bMGff/7pgrdIRACAw/8DDn0JDF0FBHjGrA2dwQAv47RZmYIzo9xl/PjxGD9+vN2frVixwuZY9+7dcfjwYYfXu3Tp0m3vKS167laaIHG6tkEHFGZieKcYfL79PPZevInzGXm4K9zf3TUkIiKjf/3rX5g8eTKGDRsGAGjdujUuX76MuXPn4plnnrF7DjMxiCro5Hrg/BZg4H8ApWf87ei0JeYXnBnlUhVeM6qio+AA0L59e7Rv3x6HDh3C6tWr0b59e6v87K5du+Kbb77Bl19+iTZt2mDFihVYu3YtOnfufIdvj4hMDi4DUg8BF7a6uyYuo9VZTJvlSAVVN7kcCIgSn99MRlSQNx5sLqaXf703pZwTiYiouhUWFkIut+76KBQKGAxc54/IZbbOAo78D7i0y901cRmdVmt+wWCUS1VqBa6KjoI7M4I9ZMgQDBkypDLVISJnZBunludnuLceLiTupiflcHNBQXKD+q2B7BTg+gkgrhuevjcGW5Ku44fDV/Gvfs3g68X/L4mIaoJBgwbh/fffR0xMDFq2bIkjR47gww8/xJgxY9xdNSLPYDCI34kAIO969d335kXg0l9AuxGAXOHyy+u0peYXHPx2qUrtpkdEtUxpAVCYKT4vuFF99715EfgzESjJr5LLa/UGzowi94poLT6mHwcAPNA0DLGhPsgr1uHbg1xbhIiopvj0008xZMgQjB8/HvHx8XjjjTfw4osvYvbs2e6uGpFnyE8HDMZZRAXVOPj921vAz68A5zbfvmwl6HRM06sqDEYR1QXZFp3i6pwZtePfwJYZwPHvquTyOp0BKhl3tyA3imglPhqDUXK5DM91awwAWP5XMvSGGrC2FRERwd/fH4mJibh8+TKKiopw4cIFvPfee1CrueYkkUu4q78h3ffmhSq5vN6YpqeHHJDJquQedRWDUUR1QY5F41CdM6Nyr4mPty5VyeW1Ostps0yHIjeQZkbdOA0Y/38cck9DBPuocOVmEX4/me7GyhERERFVk2yL9TKrMxhVmCU+Sv0OFzMYv9/pKrfCEZWDwSiiuiD7svl5dQajCm+Kj3lpVXJ5PRcUJHcLagR4BQD6UiDzLADAW63A0/eKm3os3XXRnbUjIiIiqh6W/Y38alozShCAImN/o4qCUXrjbnp6mevXo6rrGIwi8kTZV4Dtc4GCTPNriQeNVOi5oCC5m0wG1Dem6l0/YTo8sksjqBVyHEnJxsFLN91UOSIiIqJqYjkzqroGv0tyAYNOfF5F/Q2dTkrT48woV2MwisgT7V0E7Py3+AhYNw6FWYBeV/V1qIaRCi4oSDVCmUXMASDcX4PH72kAAPjPprNO7SpLREREVGtkXQB2/UfcKAlwT5qeNPANVFl/QzCm6ell7Gu4GoNRRJ6oOEd8vHZYfLRcMwqC9Qd3VSktEFOXADFNrwo641KangGyKtnKlcgppmDU31aHX3nwLqgVcuy5mIVd5zLdUDEiIiKiKrLzA2DrLODwSvG1ZX+j6Cag19o/z5UKb5mf56UBBoPLb6GXZkYxTc/lGIwi8kAG44whIe2YGASyHKkAqme7VcuAl7bQHCBzIYMx2KUHGwdyI8uZURZB14bBPhjZRVw7at7vp2HgznpERETkKYqyxccr+8UgkOWyIED1pOpZ9jcMWqDQ9YN/UjDKIGOanqsxGEXkgZLTxQ9mWWEWtDfOmxcR9IsQH6ujcSgqs05OFSxirpO2WmXjQO4U1hyQKYCiWzZTxF/ueRf8vJQ4kZqLxK3nsO7wVew8W42bCLhIbrEWx6/mMN2QiIiIRHrjchmpB8WBbn0JIJMDPvXE43e6iLkgANdPmXYrtqtstkdu6p3d01JpIVCcC8E4+G3gzt0ux2AUkQcqLSkyPf/5myXiE5UvENZMfJ7vgs7w5d1i59sRm8bB9Xnc0larXFCQ3EqlMf9tWawbBQAhvmq88EBjAMAnW89h0rfH8Mzy/dh9vnal7f3ru2MY9NmfOHol291VISIioppAWrs1OwVIPSQ+D2gABESJz++0v3HqJ2BRF2DbLMdlyg5+57pw8HvlI8Cn90BVLN6DM6Ncj8EoIg8k15tHEGIztwMAcrwioPMOAwAI+ddxOasA3x28gi//SsbBSzdRrNVDbxCQX6JDTpEWecValOoc5F2f2wx82R/4v9fs/rhYq4c2v0wwypUzo3bOB74aBHmJmPrHmVHkdlKq3rUjNj8a2y0Og9pGoVNcCGJCfAAAv51Ir87a3bHjV8W/tYs3CtxcEyIiIqoJBMuNhE6uFx+DYgC/cPH5nS4Lcn6z+HjiR5u1Z4u1elzOKkDezTKzr1w1MyonFbh6ACi4gbBb4nc7BqNcj79RIg8kN5iDUR3k5wAAh3L8cfHvAoxVAl9u2o9Z/9ek3GsooEcr+WUExCVgQNsGKCjRYceZG7iWXYTp6m/RE4D+zCacuXIDGYUCdl/IwsFLN5FysxCZ+aUYrfgLMy02nTh0/BQO5V3A9dwSZBdqoTMYoDMI0OkN0OkFhPqp0a1pGLo1rYcgH7XpPEEQUKTVQ62QQ6mQizsB/vkhoC1EuDweABcUpBqgUVfg77XiDpbtnwaCok0/8lEr8enw9gCArUnX8dxXB7E16TpmDW4JmUzmrho7rUSnR1puMQAgp6gaFiMlIiKiGi8zOxdhxudFJ/4P3gDSZPXgr9LAD8Cpc+ew6tJx7L2YhYISPZqE+yImxBf5JTpk5ZegSKtHn8INGFz8E7bc8znat2mLy1mF2JJ0HTfySpB4cw/CASD3Ks6eOooTJWHYfOo69l7Mwq1C8fvIHOVxjLCIaGzedwRrTh3A1VuFuFlQiqJSPUr1Bijlcnip5IgI0OCeRsG4JyYYHWODERPigxKdAYcv38KFzAJ4KeRQK+VokLYZHY3X9Ms8CoBpelWBv1EiD6Qw2OZW53pFIKsoEAAQaMiGSiFDm4ZBCPZR4djVHNzIK7Eq/7byazyr/B3/TH4FUy50tfqZj/pvQA4o9EWYufAr7Bfibe4XLMuzep109jTmnDpdbr2/PXgVchnQLjoI3e8OR26xFluTruNSViEAQK2QI15xBT/JxddZZ/cCCo5UUA3Q7mng8P/EdRPWvwSM+hmQ204+vu+uetCo5LiWU4yktDy0iApwQ2Ur5uqtItOAJINRREREBAD6UvOyIN6C+Pzb83KoUYiXlMDev09jlc68iVJ6bjH+gjlzwgulWO61AsGyfCT/9T1m/JFv+pkGJQj1uggYx+xWrv4KX+v7WN3fSylHiFw8J1UIRQNZFnIzUrAt1XZGllavR5FWj+xCLU6n52H1PrFeYf5eyCmyzQaZrNyMjsbuRcPic2I95CqQa7EHR+SB7AWjBvfogjxFEPD7N+gfp8DAkf2gUYkzigRBwM2CUshlMmhUCii0+VAlPg9ogTGNs3G1NAh+Xkr0aBaOxiEatP/+MmD8zO7rnYQ0zT3o0jgUXZvUw13hfmgY7A31pi3AUaBYHQxN6S20CSzEo9FRCA/QINhHDZVCBoVcBpVCDpVChos3CrDjzA2cuZ6HwynZOJySbfMeSvUG3I1zpgTj1vJkAIBK7VUFv0WiClAogceXAIvvBy7tAvYtArq8bFNMo1Lg/rvqYUtSBrYmXa8VwagUYzAYYDCKiIiIRErB9jtBsU8DFBSJqf13+xZidMtYdGkSinp+XrhwIx9XbxUhQKNEPT8vNE7fgOB9YjDp3nrF+O6WAvUDNejToj4S5Oeg2GNOzeutPomDgY+jT4v6eLB5OBqH+SFAowRWfApcBvxj2gFXtuLe0GLM6dIaDYO9EebvBW+VAmqlHHqDmGlx8UY+Dqdk49DlW/j7arZpML63bzIe9j+LXwOHo1AvQ/eMy4CxO6WRie8zPMivCn+bdRODUUQeSCnYBqNkQdEIUPsDAHxKswCVObVNJpMh1M8ioHPiJ0Arrg3TPrAQP/7jPvPPMpIAg3kkZGxUCsaOfdC2EjqxIdI0aAMk70SbgEIkDmtfbr2nDIjHtewi7Dx7A3+ey4RGpUDfpv7oEpoPfWhzFGr1CNzyG3BCLF9PlgsACPDxLve6RNUitAnQ9z3g10nA1tlAh2cBtY9NsV7x9bElKQNbTmfgn72auqGi1vQGAQq543TBlJvmYFQug1FEREQE+/2Nt4b1AQoygR/+h/sjBdz/SEvTzzo0CrYu/OV609OHog14aOJD5p/t3Sk+BjQAclPRQ30GPf7ZVRz8s1QoLi4eENseuLIVDRS3MKJzjMM6313fHw+1igQgrjt18loOAr3VaPLD+5BdP4lH728PtB8J/PuCzbleXhqH16XK4QLmRB5IGqko9I8zHwxqBPgZM7sLbrOT1+H/mZ+XXXg89bD4GBxrfH0IKM61vYa0m560sLOTu1tEBXljeKcYfP7UPfjPk23R7+onCFjeDcFXNqNBkDf8Mo/ZnqTgtFmqIRLGAIHRgK5I3HHSjl7NxYU9j13JRoZxLSYAuHgjHx9vOYes/BK75zlSrNVj+JK9GPzZnygs1VXo3N3nMxH/zkZ8uPmswzKXOTOKiIiIypD6G6VeIeaDQTGAr7G/kV/OAuaZ54DLf5pfl114/Jqxv9H+aUATCJTk2N0kxrSbXkQr43XSbBY7d0SjUqBDoxDcFaKG7MYZ8eDf3wIZpwBtIeAVAPhHmk9gmp7LMRhF5IFUxpGK/PB7zAcDowFfaXeLG4DBwU55N84AV/ebX9s0DsaGoPnDQEgTQNADl/+yvY5xpAL1W5rvqa9ERzb5D/Hx0FeAtgi4flJ8rbaYKssFBammkMmAJj3F5xe22S0SHqBBm4bi+m3SrnrbT2dg8Gd/4aMtZ/H2+hPl3uLjLefw5H/34MINcWr7h5vPYs/FLBy7moMlf1ysUHV/OZ6GUp0Bn2w9hx+PXLVbxnJmFINRREREBABqY38jr34n4xEZENAQ8Ksvvsy/bv9EADi0QnyUgj2O+hsNOwJxD4jPL+6wLiMI5sHv+sbBb20BUJxjXa5s/0NXAlz6y9wXyjoHGIyDeSm7gZM/is8b3ANEtjWfx8Fvl2MwisgDSSMVJREJ4gGFlzhKIY1UGHRAcbaYcnd+i/XJh1eKjxFtxMfcNOvAlTRSEdUeaNxdfF62cQDMwah6dxtHEgQgr4Lb2ZcWAjeNnesLW8X7CHqxkYu931yOjQPVJE2MaasOglEA0Dte/KI24+eTeGDedoz56gDySsQvQptOXce17CK75+2+kImPtpzF/uSbGL5kL9bsT8HSXeYA1H93XkR6TrHdc+35+2q26flbPxy3ei25wmAUERERWRIEqGHMxIg0BqP8IwGlGvAzDn4XZ4uBnx9fAlb9A9AZ0/p0pcDR1eLzbq+Lj5b9jeJcceYUAES2AxobB/kubreuQ0muOYgUEAV4G9MAc6+Zy5z9HXg/Atj2nvharwNWDQFWDACOrRGPZSRZX3fP5+JjgwRzfwjg4HcVYDCKyANJjUNJ9H3A3f2B+14Vd/ZSqsWproA4ArFyMPD1E8C1o+IxvRY49o34/IF/AZABBq151EFXCqQfF583uAdo3EN8bi8YJU2b9Qkxj3pYpvzlXgNWDwVO/Ww+duIH4ON25utlngFgnGpr0AFb3hWfR91jTv8DOG2Wapa47gBkwI0k6y9EFoZ1isYDd4dBKZch5WYhBAEY3ikGneJCoDcI+HrvZQDi5gJS2l6pzoDpxllTaqUcGXklmLLuOAQBGJoQjQ6NglGk1WPBpjN271mi0+Pbg1dw0Tijqlirx+k0cdfLe2KCUKozYNz/Dlml+gmCwJlRREREZE1vXi+qqMlAILYbcO9L4gFNkPm7+YVtwLHVwLlN5rS8S7vEfoJfhLg+k6m/YVxGJP1vAIKY1eEXZu5vXNkvDlRLpIFvlY+4Rqd/lPg6z+K718HlYh/ij/ni860zzVkX0oC8lHXhE2p8b8blEhomWPc3OPjtcgxGEXkaQYDaODNK7R0AjPgGePBt88+lVL1j35inz57dKD6m7BUbAu8QoNkA8zRbaepsximx8dEEAcFxYsMDGXDjNJBnMRVXWyTmWgPiB3uANAXXonHYv1S87/fPAhd3AlcPAj+OA24lm2dnXT9l/d5uGEcuGnQA6rcyHy+7mCGRO/mEiMFaALiw3W6RcH8NVo7phCPv9MHipztg2TMJmPt4azx3v7jO25r9KcjKL8EzXx5Ah/e2YMyKA5j1y0lcuFGAen5qbJrwAJpHiBsSxIT4YPqgFnh7YDwA4IfDV3Hg0k2r+53PyMdjn+/Gm9//jYlrjwIATqfnQWcQEOKrxooxndAw2BvXcorxvz2XTefdyC9BkVZves1gFBEREUFnnoWt8q8HjP5FHPwGxAFwKRtj96fmc85uMj7+Lj7e3Q9QaQD/CPF1jnG5gFSLLAwACGksXs+gtZ7FJAWjvI1rVgUYg1FSf6Mk3/p72K+vW9fninFZEuma944HlBaLlDfoAERazoxiMMrVGIwi8jQGHeQycTaRyt6uD9LUWSngAwDnNouPUlDq7n5igKdsEMkyRU8mEzvdYc3EY+l/m68nNQ5ypbj4n9Q4WM6MOvObqb74diTwzQjzKIupcTAGo5o/DMBit68GnBlFNZwTqXoA4K9R4aFWEehlTNvrHV8fDYK8catQiz4f/YE/zt4AAGw7nYGv96YAAKYNjEdsPV9888K9mNK/Ob5+rjP8vJRoHxOMwe2iIAjAU1/sw7cHryA1uwiJW85i0Kd/4lSauNHAsas5SM8pNqXktWkYiACNCq8Zd/ZbvPMC8o0pgynGxcsDvcW/sRKdAcUWwSkiIiKqg3TmmVFeGtudg02bJlmuK3t2o7jOk6m/Ydw9r2wQSVovSgpGyWTm7/1W/Q1j5oaPFIwq02+5sE2c5RQcC7QdDgjGNMBOLwIyBZB7VQyAZRhnRsXcKw7GA0BgjNhnCmpkzirh4LfLMRhF5GH0WvNIhd3GQRqpKLHYAS/1EFCQZadxaCA+SjOjyo5UAOYFyq9bLLospeh5B4sNiH+ZRubmRXGWk0whptwV54iztOo1E4/lXAFyUs3BqKZ9gEb3ma8f1V6cmSUtYs4cbqppmvQSHy9ud7xZgB0KuQyjujQCANwsKEWIrxqLn74Hj9/TAHIZ0LNZGB5tJ/5dBvmo8WL3JogJNf+dz360FXo1D0epzoA3v/8b93+wDYlbzqFIq8f9d9UzzabafiYDx66IC3y2aSB+yXqsfQM0rueLW4VarPgrGYB58fL4SH/IjfHgXM6OIiIiqtP0WnFtyxJBCS+VwraAlF0BiP0BuUrMfjj9C5B9WVzPVlp79nbBKMAiGHXcfMy0JIgxvc7UbzFe58wG8bHZQGDQJ0DH58XZTw/NNV/v/FYgWxzsQ3gLoPOLYl1bPioek8nM60Zx8NvlGIwi8jClxeaFj7003rYFpJlRABDa1JjuJgD7lwBZ58UPWmlWR9kZTWlHxUcpBQmwCEadNB8rLNs4lFkz6owx6NWoK/DUd0B4S7EBGb7GvDXrlX3mNL3wFkDrIeLzkMbiCIhcbr43c7ippmmYAKj9xVG79GMVOnVox2iE+XshJsQH34/rgodaReLDJ9vh+Mx+WDoqATKZzOG5ARoVlo5KwOt97oZMJg5A3ts4BB8Pa4eVYzrh4Tbi3+LWpAyLmVFBAAClQo7Xeouzo5b8cRG5xVpcNs6Mig31RYBxdhRT9YiIiOq20hJjMAoqaOwFo3wt+huthgCxxkHl36eKj3EPAGpf8XlAQ/Ex9ypQlC0GrQDrneykgJBlMMpmZpSx33L9hDhzSxpkbz5QXDd34AIxECVXiLOgAPOufn4R4nVi7gXeugT0ftd8H6keXhY7eZNLcDoBkYcpKS6CNwCtoICXys6fuGXj0GYoUJovfmj/lSgei70f0ASIz/0tprvqSoCM0+Jry8ZB2krVKhhlbBykHG7/MtNmTSMVAwDfesC4P8V0PaUaiO4MpB0TG5B84+57Yc3Fe95KNi9iCIiBtCv7ODOKah6FCojrJv6/fnGn9ejebQT5qLHrzZ6Qy2RQK81jRr5ezv1/LpfL8M9eTdG/dQS8lApEh5hnTj3YvD4WbDqLP8/fQIlOnLHVJjrQ9POH20Ths23ncS4jHwu3X0BGrjjTMibUB4HeKmQXahmMIiIiquNKjf2NEqgQYndmlEV/o+0wcQmOizvMs5Du7mf+ueXMKCkNL6iROcgEmGcyXT8pzjiXyy2CUcbB75iu4qB66iFg9T+AoltiXyS6s239ojsB+xablyCp38L8s7JBpy6viAGsjmMd/TqokjgzisjDaC1GKpQKO3/ivvXMz1sPEVPgAPNChFKKHmCdppeRJC4cqAkSd7eQSLOTMs+KASvAeic9AAhtIj6m7AX+/g64vFt83cx4L2mnP8DcYJxcLz4GxojBMaUX0GeWedYWYA5MSdcnqkkadRUfr+yr8KkalcIqEFUZd4X7WwWiADHdLjJQg2KtAYIARAZqEO5vXltOIZfhrYeaAwCW/XkR+5LFv+WYEB/TulEMRhEREdVt2hJx5rQWKijkdmZsS2l6IU3EhcAtg0+A42BUmnE2ueXAt3QdpQbQFphnTpXNxKh3FzD4c/G5tDN3s/7213qKvtf6dXgL2zKm+kWKfZCgGMdlqFIYjCLyMNK0WS0cpK5Ju9A17gGExInBH68A88+bWQajpMYhzTxSEdFazJ+2LKMJEmc23TBuKV9YJhgV2Q5oOwIQ9MC6seJjWLyYcleWFIyStlWtX07jED8IeOUQ0HOa4zJE7iJ90UnZK+bL1QAymQwPNjePVrZpGGhTpneL+niweTi0egGp2eLnSaMQXwajiIiICABQWiIOYpdCbb9Aq8eBu3oD/T8Q+w2hTYDQu8SfhbewDuwESml6qY6DUQqlOWAk9UnKZmIAQNuhQE+LXcSlBcnLCmxgTg+U6kTVjsEoIg+jLRUbB63MQTAquiMwdhvwj6/E1wqVeQHBsHhxxwmJ1UiF8YO/bOMgk5kDXFKqXtmtVmUyYNDHYn64pLmDxiEo2jwjCwDC4+2Xk65b7y5x6ixRTRPZVhzFK7oJZJ5zd21MesVbBqOC7JaZMaiF1cysmBAf05pR2YUMRhEREdVlUiaGzlF/wy8cePoHcwYGALR41PpRYtnfkBYvj2xne82yi5iXHfyWPPAG0H2yuFZV076O30SMRfpeeYPfVGUYjCLyMNpi47RZR40DADTsAHgHmV93eBaADOhUJhdaWutJWwBc+lN8Li0gaEladFzaUa/s7haAmIb35P/EkQeZAmj5uOP6RXcyPw9v6bgcUU2mVItT0wHgyl731sVC1yb1oFGJzb+9mVEA0CjUF+O6i+mvgd4qBPqoODOKiIiIAAA60+C3g5lR9nR/C3jqe6DbJOvj/pEAZIC+VNxMCQAi7fU3pGBUOf0NQBys7jkFGLLMvAyIPaa1pGTijt5U7bjqL5GH0WnF9DaHaXr23NULmHHL9rjaR9yOtegWcCNJPGavcTDtqGdsHMrubiHxDgKe3wbkZwDBjRzXJ/pe4OSP4vPyZkYR1XTRnYHLfwEp+4B7Rrm7NgDE9ahmDW6Fk6k56NqknsNy43s0QWZ+CdoaA1YMRhEREREA6KSZUfIKBKOUauuZUhKFSlxjStq4yD/KegF0Sdkd9Rz1N5zVuKe4CVJkO7HPQ9WOM6OIPIy5cfCq2IkymfVaUBLLlDmlBghtalvGFIxykKZnSeVdfiAKMM+MkiuBenbuRzXKwoULERcXB41Ggw4dOmDXrl3llt+5cyc6dOgAjUaDxo0bY/HixVY/X7p0Kbp164bg4GAEBwejd+/e2L9/v1WZP/74A4MGDUJUVBRkMhnWr1/v6rflGtLWwTVoZhQAPJkQjXcHt7K/6KiRRqXAnMdaY2hHcV0HKRiVy2AUERFRnabXiv0NfXmZGBUhpeoBQFQ7+2WkVLq8a0BBpu1uehUVdjfw4h/AsNWVO5/uGINRRB5GrxWnzTrM4a4oKVUPEINO9nakCIsHZHKg4IY468nRtFlnRbUXp/IO/I+4ix7VWGvXrsWECRMwbdo0HDlyBN26dUP//v2RkpJit3xycjIGDBiAbt264ciRI5g6dSpeffVV/PDDD6YyO3bswPDhw7F9+3bs2bMHMTEx6Nu3L1JTU01lCgoK0LZtW3z22WdV/h7vSMOO4mPWefGLUy3GmVFEREQEAPpSMROjwoPfjgRaDH6XXZ9W4uVv3vzozG/i5kmA/cFvZ9VvCfjXr/z5dEcqFYxy9Sg4ACQmJqJZs2bw9vZGdHQ0Jk6ciOLi4spUj6hOk4JRenkVjFTYWy8KEKe2hojry+D6CccLCjpLJgN6TgU6jK7c+VRtPvzwQzz33HMYO3Ys4uPjkZiYiOjoaCxatMhu+cWLFyMmJgaJiYmIj4/H2LFjMWbMGCxYsMBUZtWqVRg/fjzatWuH5s2bY+nSpTAYDNi6daupTP/+/fHee+/h8cfLWXusJvAJAcKai8+v7HNvXe4Qg1FEREQEAAZjf8OgcFV/w4lgFGBeN+rnV8RHpTdT7GqxCgejqmIUfNWqVZg8eTJmzJiBpKQkLFu2DGvXrsWUKVMq/86I6ih9qRSMctFIhVXj4CAYBZhT9bbOAkpyxeeVnRlFtUJpaSkOHTqEvn2tdyrp27cvdu/ebfecPXv22JTv168fDh48CK3WfpCjsLAQWq0WISF3MPLlTtICmSl73FuPO8RgFBHVdqmpqXj66acRGhoKHx8ftGvXDocOHXJ3tYhqHVMwymX9DYvB7/KCUR2fFxcbVxjvG3ufa+5PblHhBcwtR8EBcUbT77//jkWLFmHu3Lk25S1HwQEgPj4eBw8exIIFC/DEE08AEDsn9913H0aMGAEAiI2NxfDhw23WCCGi2zPopMahAgsKlifAIk0vopzGIaYLcGq9eUtWpTegsb9TF3mGzMxM6PV61K9vPb25fv36SE9Pt3tOenq63fI6nQ6ZmZmIjIy0OWfy5Mlo0KABevfufUf1LSkpQUlJiel1bm7uHV3PaTH3Aoe/Ag59JabqtRoCNL2z9+IODEYRUW1269Yt3HfffejZsyd+++03hIeH48KFCwgKCnJ31YhqHYNxwySDwsWD375h1kuElBXXDXhlP2AwiMuC3EmKHrldhYJR0ij45MmTrY5XZhR82bJl0Gq1UKlUuP/++/H1119j//796NSpEy5evIgNGzbgmWeecVgXt3UqiGo4g7YUACAoXBWMMo5UyBTmhQPt6fS8uBBg1gUg56rYAZcrXFMHqtFkZRa+FwTB5tjtyts7DgDz5s3DmjVrsGPHDmg0mjuq59y5c/Huu+/e0TUq5a7egG84UJABHFsj/hv5I9Dkweqvyx1gMIqIarMPPvgA0dHR+PLLL03HYmNj3VcholpMMA5+u6y/0airGIRqM9T+hkplyeWAr+Mdgal2qFCaXlWMggPAsGHDMHv2bNx///1QqVRo0qQJevbsaRP0sjR37lwEBgaa/kVHR1fkrRB5LuPuFi6bNhvRBlD5AnEPiDvhOSJXiJ3rTs8Dfd4FmvV3zf2pxqpXrx4UCoXN539GRobN574kIiLCbnmlUonQUOu0zgULFmDOnDnYtGkT2rQpJ0XUSVOmTEFOTo7p35UrV+74mk7xCwcmngBG/QzcZdzS+MCy6rm3CwUYg1ElOgOKtXo314aIqGJ+/vlnJCQk4B//+AfCw8PRvn17LF261N3VIqqddOKkEEFxZwOFJgFRwKQksQ9BdUalFjB39Sj4jh078P7772PhwoU4fPgw1q1bh19++QWzZ892eE23dSqIajiDzsUzo/zCgdeTgKe+d831yGOo1Wp06NABmzdvtjq+efNmdO3a1e45Xbp0sSm/adMmJCQkQKUyL4I5f/58zJ49Gxs3bkRCQoJL6uvl5YWAgACrf9VG6QU07g70mSW+PrtR3HmyFvH3UpoGK3M5O4qIapmLFy9i0aJFaNq0KX7//XeMGzcOr776KlauXOnwnJKSEuTm5lr9IyIAxplRULqovwE4NyOKPEqF0vSqahR8+vTpGDlypGkdqtatW6OgoAAvvPACpk2bBrncNmbm5eUFLy9u+U5kQ28cqVC68O+Daz+RA5MmTcLIkSORkJCALl26YMmSJUhJScG4ceMAiAMHqamppi/748aNw2effYZJkybh+eefx549e7Bs2TKsWbPGdM158+Zh+vTpWL16NWJjY01tiJ+fH/z8/AAA+fn5OH/+vOmc5ORkHD16FCEhIYiJiamut19x9VsADToAqYeAY98A973q7ho5TS6XIUCjQk6RFjlFWoQHuGg0lIioGhgMBiQkJGDOnDkAgPbt2+PkyZNYtGgRRo0aZfcct6V3E9V0xsFvKPldgCqvQjOjqmoUvLCw0CbgpFAoIAiCaRYVETlHZlxQEK5aUJCoHEOHDkViYiJmzZqFdu3a4Y8//sCGDRvQqFEjAEBaWprVbqtxcXHYsGEDduzYgXbt2mH27Nn45JNPTBtaAMDChQtRWlqKIUOGIDIy0vRvwYIFpjIHDx5E+/bt0b59ewBiUKx9+/Z45513qumd34H2I8XHI/8Dalkbx3WjiKi2ioyMRIsW1mtfxsfHO9wRHGAmBpEjMuPgN1w5+E11ToV306uKUfBBgwbhww8/RPv27dG5c2ecP38e06dPxyOPPAKFggsgE1WIqXFw4bRZonKMHz8e48ePt/uzFStW2Bzr3r07Dh8+7PB6ly5duu09e/ToUXsHK1o9Afw+Fcg8C1zZD8R0dneNnMZgFBHVVvfddx/OnDljdezs2bOmwRN7mIlBZJ8UjJIzGEV3oMLBqKFDhyIrKwuzZs1CWloaWrVq5dQo+MSJE/H5558jKirKZhT87bffhkwmw9tvv43U1FSEhYVh0KBBeP/9913wFonqFqlxkHHaLFHNpAkAWjwKHFsNHP6KwSgiomowceJEdO3aFXPmzMGTTz6J/fv3Y8mSJViyZIm7q0ZU68j1YpqeTMX+BlVehYNRgOtHwZVKJWbMmIEZM2ZUpjpEZEFmahw4UkFUY3UYLQajTvwA9H0P8Alxd42cwmAUEdVWHTt2xI8//ogpU6Zg1qxZiIuLQ2JiIp566il3V42o1pEbxMFvBfsbdAcqFYwioppLbhCDUXLOjCKquaI7ARFtgPS/xdlR9090d42cEsBgFBHVYg8//DAefvhhd1eDqNaT+hsylbeba0K1WYUWMCeimk8upelxpIKo5pLJgM4vis8PLAP0OtdctyQPuLgTMOhdc70yODOKiIiIlMZglELNwW+qPAajiDyMQmocmMNNVLO1egLwDgFyrgBnf7uzawkCcOon4LNOwMpHgN/edE0dy2AwioiIiBQMRpELMBhF5GGkxkHOxoGoZlN5Ax2eEZ/v+2/lr6MtAtY+DXw7Csi7Jh478AVw6a/bn5t1Afi/14BUx+s6WpKCUbkMRhEREdVZSkHsbyiZpkd3gMEoIg8jNQ5cUJCoFkh4DpDJgUu7gB3/Fmc43Y7BAOjEv3OUFgCrnwRO/wLIVcAD/wLaGRfj/fmfYqBKoisF0k8Axbni65xU4KtHgEMrgNVDgfyM2966QbD4pTMpLQ+CM3UlIiIij6MUxEEplRcHv6nyuIA5kYdRGBsHpZojFUQ1XlA08ODbwNZZwI65QO41wCcUuLgdCIwGBn1svdNeQaY4C+rKfiCyjbjW1PXjgNoPeOo7oFFXoCgbOL8VuHkBWPUPIKABkJ8unqMtBLwCxfWqkn4Gcq8ar5sBrH8JGPEdIHc8TtU5LgQalRyp2UU4ez0fzSL8q/b3Q0RERDWOyjj4rfJif4MqjzOjiDyMypimp2SaHlHt0O11oP98ADJxZ70/PwSuHRGDRUu6A9eOiuWyLgDL+gApewBBL5a5fhzwCgBG/igGogDAOwh4+EPx+aVdwN/fABd3iIEohRdQkgP8MQ+4cRrwjxQDUEoNcH4LsG9RuVXVqBTo2qQeAGDr6etV8dsgIiKiGk7NYBS5AGdGEXkYJaRps2wciGqNzi8AvqHAjg+AiNZiYGn3p8CtZDEgJVcCgkH8FxQDPPZfcRZV+t9A6yeBiFbW12s+EHjyf+LsKJkC8PIDojsDYc3FINcf/wGKbgJPfQ/UbwH0ex/49XVgy0zg7oeA0CYOq/pg83BsO52BbUkZGN/jrqr9vbiJVm/AP1cfQUJsMMZ2a+zu6hAREdUoaoi7ALO/QXeCwSgiD6MStICMM6OIap1WT4j/TK8fB9a/DJz5FTCIX/rQsCMwbDXgFy6+bj3E8fVaPGL/eMvHxH+CAMhk4rGE54CkX8T0wE3TgeGrHV72webivQ+n3MKtglIE+6qdfYe1xrEr2dh4Mh0HLt1kMIqIiMiC3iBADXFmlFrj4+baUG3GND0iDyIIAtTGmVFqjlQQ1W7ewWJQ6M1kYFISMPEU8NxmcyDqTkmBKOn5Q/8WZ1Gd+RW4sM3haVFB3mge4Q+DAOw8e8M1dalhbuSVAABuFpZCb6gbC7WfvJaDKev+xvXcYndXhYiIarASrRZqmR4A4MUFzOkOMBhF5EFKdAZTMIq7WxB5CJ8QICAKCGxgHUBytfDmQKcXxOcbp4iLozvQK14MiG1Juo7T6blYeyAFucXaqqtbNcswBqMEAcguLHVzbarHl39dwpr9V7D+SKq7q0JERDVYcZF5p14NZ0bRHWAwisiDlGgN8DLmcHuxcSCiiurxFuAdIi5ufuJ7h8UebF4fAPDL32l4KHEX3vrhON7+8UR11bLKSTOjACCroG4Eo7ILxWDizTryfomIqHJKis3BKLmKg99UeQxGEXmQEq0OXjKxQ8E1o4iowryDgXYjxOfSLn52tIsOQkSA+BmjVopfJX75+xouZRZUdQ2rhVUwKr9uBGcKSsSBjJwiz5nhdjvXsouQllN0+4JERGRSWlwIADBABihUbq4N1WYMRhF5kOIS81ofMiWDUURUCSFx4mP2ZYdFFHIZVj/fGV+MSsDh6X3Qs1kYDALw3z8uVlMlq1ZGnvmzNKugpJySnqOwtG4Fo0p1Bgz4ZBcGffpnnVkXjIjIFUr/v737Do+iWh84/p2t6Z2EhBp6FwhFmlgQrh3FAnYFFAtSfirYrl3uRa5iA66IWFDALnqRYqH3jnSUGgghCenJ1vn9cbIJIQkkpGzK+3mefXZ3dmbnnShzdt455z02lcS3Y67c8gGi1pNklBC1iCPvTgUAJqv3AhFC1FwhTdXzmcPnXa1ZvQAGtIsiwGri0StaAPDt5uO1ogD26cy61zMqs471jErPdZCa7SAp005mbsn10YQQQhRmt6tklAPpFSXKR5JRQtQitrN6RmGsfdOtCyGqQGhT9XzmiKrgXQrdm4bRvWkodpebWasOVV5sVaQu1ozKsqmZkepKMirX4cp/nWmXZJQQQpSWM1ddb9g1udYQ5SPJKCFqEYddus0KIcoppBGggSMLspJKvdkjlzcH4LO1h9l2LLVyYqsCbrdO0lm9oZIz68YwPU/NqNo0K+L5nJ2M8hy7EEKIC3M41PWGU5OeUaJ8JBklRC3iyJVus0KIcjJZIShGvT5P3ahzXdE6kstb1yPX4Wb4Jxs5klwzi5mnZNsL1RCqC7PL6bpOlqdmVHZdSUa5819nSjJKCCFKzWXzJKOkZ5QoH0lGCVGLOO2q26xD7lQIIcojpIl6vkDdqLNpmsb7d3alfUwQyVl27vt4AwcTMysnvkp09hA9qBs1o3IcLjz5twybE3cdKOh9ds+obJvrPGsKIYQ4m+d6w2mQZJQoH0lGCVGLOB15jYPcqRBClEd+3ajDZdoswGpi9v3daRDiy+HkbAa+vZzx87exeFcCqw8mcTip+veWOjcZlVQHZtM7u2eQrkNGHSjoLT2jhBDi4rjyklEuSUaJcjJ5OwAhRMVxerrNGqRnlBCiHELP6RnldoMzByz+F9w0MsiHeQ9dyis/72bp7lN8tzWe77bG538+uHMME69pS/1gn0oIvPwS85JR0cE+nEzLrRPD9LLO6RmUluMg2K92tyM5UjNKCCEuiiuvZpQko0R5Sc8oIWoRt0NdRDk1q5cjEULUaJ6eUZ6aUf8bD5Obwcntpdq8UZgfM+/txo+P9eH6TtF0bhRCy8gANA1+2HaCK/+zjOd/2Mny/aexOavXEClPz6g29QMBSM124HC5z7dJjXduMqYuzKhXqIC5zKYnhBCl5rnecEsySpST9IwSohZx5c2m55aeUUKI8ji7ZpQjF3bMB2curJsBN08v9ddc0iiE9+/smv9+5/E0XlzwJ1uOpjJn3VHmrDtKVJCVD+7sSremYRV8EBfHk4xqGRXI8v2ncetwJstOZFD17MlVEc4dplbXklEyTE8IIUpP9ySjjHLzW5SP9IwSohZxOVXjIN1mhRDl4ukZlRYPh1aAI1u93/U95KZd9Nd2bBjMN6N688kD3RnWozERAVZOpdsY+uE6Pl93BF33fuHs05nqPBoZaCXMX51Lk2v5UL062TPKWdDbTQqYCyFE6bmdqmaUJKNEeUkySohaxC13KoQQFSEgCoxW0F2w+ZOC5c4c2PlNub7aYNC4vHUkk27pyPKnLue6TtE43Tov/PAnU389kL+eruscTc5m5YHTzNtwlKW7T3EyLafSE1aJ6epHdmSQT0EyqpbPqFcne0bZpWeUEEJclLxkFEa5+S3KR4bpCVGL6Hmz6ckYbiFEuRgMqoh50n7Y/4ta1qQPHFkNWz6F7sMrZDf+VhPvD+tC+5ggJi/axzu/HSA2wp9+LSMY/9V2lu8/XWSbJuF+vDO0C50bhVRIDOfy9IyqF2Al3N8KZJJcy2fUy7YXLWBe2+VKAXMhhLgonmF6uqn2Dl8XVUOSUULUInreMD1d7lQIIcorJC8ZpbvBYIKbPoAPeqgi5ie2QUznCtmNpmk8enkL0nOczFj+F09/s4NQfzOn0m2YDBqxEf7EhPhyKj2XA4mZHEnO5o7/rmXyrZ2ICfHl972JBFhNjOrfHKNBK3c8nppR9QKthAfUjZ5RdXOYnhQwF0KIi6G5VDupyfWGKCdJRglRixQko2SYnhCinDx1owAa9YSwWGhzPez6DrZ+XmHJKI+nB7Xm79OZLNl9ilPpNppF+DP97jha581qB5Ce62DsvG38vjeRMfO2Fdp+5/E0pg7tjI/ZWOI+dF1nz8kMnG43nRqGFPk81+EiI1clJiKDrITn14yq3T2j6uQwPUdBzahMqRklhBCl5klGYZaeUaJ8pGaUELWJZwy3SZJRQohyCm1S8Lrl1eq5y13qec9P4HYX3aYcDAaNqUM7M7hzDHdf2pgFo/sWSkQBBPmYmXlvN0b0jc17b+KaDvWxmAws2pXAvR9vKDaRkmN38c6vB7jqP8u59t2V3Pj+an7afqLIep5eUVaTgUCrifAAdS5NqSMFzK0m9bMwvQ4ko3JkmJ4QQlwUzanaRE1ufotykp5RQtQmrrwLJmkchBDldXbPqBZ5yaiml4E1CDJPQfxmaNS9QnfpZzExdWiX865jNGg8f307RvRrRniABbPRwNq/knnos01sOJTCHf9dy2cP9iAySN2xPZyUxag5m9mbkAGAQQO3Dk99s53YCH86NAjO/+7Es4boaZqWP0wvqZYP0/P0DIoJ8eVQUlYd6RklySghhLgYmjtvmJ70jBLlJD2jhKhFDE5Pt1lJRomqM23aNGJjY/Hx8SEuLo6VK1eed/3ly5cTFxeHj48PzZo1Y8aMGYU+nzlzJv369SM0NJTQ0FAGDBjAhg0byr1fUUZRHUAzQlgziGqvlpks0GKAer1vofdiA+oH+2A2qp8xvZqHM//hXtQLtLI3IYMhM9Ywf+NRJv2yhxveX8XehAwiAiz857ZL2PrPgfRvVY9ch5uHPtuU3xsK4HRG3kx6geocmj9ML7N2D9PzJGNiQtSFRV1IRtnOGqYnNaOEEKL0DHk3vyUZJcrropJRFX3hAZCamspjjz1GdHQ0Pj4+tG3bloULvftDV4iaRnPnNQ4mKSgoqsb8+fMZO3Yszz33HFu3bqVfv35cc801HD16tNj1Dx06xLXXXku/fv3YunUrzz77LE888QTffvtt/jrLli1j2LBh/PHHH6xdu5bGjRszcOBA4uPjL3q/4iKExcLwJXDPD6CdVRi8zXXq2cvJqHO1iwni21G9aRLux7GUHCZ8u5P/Lv+bjFwncU1C+Xl0P4bENSTY18y7w7rQLMKfE2m53DlzHSfTcoDCxcuBOjdMLybYF6gbyajCPaOkZpQQQpSWIa9nlFFufotyKnMyqjIuPOx2O1dffTWHDx/mm2++Yd++fcycOZMGDRpc/JEJUQdpnjsVJl8vRyLqirfeeovhw4czYsQI2rZty9SpU2nUqBHTp08vdv0ZM2bQuHFjpk6dStu2bRkxYgQPPvggU6ZMyV/niy++4NFHH6Vz5860adOGmTNn4na7+e233y56v+IiNexWuHYUqJ5RBhOc3gvJf3knrhI0Dvfjm1G9ueGSGHrEhnH3pY2ZPKQTc0deSv3ggju4wb5mPrqvG1FBVg4kZnLr9LWs+SuJP+PTgbOSUf51Yza9zPyeUartSM+tA8mos2bTO7eAu6gbJk2ahKZpjB071tuhCFGjmPJufhstcr0hyqfMNaPOvgAAmDp1KosXL2b69OlMmjSpyPpnX3gAtG3blk2bNjFlyhSGDBkCwMcff0xKSgpr1qzBbDYD0KRJkyLfJYQ4P0Pe7BYGuVMhqoDdbmfz5s1MnDix0PKBAweyZs2aYrdZu3YtAwcOLLRs0KBBzJo1C4fDkd8GnC07OxuHw0FYWNhF71dUIN8QaNIHDi2Hfb9A78e9HVEh9QKtvDfs/HWnAJrVC+DbR3pz76wN/J2UxZ0z1+d/FhmoElfh/upcmmFzYnO6sJpKnqmvJvMMU2vgSUblOHC7dQwG7Xyb1Wg59oJklN3pxuFy5w/7FLXfxo0b+fDDD+nUqZO3QxGixjHkJ6NkmJ4onzK1up4LgHMvJC7mwmPTpk04HOrO24IFC+jVqxePPfYYUVFRdOjQgTfeeAOXq+Ru0zabjfT09EIPIeo6Y17jYJAx3KIKJCUl4XK5iIqKKrQ8KiqKhISEYrdJSEgodn2n00lSUlKx20ycOJEGDRowYMCAi94vSLtRoVpfq573/eLdOMqpYagfX4/qxRWt6xERYKVpuB89YsO44ZIYAIJ8TZjyEjK1eahe1lkFzEEVeM+s5XWUch2FZ4PMlqF6dUZmZiZ33XUXM2fOJDQ01NvhCFHjmHXVHpokGSXKqUzJqMq68Pj777/55ptvcLlcLFy4kOeff57//Oc/vP766yXGMmnSJIKDg/MfjRo1KsuhCFEr5d+pkJ5RogppWuHeE7quF1l2ofWLWw4wefJk5s6dy3fffYePT+EfPWXdr7QbFaj1Ner56Bo4c8S7sZRTeICV2Q/0YNPzA1j21BV89XAvYiP8AQrNqFebh+p5hqmF+puxmtRPw7Ts2j1U7+xhelD7k2+iwGOPPcZ1112Xf4PjfOQmhhBFmdyqfTDJMD1RThfVH7miLzzcbjeRkZF8+OGHxMXFMXToUJ577rnz1v545plnSEtLy38cO3bsYg5F1BHbjqWyN6H2/4AwSbdZUYUiIiIwGo1FbkYkJiYWuQnhUb9+/WLXN5lMhIeHF1o+ZcoU3njjDZYsWVJoKMXF7Bek3ahQoU2gSV/Q3fDtCHDV3sRFWN5QvROpOV6OpPJ4CpgHWE0E+6qhsrW9iLntnJ5RWVI3qk6YN28eW7ZsKba0SHHkJoYQRZlR1xtmq1xviPIpUzKqsi48oqOjadWqFUZjQS2Gtm3bkpCQgN1e/J1Iq9VKUFBQoYcQxUnMyOXmaav5x9SV3PvxBlYfTMLudF94wxrIKN1mRRWyWCzExcWxdOnSQsuXLl1K7969i92mV69eRdZfsmQJ3bp1K1Qv6s033+TVV19l0aJFdOvWrdz7BWk3KtzgD8AaBMc3wLLSXdjVRHFNQgD4ZvNx7wZSSdxuney8+kn+ZyWj0mt5MirHcU7PKElG1XrHjh1jzJgxzJkzp0hP25LITQwhCnO5dSy6ah/MFj8vRyNqujIVMD/7AuDmm2/OX7506VJuuummYrfp1asXP/30U6Fl51549OnThy+//BK3243BoPJj+/fvJzo6GotFpqgX5ZOYbiOvMx4r9p9mxf7TWE0GOjQIJsjHhMOl42M20i46kDbRQYT5W/CzGDEZDLh1HbeuY3e6VQJLA4vRQI7Dxf5TmRxOyqJeoJV20UHUC7RyJttOps1Jw1A/WkUF4Gcp2xwBadkODp7O5ERqDn4WI0G+ZvwsxrxhExqZNieZuU6iQ3yIDfcvUlzWrDtAA6NZus2KqjF+/HjuueceunXrRq9evfjwww85evQoo0aNAtQP+fj4eD777DMARo0axfvvv8/48eMZOXIka9euZdasWcydOzf/OydPnswLL7zAl19+SdOmTfNvaAQEBBAQEFCq/YoqENoUbnwXvr4fVr4FzS6H2Mu8HFTFu793LHPWHWXpnlMcSc6iSbi/t0OqUNlnJWXqUs+o3Lzj9rMYyba7pGdUHbB582YSExOJi4vLX+ZyuVixYgXvv/8+Nput0I1xUDcxrFYpfSBKJzEjl30JGSSk5ZLrcFEv0IfIICtOl06mzYGuQ4ifmWBfM74WE75mIxpgd6nrDJvTjc3pwmQw4GM2kJrtYNuxVPadyqBBiC+dGgYT7m8lJctOps1BgNVMqL+ZIB/1sJoN5Dpc5DrcBPiY8LcY80ci5TpcpGY7SM6ykZCWy/EzOSRl2vJvQpgMGjpqQofUbDtpOQ6ig31pFxNE66hAQvzMaJpGtt2JBdU+WKRnlCinMs+mVxkXHo888gjvvfceY8aMYfTo0Rw4cIA33niDJ554ooIOU9RlnrufkYFWrm4Xxc87TpKW42DzkTOF1vt1z6kK3a+mQaDVhMGgcXbKyN9qIjzAir/FSJbNSabNSUauepx7p/Z8gnxMdGgQTJNwf6KDfTiclMXduh00MMkPJ1FF7rjjDpKTk3nllVc4efIkHTp0YOHChfkzop48eZKjR4/mrx8bG8vChQsZN24cH3zwATExMbz77rv5s6sCTJs2Dbvdzq233lpoXy+++CIvvfRSqfYrqkj7m+Gv32HLZ/DbqzBi6YW3qWFaRAZweet6LNt3mtmrD/PSje29HVKF8iRhDBpYTYY6kYzSdT0/GRUeYCE7JSe/iLuova666ip27txZaNkDDzxAmzZtmDBhQpFElBBlcSI1h8vfXIbdVXj0hQUHdkxAySVtDLipTwoniCjTPq3YmWV+kw16Q1523lfkc1+zEV+LkcxcZ5G4yirQaqJekJX4MzksN+b1jLLKzW9RPmVORlXGhUejRo1YsmQJ48aNo1OnTjRo0IAxY8YwYcKECjhEUdd5hh+EB1h5/eaOvDa4A4eSsji8ZxOZhiDc/lGkZtvZczKDfacyyMh1kGVz4dJ1jLhpxClOmxtgzpvS2+FyYzRotIgMIDYigMT0XHafTCctx0Gon+pVdTgpk/ttc8h2WJnmGlwonjPZDo6fKbn2SP0gHxqF+WJzuknLcZBjd+FwuXG5dQJ9zPhajBxLySY918mav5JZ81dy/rYPWvLqfvgHVPBfUYiSPfroozz66KPFfvbJJ58UWda/f3+2bNlS4vcdPny43PsVVeiK52H7PDVc79gGaNTD2xFVuOF9Y1m27zRfbTrGuKtb5SdsagPP8DR/qwlN0+pEMsrh0nHn9ZgO97dyLCVHekbVAYGBgXTo0KHQMn9/f8LDw4ssF6Ks/jqdid3lxtdspFvTUHzNRiKSN/Fy2nPEa/X5xe8Gllmv5GSuWf2+d7jyyobovGd+j+uM63lEe47Npq643CphbjEZ6NgwhLbRgZxIzWXn8VQybS7C/M0EWE20yNpM36xd9GUXs1zXcFyPBNTNBbeubsiffaPbaNAI9bMQGWilUZgv9QKtZNtcpOU4cLp1BmV8R7ecVXzT5CVcgTEcTclm94l04lNzyLA5yTitzpNWY95NDClgLsqpzMkoqPgLD1DD+datW3cx4QhxXjl5yShfsxoCqmkazdLW0+z3WwANYvtBt+HQZ3DRjX8aC5tnw/X/hUuGln6nyX/Bez8CcMd9j2MPbgaADmTkOkjOtJPjcBFgNeFvNRHoYyLQaiY8wIK/tZh/lmeOwMGl0OVeMFlwuNzsPZnB3oR0jqZkcyI1l8ZhfsTuMEI6mMzSbVYIUUUCo6Dj7bBtDqz9oFYmo/q2iKB1VCD7TmUwa+XfjB/Y2tshVZizi5cDBNWBZNTZF2cRebMlZslsekKIcsi2uwghg1b16/P58J5q4ZxJkOakqX6cR7Km84jpZ3hsOfiruskutw67f8T4zXoAprfeDkOfLv1O12yFJerlskFJZF96N74mA+a9P5Id2YXTxkhyHC4CfcwEWNT1hsGggdutriuOb4Sej6h4zhyB9z4Ct4NnLfPh+pnqi/cvxp6ayJHGQ0jMtNMw1JeQGW5wAEYppyPK56KSUULUJDl2Gx+Yp+LObgr0UQvXvJf3qQ6HVqiH+WtoNbBgw7/+UIkogE0fly0ZlVDQDbzJiV+g1cS8YM5AeACYznPydrsh/TiENC54P+8uOLUT0k/AVf/EbDTQMSaAjpFmsJw1s8uuvB/YJklGCSGqUK9HVTJqzwL1gza0dg2X1DSNkZc148mvt/Pu7weJT83llZvaF3/zoIY5u2cUUCd6RtnyklGaBiF+qj2WAuZ107Jly7wdgqgl9LR4Nlgf5XBaa3CvgtQjcPBX9eEVz8Gm2ZB2DP54Da5/GwCjLRUWnZV82r8YslPAL6x0Oz3resO06xuC+j8JG2bCL0/hF96SJo+uBeNZPXndbtjyOax+F5IPqGXHNsA9P8DyyeDOO+/v/AoufQRy02DuUCy6m5Z3NaJlywHqc5ctb6dyvSHKp0yz6QlRE1lSDnKdcQM3ZH6lGoXT++HvPwAN7v8fdLxNrbj0n+DOS+bYs+CnMQVfcmw9nDlc+p2e+rPg9c6vQdfh5A54qx3MuYX8iupny0pSRYDf7QxTO8Lvr6nlu79XiShQvQ7SjoMjBz65Hqa0Ur2wPJx5s0+eL9klhBAVLao9NL8SdDes/6+3o6kUQ7o2YOyAlhg0+HbLcW6etprsWtCbxlMrqS4lo3IdqnaKj8mY3yNMhukJIcrDknIAi+ailX03bJylkk8Aza+C/k/DkI/U+82fqCSSrsOSFyDzFIS3hMh2Khm0+4fS7/Ts643Te+HI6oLZbZMPqHqOHgk7YdbVsGC0+swaBCZfOLQc/jcetn+p1muQN4Px/8bDNw+odh1gxWQVs8sJ7rzzpUlq1IrykWSUqPWcuRkFbxY/B+umqdetr4WmfeHaN8EnBE7vgW1fqhPtb6+oOxpBDaFRXlfbnV+XfqcJZzUOyQfhxFZY9Aw4suHwSthz1gyTuq4ai3e7wm8vq/0CrJiikmd/vKHem3zBmauKBP80Bo6uAXuGWq/gYNWzURoHIUQV6/WYet74Eexb5N1YKoGmaYwd0Iq5Iy8lIsDC/lOZfL813tthlVvBMD1VF7FOJKOcecP3LUb8845bCpgLIcrDZcssePP7q7D1c/W6+wj13LSPmvRDd8PP49TNac86N74Lne9Ur3d8VbodOm0qAQUQ01U9z78HclIKeiwt+xfYMlVPqP/2h/hNYAmEq1+F8bvhmn+r9TbPVnG1vhZu/1Rtf2KrGtER1VFdVxxbr0aSeHpFgSSjRLlJMkrUevrZjcPpvQVD73o+pJ59Q+Gyp9TrP16HT2+A9TPU+xumQtd71esdXxffo6k4njsVwXlD7X56Ao6sKvj8t1fUnYWMBPj8ZnWXwpYG9TvCTdOgyz2ADnOHqWSWbxjcldc47ZgHO+aDlvfPd8f8gl5bLk/PKGkchBBVrPlV0OZ69UN13p2wfb63I6oUPZuF88jlLQD4dM1h9NK2C9VU/jA9S+GeUem1OBnlqSXpYzLk9wiTnlFCiPIodL1hS1eJnKCG0GpQwfKrX1U3l49vVDPRGq3wj39Bk97QYQigwdG1hUdjZCSom+l/Ly+8w9P7VA8ln2DoO04ty0lRz0M+gtBYyEqED/vD0hdAd0HbG+HxDdDnCbAGqmucdjflfaGmhhMGNyy4ueQXAXfOg7i8mfpWvAnxmwtikJvfopwkGSVqPbctCwD97ClV67WB2P4F73uMVDWaMk6qnksmHxj4GrS8GtreoE62SfsKjc1G11XDkHGq8A5zzqgx4QBXPKuePdv1eFgllpIPqGGBH16hhgx69vfQcuhyF1wzWcXoSS71Gw+xl6kiwR7XTM4bFuOCVVNVPJ6eUZKMEkJUNU2D2z6BTneo89L3D8HP49U5sZa5rVtD/CxG9p/KZO3fyRfeoBo7t4B5sJ9KRiVn2b0WU2XLzasZ5WM25ifhpIC5EKI8dEc2AMnWRuC55oi7HwzGgpVCGsGVz6nXza6AR9eq2kwAQTHqtz4U9I5y5MCXd8Da9+GzG+F/T6pSIlBwbVG/E7QcCNZg9T72MnVjaMCL6n3yQXUD+x//hts/U/vx0DS44R3VI+rK56B+3qySlz0NV78C9/2kklN9xoDBrK6RPr1BrRMYA8aaXzdReJcko0St52kcjgV2UQkegJ4PqxOwh8mqkjsmX2h9HTy2HnqPVp/5BBfc1Th7qN6vL6qG4f3uBcP7AE7tUs/BjdVdDp8Q9T4gCq56AS57Ur1f9wFknICI1jBqldqfp8Gy+MGtH4PZH0KaFHTxHfASRHdWd0C6j1CNBcC2L9Q4cM8Ybot/ef9sQghRdkYzDJ4BvR5X7zfNgvfiYNf33o2rggX5mLmlawMAPltzxMvRlE/WOQXMW9QLwGzUOH4mh70J6d4MrdLkOlUNFKvZmH/cmTJMTwhRDlpekighsL1K5DS/EroPL7pi79Hw9CG453sIb174s053qOflk1Wd2AWj4eQ2MPup5RtnwqyBaoieZxRGVAcw+6gb12HN1PWMpkG7wSrJFFAf7voGLh1V+NrHwzcUhs0tGCUC6vv6jIGodup9cEPocrd6bTCp1w/WvuH4oupJOlPUep7GwWkOgLs/hyNroMOtRVdsfQ08ewIMxeRoO92uZola/191ogdY/Y56tqXBD4/AvoVw6ycF9aLqd1CFxLveC2veVT2frIHQbTismwFpR9WdjCEfqYTXuaLaw5htatpUs69aFtwAHj6rm26TXtCkrxoCeHyjaqwuf6b47xNCiKpgMMCg16HVP2Dhk2p49Nf3q6EGnjvAtcC9vZoyZ91RluxO4GBiBs3rBaAV90O/mss8p4B5qL+Fq9pEsWhXAl9vOs4L17fzZniVwtMzytdsyK+VJcP0hBDloeXd/NbN/moYXJ8nSl65pNnyOt0O+xepa47FeaMrDCa48ys1WuLbESoJtX3uWT2jOqrnvmPVIz8gDe74Qj1XRNv0j0nQsLuqfRXatPzfJwSSjBJ1gKdxcJv9VGa/0+0lr1xcIgqg1TWqy+ven+HnsQXL+09QiaI/3lBFyf/8tmDmu6i8rq5XvQiXPgpB0eq92QceWAgnt6sE2Nndd88VEHnhAxz4Knw7HBr3hiufL9iPEEJ4U2w/1etzyfOqDt+iiZB6DBpfqnpv1u9YunNcNdUqKpDezcNZ81cyA95aQZCPiU4NQ7i6XRRXtomkQYgvBoNGYnouqw4mkWVzMrRHY8zG6tUpPb9nlKWgLbq9e0MW7Urg+63xTPhHGyym6hVzeRUapic1o4QQFUBz5JUFMZdjdILRrIbSbfpYTXzksqki47H91OeXPQWLn1HlOTxD4D1D64pT0nXNxTD7qlIiQlQgSUaJWi//TkV5hq4ZTXD757D2Pfj1ZVUP5ZJhqheSpoHbpWbOWD1V9WSCgsbBaCqaIApppB4VoUFXeGJrxXyXEEJUJKNZFWf1C1cTRKz7QD086rWFZv3VcIamfWvcEOP/G9iK4/O3czQlm/RcJ6sOJrHqYBIvLtiF0aAR4msuVHtpzV/JvDusS7VKSHlqJXmSMgCXtaxHZKCVxAwbv+9N5B8d6nsrvEpRbDJKakYJIcrB6FTXG+VuxzRNDe9rfiWkx6u20SPuPlVE/Mwh9d5gKihBIkQNJMkoUevlNw6e8dYXy2BQ46eb9lPTnXa5p6Dba/cR6i5F4u6C9aPOc6dCCCHqCk2D/k+r+nc75oE9W93RTdoHp/eox/oZKpHfYYiaxSeqA+SmqllHA+p5+whKFNckjBVPX0Guw8WhpCxWHjjN4l2n2HL0DC63TnKWHU2D9jFB7E/I5Jc/E3jsiy10aBDMzztOcCQ5G6vJQKCPmX8N6Ui/llV/rPkFzC1GyE4BvzBMRgO3dG3IjOV/8fWmY7UwGaVqRvmYDQUFzKVmlBCiHEx51xsGazmvNzzCYtXjbBZ/6DkKlr2h3ke0lkmLRI0myShR63mSUYaKuuPeoKt6nM03BLo9oGpDgSo8HhpbZFMhhKizLrlDPTyyktXMPH//AQd/V3X0ts9VD5MvOHMATdXV61hMnb9qxMdspG10EG2jg3josuY4XG5SsuwkZdqIDvYlzN/CH3sTeXjOZpbsPsWS3QWzsNqcbtJznbzy024Wj70Mg6Fq6055kjAdj3wCC/8Dw+ZB62u4rZtKRv2xL5FT6blEBflUaVyVqXDPKDU8MVOG6QkhysHkygFAswZU7o56jFTXG/bMgnpRQtRQ1aefuBCVpMoah0sfLRiiF9WuYsdpCyFEbeMfDu0Hq2mlx+6AEb9D+1tAM+YlogB0+GkMJB3wZqRlZjYaiAryoX1MMGH+ql24ok0kM+/tRoMQXy5rVY8pt13Ciqeu4Jcx/Qj0MXEgUfWcAth/KoMZy/8iLdtR6bF6kjD1UvOGex9aCUDzegHENQnFrcOP2+IrPY6qVNAzykhA3jA9u9ONw+X2ZlhCiBrM7Fbtlqmyrzf8wqB3XnH0lldX7r6EqGTSM0rUepa8xsForeRaJEHRcMlQ2PIZNIir3H0JIURtomnQMA5umw1ZSZCbpoqbzx2mek99dR/c9D4c/A1s6dDv/1SP1Bqmf6t6rJ54ZZHlD/aJ5Z3fDvDubwdoEu7HnTPXkZ7rZN6Go3x0XzdaRAbiduvkOFz4WYwlztrndLnJdbrxP8865/LUSvLNTVILUv7O/+yWrg3YfOQM322J56HLmhe3eY2U4+kZZTIWqpWVZXMS4mfxVlhCiBrM4s4FwOgTWPk76/80dLkbgmIqf19CVCJJRolaz+zyJKMq+U4FqEK99Tupu/tCCCHKzj9CPUAN0ZvRFxJ3wcwrCtbZ/aNKXHkS/zmpavahv5ep2n4trqrqqMvlwT6xfLzqEPtOZTBk+hpsTjeaBoeTsxn8wRraxwSx60Q6mTZnfmH0QR3q8+jlKkH07m8H+Gn7yfwkS8vIAF4b3IGezcIvuG9PzShL7mm14Kxk1PUdY3h5wW72JmSw+0Q67WKCKvjIvaNgmJ4Bs9GAxWTA7nSTZXcRUkHlXoQQdYs17+a32bcKJuLQNAhuUPn7EaKSyTgiUetZdHWnwuRbBckoi78ay+1/4QsAIYQQFxBYH26ZCQazqiPV6hpVCD31CMwaBDOvgs8Gw9sd4LeX4dBy+OJWWPU26HrR78s4Bd8Mh48GwKldVX44JQn2M3N/n6aAqiHVoUEQf/zf5fRoGkamzcn6Qyn5w+k8hdG/XH+UK6Ys48opy/lq0/H8RBTAgcRM7vhwHU9/s52/T2eed9+ZNicabkw5ecmoM4fB7c6P66q2kQB8v/V4xR60F9mc6m/la1b1ovwt6jlL6kYJIS6ST971htm3CnpGCVFLSM8oUev5uHPBUEXJKCGEEBWr+RXwf3vVjKgWP9ULasFo2LMA4jcVrFevLdRrDbt/gF9fgr3/g5aD1IQTmkElWX57Wc3kByohdeN7xRdHt2fDmvcg+hJo/Y/KP0ZgeN9YvtsST4ifmc8e7EmYv4U5I3ry0/YTuHSdjg2CaRTmR5bNycHETKYtO8jqg8mATq9m4Yy7uhWtowJxuN38Z8l+5m44ylebjvPVpuP0jA3jgT6xDGwXVahAelq2g1yHmzAy0dx5iRiXDTJOQHBDAG7u0oBf/kzgx20nmHhNW4xVXGC9MpxdMwrA32riTLZDipgLIS6Kruv4opJRVklGCVFqkowStZrT5S5oHKpiDLcQQoiK5xm2B6pW1O2fwcntkH4CclNV3YzY/mrowqaPYeHTcHyjepyrfifwDVW9qL4dDru+h96joVFPtX1uOswdCkdWq0kpRm+GkMaVfoghfhZWPq2GInoSRhaTgSFxDQutF2A1ERXkQ58WEWw/lorD5SauSWihGlGTbunIkK4NmL5MzYa3/lAK6w+l0KZ+IPf2akr9YCunM2y8uXgfAA3NaYWDSfk7Pxl1eetIQv3MJGbYWH0wicta1ausP0GVybEXDNMD8ouYS88oIcTFsDnd+GIDwOIv1xtClJYko0StluNw4avlNQ5+0jgIIUStoGkQ01k9ztXtQWgxAA4shUMr4PReMJhUYqnt9WoWIs0Av7+qhvPt/Vk96rWBxpeqJNeJvJnlXHb4YxLcPL1KDstQxl5HlzQKKfGzbk3DmHV/GCdSc5iz7gifrT3C3oQMnv1+Z6H1mtfz582eUfDrWQtT/obYywCVELu+UwyfrzvCM9/tZHjfWG7t1pAgH3OZYq1OcvOG6VnP6hkFkowSQlycbJuTkLyb375+taO2nhBVQZJRolbLcbjw89ypkGF6QghRN4Q0hu7D1aMkA16CTkNh7fuwY75KWp3eqz7zDYOrXoCfx8H2udD7cYhqXyWhV7SYEF+e/kcbHrqsGZ+sOcymw2dIy3Fgc7q4qXMDRvZrhuXPeYU3OquIOcCDfWNZuPMk8ak5vPLzbj744yBzRvSkbXTNvOjyFDD3LZKMcpW4jRBClCQ7J5MwTdUpNPrI9YYQpSXJKFGr5dhdBOfdqdAsVTC7hRBCiJojsg3c9D4MeBmOrlHD+lKPQf8J6rO/l6saVL+9AnfO93a05RLiZ2HsgFbFf5iRkPdCA3RIOVTo49gIf1Y8fQXfbY3n41WHOJSUxT2z1vPVw71oVq/mXXgVqRnlKWBul55RQoiys2dnFLwxy5ScQpSWzKYnarUcmw2rlvfjUpJRQgghiuMfDm1vgKtfgdtmq0QUwJUvgGaE/Yvg2AbvxliZMk+p58h26vmcZBSo3kP3XNqEHx7rQ7voIJIy7dz10XqOpWRXYaAVw9MzylMzKirIB4B9CRklbiOEECWx5SWjcrGAwejlaISoOSQZJWq13LPvVEgySgghRFlEtIBLhqnXG2YWLM9JhfSTXgmpUnh6RjXppZ5T/gZdL3bVYF8znw/vQYvIAE6m5XLnR+uIT82pokArRkEySl009m+tirL/ticRvYTjFkKIknh6RuVqPl6ORIiaRZJRolZz5jUOLgyqeK0QQghRFp66U7t/gKwksGfBh5fDe13h9H5vRlZxMhPVc8Puqri7I6tgWTHCA6x8MaInsRH+HEvJ4c6Z60hIy62iYMvPM0zPUzOqV7Nw/CxGEtJz2XUi3ZuhCSFqIGduJgC5mq+XIxGiZpFklKjV7DmqccjRfNXsS0IIIURZNOgKMV3UzHpb58CKN+HMIXBkw68veju6ipGZ1zMquBEEN1Svzylifq6oIB++HNmTxmF+HEnOZtDUFUz4ZgcrD5yu9r2L1Gx6Oo2Xj4MfH8fHZKBfywgAlu4+5d3ghBA1jiPvesNukJ5RQpSFJKNErebIu1Nhl26zQgghLla3B9Xzuumw5v28hRrsWwiHVnotrAqTkZeACawPYc3U6zNF60adKzrYly9H9qRZPX/SchzM33SMe2ZtYPTcrWRX42LgOXYXoWQQtP9b2Po5ZCYyoG0UAL/tlWSUEKJsPD2j7AbpGSVEWUgyStRqrly5UyGEEKKcOgwBa7DqQeR2QMtBBcP3ljwHbrd34ysPW4YalgcQEFWQjLpAzyiPhqF+LB3Xny9H9uTOno0xGTR+3nGSW6at4a/TmZUU9MXTdR2b002IllWwMGkfV7SJRNPgz/h0TqbVrBpYQgjv0m3qXOc0SjJKiLKQZJSo1Vw29WPTIY2DEEKIi2Xxh0uGqtcmH7jm33D5M2ANgpPbYfGzkFtDaw15ekVZAsAaAKGx6n0pk1EARoNG7+YRvHFzR+Y+dCkRAVb2JmQw8O0VPPn1dg4lZV34S6qIzakShyGclShL2k9EgJWujUMBVchcCCFKy21X5zin0c/LkQhRs0gyStRqbk8yyiCNgxBCiHLoMwaa9IXr/gNhseAfAZdPVJ+tnw7vXALrP6x5vaQy85JRAWqYWn7PqMQ9F3Us3ZuG8fPovlzeuh4ut843m48z4K3lPPX1do6lZFdQ0BfPM5Ne8Nk9o/IK0XuG6kndKCFEWeh51xsuk9z8FqIsJBklajXdru58SuMghBCiXIIbwAP/gy53Fyy79FG4Yw5EtIKcFPjlKZhzM6Sf8F6cZeUpXu5JRsV0Bs0IibvV8VxEMfL6wT588kAPvn+0N1fkJaW+3nycK/+zjGe+28GRZO/1lPLMpBdmKDxMD+DqdupvsPpgEkmZtiqPTQhRM2l5Q53dZn8vRyJEzSLJKFG72eVOhRBCiEqiadD2BnhkLVw7BUy+8PcyeL+7eszoB989DH9+B7lp3o62ePnFy/OSUcENYfA0QIONH8Hi5y4qIQXQpXEos/OSUv1aRuBw6czdcIwrpixj4rc7sDldFXMMZZCT1zMq3HhWXaikAwC0iAzgkobBON06P2yNr/LYhBA1U34yyiQjMYQoC0lGidrNoYYEuExyp0IIIUQlMZqgx0gYtRKiO4M9E5L2Q8IO2DEPvnkApnaChJ3ejrSo/J5R9QuWXTIUbnhHvV73ARxYWq5ddGkcyufDe/L1qF70b1UPtw7zNh5jzNxtOF2qp9Kp9FzScx3l2k9peIbphRnPGjKYHq8KuQO3dmsEwDebj6NfZBJOCFG3aHnXG1jkekOIsrioZNS0adOIjY3Fx8eHuLg4Vq48/7TGy5cvJy4uDh8fH5o1a8aMGTNKXHfevHlomsbgwYMvJjQhCtHseY2DWe5UCFFZKrpN2LVrF0OGDKFp06ZomsbUqVOLfEdGRgZjx46lSZMm+Pr60rt3bzZu3FiRhyVE2UW0hJG/w0PL4f7/wbD50Hs0hDSG3FT44RFwVX7CpUzO7RnlEXcf9HhIvd7yaYXsqnvTMD59sAezH+iOxWhg0a4EHv1iC/fP3kDPN37jyinL2HE8tUL2VZL8ZJR2zlDBvN5RN3aKwWIysDchg10namhRelGsSZMm0b17dwIDA4mMjGTw4MHs27fP22GJWsDoVNcbmkWuN4QoizIno+bPn8/YsWN57rnn2Lp1K/369eOaa67h6NGjxa5/6NAhrr32Wvr168fWrVt59tlneeKJJ/j222+LrHvkyBGefPJJ+vXrV/YjEaIYRqf6salLMkqISlEZbUJ2djbNmjXjX//6F/Xr1y/2e0aMGMHSpUv5/PPP2blzJwMHDmTAgAHEx8vQGuFlBqOqu9S0L7T+Bwx8DUb8Br6hqmfUqqngtMP2ebDkBfX49WXY+Q2kHILjm2DZv2HBaEg/Wfnx5hcwL+bfWtwD6nn/IsisuBnmrmgdyQd3dcVk0Fiy+xTL9p0GICnTztAP17FsX+XNZuepGRViODcZpYqYB/uZGZhXO+rrTccqLQ5R9ZYvX85jjz3GunXrWLp0KU6nk4EDB5KVVX1mexQ1k8mVN+zXEuDdQISoYUxl3eCtt95i+PDhjBgxAoCpU6eyePFipk+fzqRJk4qsP2PGDBo3bpx/Z7tt27Zs2rSJKVOmMGTIkPz1XC4Xd911Fy+//DIrV64kNTX14o5IiLMYnHmNg1W6zQpRGSqjTejevTvdu3cHYOLEiUW+Iycnh2+//ZYff/yRyy67DICXXnqJH374genTp/Paa69VxqEKcfECIuGayfDdSFj+b9g8Ww0Nu5Aja1QPq8Dik7IVIrOEnlEAUe2gQRzEb4Ydeb28KsjV7aJ4b1gX3vntAH1bRHBz1wZMWriXVQeTuH/2RiIDrcRG+DOofX3uurQxVpMxf9u0HAdPzN2K3elm+t1dCfGzlHq/np5RIagJTjD5gDM3PxkFcFu3Rvy84yQ/bj/Bs9e1LbRvUXMtWrSo0PvZs2cTGRnJ5s2b89sSIS6GJxllkOsNIcqkTD2j7HY7mzdvZuDAgYWWDxw4kDVr1hS7zdq1a4usP2jQIDZt2oTDUdBV/ZVXXqFevXoMHz68LCEJcV6exkGTMdxCVLjKbBPOx+l04nK58PHxKbTc19eXVatWlbidzWYjPT290EOIKtPxNmh1DbgdKhEVUB96PKwSPN2Gq6SPwQzWYGh7IwQ3guSD8OkNldtDKuOc2fTO5Zk9cOuciy5kXpJrOkazaOxlPH99O9rHBPPx/d25vVtDABIzbKw/lMIrP+9mwFvL+X7rcexON5k2J/fP3sDy/adZ+3cyD3++uUyF0D3JqCDyesPEdFXPpwuGa/VtEUH9IB9Ssx18ub74Xp6i5ktLU5MKhIWFeTkSUdNZ8q43jD7SM0qIsihTz6ikpCRcLhdRUYV/sERFRZGQkFDsNgkJCcWu73Q6SUpKIjo6mtWrVzNr1iy2bdtW6lhsNhs2W8G0u3JRIYpjdqkx3Ea5UyFEhausNuFCAgMD6dWrF6+++ipt27YlKiqKuXPnsn79elq2bFnidpMmTeLll18uxZEJUQk0DW56H5b9C+p3gEuGgclaeB2XAzSDGuqXcgg+uV712JnaEZpfCe1vhjbXgU8QHF0Hv+f1AhzyUUHvqdx09b2e73bkwt6foVEPVbvqbGcOQ06Kel3cMD2ADkNg0bNweq/qIdWwW4X8OYpjMRmYfOslPHdtOw4lZ7H16BmmL/uLYyk5jJu/ndd+3kNEgJV9pzII9jXjduusP5TC09/sYOodndE07YL7yM1LXAXqeT2jGvWAo2sK9YwyGjQeu7IFL/zwJ28u3sfA9vVpECKz8tYmuq4zfvx4+vbtS4cOHUpcT643RGlY3CoZZZJklBBlUuZhekCRxl7X9fP+AChufc/yjIwM7r77bmbOnElERESpY5CLClEaZlcuAEarNA5CVJaKbBNK6/PPP+fBBx+kQYMGGI1Gunbtyp133smWLVtK3OaZZ55h/Pjx+e/T09Np1KhRqfcpRLn5R8B1U0r+3GgueB0WC/f/BF/fDye3w4HF6mG0qmRW/OaCdT8epIql7/4RVr2lJu3oPgLqtYbfXoHUI+BfDx5YBBEt1Da2DJg7TL1u2AP8Sugd4hMM7W5SswL+NAb6T1AJMUPlDV0L9jPT2S+Ezo1CuKN7Iz5edYjP1h4hMcNGcpadAKuJzx7sQUau6iX147YT+FlMvDa4A25d5z9L9vPH3kRaRAbQpXEIjcL8CPO30CTML79mVEB+Mqqnek75WyUD8/4b3NWjMQu2xbPx8Bme/34nH9/fvUznKFG9Pf744+zYseO8vWlBrjdE6Vh1db1h9gn0ciRC1CxlSkZFRERgNBqL3PFOTEwscqfbo379+sWubzKZCA8PZ9euXRw+fJgbbrgh/3O3W/1QMJlM7Nu3j+bNmxf5XrmoEKVh0aXbrBCVpTLahNJq3rw5y5cvJysri/T0dKKjo7njjjuIjY0tcRur1YrVai3xcyGqnbBm8PAKSNwLu3+AP79VPXjiN6seVJfcCUdWqR5O03oWbOfMhRWTz/oiDbJOw2c3wYOLVLJqwWhI3K2G593+qeq5VZJej8KeBXDqT/jqHohoBXd/W7SnVSXws5h4/MqWjOrfnGX7TrNsfyK3xTXikkYhAPx7SCee/GY7czcc5XSGjbQcOxsPnwFg36kM/rezYIijpkF0kBre6+fOUAuj2oHZHxxZqjdavVYAGAwak27pxLXvrOSPfaf5cdsJBndpUOnHKyrf6NGjWbBgAStWrKBhw4bnXVeuN0Rp+ORdb1j85HpDiLIoUzLKYrEQFxfH0qVLufnmm/OXL126lJtuuqnYbXr16sVPP/1UaNmSJUvo1q0bZrOZNm3asHPnzkKfP//882RkZPDOO++UeMKXiwpRGlZ33p0KXxmmJ0RFq4w2oaz8/f3x9/fnzJkzLF68mMmTJ194IyFqmsg2EDlR9UpK2AnH1kOT3hDVXtV8+vwWSNwFgTEw8FUwmGDNeyrZ1Otx6HIXzBmialC92xncTvW9RisM/RKCYs6//+hLYPQW2PgRbPpYJcQ+vQHuXwjBVZOgMRkNDGgXxYB2hRPdQ+Ia4m818sS8bfy6RxVjD7SamHhtG1KzHew4nsqpdBspWXaOpmRzIi0XK3Ysul19gW8YRLSEk9vUceUlowBaRAYw+soW/Gfpfl744U+6NA6hSbj8nqipdF1n9OjRfP/99yxbtuy8Ny885HpDlIaPbgMNLH7SM0qIsijzML3x48dzzz330K1bN3r16sWHH37I0aNHGTVqFKDuIMTHx/PZZ58BMGrUKN5//33Gjx/PyJEjWbt2LbNmzWLu3LkA+Pj4FBmrHRISAnDeMdxClIaPngsamH2CvB2KELVSRbcJoAqj7969O/91fHw827ZtIyAggBYt1BCjxYsXo+s6rVu35uDBgzz11FO0bt2aBx54oIr/AkJUIU2D6E7q4RFYH4YvhkMrIfYy8AxLbz8Y3G4w5M1Vc++P8PE1kJZXkDukCQx6vfQ1oIKi4aoXoPtwmH2N6o316Q3wwC/Fz8RXhf7RIZrPH7Tw6BdbiAzy4YM7u9CsXtEeCkeSs5i74Rh/7t0LaYBmBGsgRLZTyajdP0Lb6wttM+ry5qw4cJqNh8/w6Bdb+PaR3viYZXa9muixxx7jyy+/5McffyQwMDC/l25wcDC+vlITTFwcl1vHD3Xz2+on1xtClEWZk1F33HEHycnJvPLKK5w8eZIOHTqwcOFCmjRpAsDJkyc5erRg5pHY2FgWLlzIuHHj+OCDD4iJieHdd9/Nn8JbiMqi6zo+eY2DdJsVonJURptw4sQJunTpkv9+ypQpTJkyhf79+7Ns2TJAzYL0zDPPcPz4ccLCwhgyZAivv/76RfWuEqLGswZCm2uLLjecNWlycEN4ZBWkHlP1qC52ltmgGLjvJ5h9HaT8Bf8bD0O/uLjvqkA9m4Wz7tmrMBm0Ems7NQn3Z+I1baCrG6YDviEqwddjJGz/EnZ+BT1HQcO4/G3MRgPvDevKte+uZNeJdF7+aTeTbulYNQclKtT06dMBuPzyywstnz17Nvfff3/VByRqhZzcHAI0NTGCjySjhCgTTdcreJ5eL0lPTyc4OJi0tDSCguREINT0zY7XGhCo5ZD18Ab8o1t7OyQhvErOk4XJ30OIcji1G2b0Ad0NDy6Bxj0vvE11cWSN6t0V1hyeyJv04PtRsH0uNLpU1dU6J6G1Yv9p7pu9AV2Hl29sz329m1Z93F4g58nC5O8hznU68ST1prUBQH/+NJrJ4uWIhPCuspwnDef9VIgaLNvmzO826yNjuIUQQoiKE9UOOt+lXi/9pxoSuPYD+PRGOL3fu7FdSE6qevYNKVh21T9VYfdj62DX90U2uaxVPZ4apG5qvfzTLn7dfary4xRCVHu2bDUZgl03SSJKiDKSZJSotXJyszFqquOf0SrD9IQQQogKdcWzYPJVCZyZl8PiZ+HQcvjhEZWcAlj2b/jkeshK9mqoheSo2fbwDS1YFhQDfcao18smQTEDBx7p35yh3Rvh1mH03K1sOXqmCoIVQlRnnmRUjubj5UiEqHkkGSVqLVtWesGbi62NIYQQQojiBcXApY+o1ye3q9n5zP4Qvwm2fAKbZsOyN+DwSljzrldDLSQ3VT37hBRe3usxdQxJ++H03iKbaZrGq4M7cFmreuQ4XNw1cz1/7Eus9HCFENWXPScTgFxJRglRZpKMErWWPVs1DjbMYJCZb4QQQogK13cs1GujHsOXqOFuAEtfhIVPFqy3cVZBjyRvK65nFKhC8M0uV6/3/Fzspmajgel3daVfywhyHC5GfrqJKYv38f3W42w5eoZaUopVCFFKzhzVM8omySghykySUaLWsuc1DrlI4yCEEEJUCp9geGQtPLYeYjpD9xFQvxPY0sHthPY3Q2R7sGfAho+8Ha1SXM0oj7bXq+e9P5W4ub/VxKz7ujO4cwxOt877fxxk3Pzt3DJtDaPnbiXb7qzwkIUQ1ZMjN+/mt8HXy5EIUfNIMkrUWgWNgySjhBBCiEpjOOvnpNEEN0wFkw/EdIWbpkHfceqz9dPBlgmpRyE7xSuhAgXD9M7tGQXQ+lrQDGrY4ZkjJX6FxWTgrds78+rgDgzuHEPv5uGYDBo/7zjJLdPWcCgpq3JiF0JUKy6but5wSDJKiDKTZJSotaTbrBBCCOEFDeJg3G54cDFY/FTvqNCmkJ0Mk5vB1I7wbhfI8NKMdJ5heufWjALwj4DGvdTrvf8779cYDBr3XNqEqUO78OXIS5n70KVEBFjZm5DBwLeX8/wPOzmVnluxsQshqhV3rko8O4ySjBKirCQZJWotl001Dnajn5cjEUIIIeoY/3DwTHNuNMFlT6nXLpt6zk2F9TO8ElrBML1iekYBtPEM1Su+blRJujcN4+fRfenXMgKHS2fOuqP0/tfv3P7ftUxf9hcpWfaLj1kIUS258643nJKMEqLMJBlVB+XYXew8nlbri2x6klFOGaYnhBBCeFfnu+DBJaq+1G2fqGUbZ0Fu+nk3qxT5BcxDiv+8zXXq+ehaOL2vTF9dP9iHz4f3ZO7IS+neNBSXW2fDoRT+vWgvt0xbTXxqDgAOl5u9Cem43bX7t5gQtZ5DDdNzmeTmtxBlJcmoOui5H3Zyw/urGPHpJhIzam/3cd2uGge5UyGEEEJ4maZB454Q1Q7a3gQRrcCWBps/KVjHaYNfX4KZV8GpXZUXi6dmVHHD9ABCm0CDbqC7YXofWPI82DLKtItezcP5elRvVj59Ba/e1J6Gob4cTs7m9hlr+XjVIa76z3L+MXUlD3yykbRsR7kORwhRRk4bOCroGsieDYBulmSUEGUlyag6aM9J9YPqt72JDHp7BTNX/M3R5GwcLjd/xqexePVG9p5M9U7PKZcj/6ReXrpNfY9T7lQIIYQQ1YfBAH3GqNdrP4D0E3BkLcy8Ela9DfGb4Kv7wH6eIuBOGzjPGfaWeuzCPa10/cLD9ABunQXNrwK3A9a8B1/dq7Yto0ZhftzTqylfj+pFswh/4lNzeOXn3RxNUb9Rlu8/zY0frOL3vafYl5BBUqZNekuJ2s/tgsOr1XNxn/35HSQdrJx927Phgx7wfvfCdeuyksCRc/5tD6+GD3rC/iX5izSHOk+5zf6VEa0QtZrJ2wGIqucpptkgxJf41BxeX7iH1xfuwWI0MJRfeMX8KbOc1zA84CHaRgdid+m43TotDCe4J/kd4s1N+NDvIbKd0DjMj8bh6uSbmevEresE+pgI8jET7Gsm2M+M06WTlGkjI9dBiJ+FiAALNqeb0xk2smwutb6vGYfdztWrh+JvS2THP74muml7fMwGjK4cAn0sWHzVftJzHew8nkZSpo1MmxO3W6eBK56uO18h7ZKHMLS5BpNRIzdbJd3ckowSQgghqpeOt8Pvr0PGCXirbcFyvwgwGCH5APwyAW56XyWBzhyC45tVourYBkjYCQGRcO8CiGgBe35WCaOASBj5BwRFF79fWwboeRfAJQ3TA1Vw/Z7v1EXn/Lvgr99h/yJofc1FHW50sC/zHr6U4Z+oXukj+zWjS+NQxszbypHkbB78ZFP+ukaDRr0AKwPaRTJuQCvCA6wXtU8hqguXW8do0Are/+//MG6ejavbCIzX/6dgRVsmfDsC9v8ClkD0u75Cb9QLg+6E4xvVDJ3mcpbf2PYFnDmsXn87HO79EXZ+DT88CvXawMjfC+1D13XsLjdupwufn8ehJe2DhU9C881gNGNwSM8oIS6WJKPqGJvTlV9A86cbNexL32KZswPPJQ+kofs4z1q/BOB+4yK+TuvPr6mNAehj2Mk48zsEa9k0ZyvJyaf5P8cjpB3bRWvjCha5urNdb1Gu2K41rGOYRdVmCPxxOFfbX6aHYS/TzO9wVA/lYZ830XwC+et0ZpGbk5+ZJxFi3EnO4v30X2DEjpknTQkMMoFbGgchhBCiejFZ4IpnYMFoQFO9lJr1h2smw+m98OmNsPVzSDoASfsK6jydLT0ePr0BBrwIC55QSaaMkyopdf//Cgqon80zRM/kA+ZSDONvNRB6PaZ6bC1+TvWWKu57SyEy0IcFj/cBQNPUhfmCx/vy2s+72RmvbrKdyXbgcuskpOcyZ91Rftx2grEDWnFfryaYjDKgQdQcH638mxnL/8aWm8UV7g0c8OmAT0Rj2uVu4/X02QBoG2fxf/taczygI8bME7yU+Sqt9EPqC+wZ5Hw8mJmu67jNtIoYEllr6sl4w9M43DomgwGTUcNo0DBqGjanm0ybE6fLTXiAlfAAC1k2J+3SVhLmTGSeNgizwcBPTKaxJy92eCXbJ13BJY7t6n3iLpb+9ylWNnqYvQkZ7EvIICPXgVuHW43LmWLOqyGXeoSJLz3Pd+5+zDXuAwNo1oCq/QMLUQtIMqqOOZ1hw4qdCeavCf1qIRo6Q9nEzT009IQd+CQ4wGDC6HYyt9EPLIr7kLZH59Jp92QMuoskvxaE5RzmZuNqrgo9TWD6ATR07vZZzUedv8ZpDiAj10l6joO0HAdnsh2YDBr1Aq0EWE2cyXaQnGXDx2TkatYS6/yLn4KGkWQz8WTiEsibZKed4QifW/9NZ/Zj0VwEajkMzf6C19PvBqBRmC+NQv0IsJpom7OVy07uBCBaS+EO80rmuq6ioSlNrRsV4ZW/tRBCCCHOo+u90GEIGK1qxj2PgEjo93+wcgocW6eWGS1Qv6Oq5dSwO9RrBd89pBJX3z+s1ml2OZzYCsc3wKIJcP3bBd+56wfVGyL2MvW+pHpRxen3f7D1C0j5CzZ8CL0fv+hD9iShPML8Lbx1R+f89w6Xm+RMO3sT0pm8aB+7T6bz6s+7+XbzcSbd0pEm4X4cP5NDsK+ZRmFys01UX3PWHcGUeYKPLG/T2fQ3aS4/nj0+gpGm+WCAVN2fEC2LEWnv8lLS/bxjeZd6WhpJehCjHaN52Pgzlxu3M8b0Xf539nKup4N9NUvd3TDioqt2gDAtA39ycGIkHT9S9CD+SokhOQVeMc9miHEVmKCx8yQbHG1obEkkRQ/gX85hTDbPzE9ErXK1p69xF5ef/oI349uzX2+Uv18rdsaavgVgr7sRbQzHGKV9TwTJxBkOkKNbCLnk+qr9AwtRC2h6LZlSLT09neDgYNLS0ggKCvJ2ONXW5iMp7Jg5igdMi9WC5leprufk/W9gCYS7voLPbwZnrvrBd3yj+qzTHXDDu6rr7DcPqsKenm3sGXDpo/CPSZCdAju+gpwU9R0GE1iDwC8cGsSpwqC/PA1b56jt21yvtv3kWvWDdPA01UU3Lya90aVox9aha0Y2DfqOJu0vJTIwr/usrqsaEye2QHAjSDsGIU3ghqnw+S3qO+78Wt3ZFKKOk/NkYfL3EKIaczlhyyfqN0R0Z4hsC6ZzhqtlJMAn10HyQWjcC+75Hg6thC9vB3ToPgIGTYK178Fvr6htYi+DQyugXlt4bF3p49nyOSx4HKzB8PhGCIyqoAMtmcutM3/jMf69aC9pOUWLnHdpHMINnWJoEOpLoNVEi8gAIoMqdgZhOU8WJn+P0tF1ndteeJ/pxsnU04rWcXMGRGN44Bf0mVdgzC3o9ZgT2pr9V84kzRpDgMlF6/UTsSZs5lSb+3CkHKPpgU+w+zfg2I1zqf/7OPxPbS4xBqfRD5MrG10zgK6joeOyBmO0pZHT60mSe/wf5l+fJ3LXbI60f4T4zuNo9vvDRJ/8jRP+7TjSbhT1oxsQYtHxO/Ib1o3TcQdEk3rv74TM7oshJ7lgX9e/i6nbfRX7RxSihirLeVKSUXXMwp0nafr1INoZjsC1U6DHSNj5jbqr6HaqZFPcfaqOw4rJaiODCQa+Bj1HqdlwAPYtggOLIe4ByDoNc24BzQiDp8Mfr0Hq0ZKDMJjUvtDyXjtU9/ycM9D1PrjxXVj9jvrh6Pkh+c0DsPsHlcy6/m1VU8KRAwd/VXc/zf7w6Bo1A092krqD6rJDl3tUvQkhhJwnzyF/DyFqgaxkOLAE2l4P1kC1bN10WDRRvQ5pXPxvksa94MFFpd+P2w0fXal6XrW/BW6bXf7YSykp08Yb/9vDd1vjAdWbKjXbTnF1zjs2CObKNpEMal+fttHq73E6w8buk+n0b1WvSM+sC5HzZGHy9yidM1l2Dv+7F10MB3FHtsdw+6ew8SNYP0OtcOdX0GoQbPsSfnhELWt3E9w0DUoa7mbPVsXD044WXEtYAlWi2hqg3uemqaLkmQlqm+BGMOQjiN8Mi59Vy0w+MPZPCKin3tsyC/aZFq/2YS9h9kzPddKqt9XMn6Dq393yYcE1khB1nCSjpHEo0ezVh7h5SR9CtCx4dD1EtlEfxG9RP9ba3aROpvYsmDVInYxv/lBNx3w+8++GPT8VvA9pAi2vVj2d3E6wpUPacdUYOLLBP1I1DhkJ8P1DBds9tlF1vQeVbPLUc0g/qWa+sJUwS07/CXDFs7DyLfjtZbWsXhtVxNQi3diFADlPnkv+HkLUYvt+UcP4PL8brn4FEv6EnV+p962vhWFzy/adJ7fDh1eo2lSei+kqlJptx2oy4msxkpiRy4JtJ1h1MIn0HAepOQ4OJWUVqqnZIMQXm9NFUqaqFbry6SvKPLRPzpOFyd+jdHafSKfhf1sTpGXDo+tUwgjg7+Xq933rf6j3uq4SVBZ/dQP5QgmdvQth3jD1OrId3DEHwpsXXS/njBqWG9FaXQfoOix6BtZPVzfXr/l3yfs4vFrN8pl5CrKTVY9Ma5AaJnzNZDWk2JYBH16u4r7/fwWJcCFEmc6TUjOqjkk5k6wSUQDBDQo+aNBVPTws/vDwctAMpcv0D3oDDvwKzhxoOVDdIShuymSXQxUjDW2i9gGqMOnK/6jhep5EFBQuLBoUDbd+DL+/qhJYWUlg9lN1JSLbQu/Rar3uI9QdUXsW3DpbElFCCCFEXdT6GnVD6o/X1e+SzsNUr4lj6yH1SPG/US4k+hJVzHzNu/DzeOhyl5rZL6KVKlNgMFb8cZwlxK+gcHpkoA8j+jVjRL9m+ctOZ9j4Y28iS/ecYsX+08SnqmnqDRrERviTkmWXOlOiSpxOSqSdpmaZI6RxwQfN+hdeUdPg0kdK/8VtrlWJ5ewU6P90wbXEuXxDC/8b1zT1b7TrPerf6/k07aMe52MNhMc3qSSXQSYWEOJiSTKqjnGkHAcg1xSEz4Wy+GX5URXSGO7/Wd2FaH9LySdmoxmi2hVeduUL0Oqagl5aJWl5tXqAOvkXlyTzCYJHVqveWEExpY9fCCGEELVLRIvCw+l8guGOz1UZgK73Xtx3Xv4M7P5RJbSW5/Wu+PsP9ftm0Ovlj7kc6gVaub17I27v3ohsu5NNh88Q7GumVVQgvpbKTZQJcbasU2pGvAxDEIElJYwuVp8xF7edpkFU+4qLQ9NkaJ4Q5STJqLom9RgANr9oKrbEJdCwm3qUlaZBo+5l36YkAZFlj0EIIYQQtV/0JXD3txe/vcVPlRlY/CyENYPA+qrO5dr31XChbg9WXKzl4GcxcVmret4OQ9RR9uQjAKRb6yMD2IQQJZFkVB1jyVLFL11BDb0ciRBCCCFEDdSoB4z4teC9JVBN3vK/J1WR5UsfqfQhe0JUa3mTBuT6N7jAikKIukwGudYxAblqdgljaCMvRyKEEEIIUQtc9iR0vlsVNl/yHHw0ABL3eDsqIbym4Oa3XG8IIUomyag6JNPmJMJ9GgCfiCZejkYIIYQQohbQNLjpfTXtuzUYTmyBjwfBiW3ejkwIrwjIOQGAKazxBdYUQtRlkowCdF3H5nR5O4xKdyo9lwZaEgBWaRyEEEIIISqGpkHcffDYemjUU83c99lNsO8X+P11mHkl7Pja21EKUSVCHacA8K0X6+VIhBDVWZ1PRq05mMQN76/i37/s83Yole5Uei4xJKs3wdJtVgghhBCiQgVFqwLpDXtAbirMHQorJkP8ZljwOJzer9ZLOQQrpkDGKa+GK0RFy8h1UB81EiOkfjMvRyOEqM7qfDLK7nLzZ3w6X206Rnquw9vhVKpTaVnU11LUm2ApYC6EEEIIUeGsgXD3N6qHlGaAFgPUa2cufP8QHN+s6kr9/irMvwtcTm9HLESFSUw5Qz0tHQDfek29G4wQolqr88mo/q3q0TIygEybk682HvN2OJUqM+kEZs2FC6OailgIIYQQQlQ8n2B44BeYeFT1lLrtE/AJgRNbYdYAyFZlEzi+EVa86c1IhahQZ04eAiAbX/AN9XI0QojqrM4nozRNY3hfNZ559urDOF1uL0dUeezJRwDItETKlMNCCCGEEJXJYFS9pACCYuC6/6jXuhua9IHr31bvV0yGA79Cdor0khI1XnaiSkalmKNULTUhhCiBydsBVAeDuzTgzcX7iE/NYdGuBK7vFOPtkCpH2nEAcvyiCfZyKEIIIYQQdUrHWyH9BGSdhiueBbMvHF0HO+bDF0PUOgYzNOoBsf2h0+0QJgWgRc3izLv5neET7eVIhBDVXZ3vGYU9C5/PruWV5vsAnZkr/sburJ29o8yZ8QC4gqRelBBCCCFElevzBAx8VSWiAK59U9WUMvur924HHFkNy96AD3rC8jfBafNevEKUkZauyp7Y/Bt4ORIhRHUnPaM2zIRj67iOdURbWzIpfhi93sjixi4NuaRhCA1CfWkQ4ktkoBWTsWbn7vxzTgJgCJGZ9IQQQgghvM4nWNWUAnA54MwROLQcdn0Ph1fCH6/Bjnkw4GVocx0k7laz8KHDFc9BREuvhi/EuXyyTqgXMnO3EOICLioZNW3aNN58801OnjxJ+/btmTp1Kv369Stx/eXLlzN+/Hh27dpFTEwMTz/9NKNGjcr/fObMmXz22Wf8+eefAMTFxfHGG2/Qo0ePiwmvbHo8BC47rHqbro4DfG19hRRXAGs3tOPY+kj26QGc1MPYT2NS/ZoSGhRARIAVX7OquWQ1G2gWEUCLyACCfE0YDRq6Djl2F3aXm4gAK9HBPvhajGTbXNicLkxGA2ajRpbNRUqWnRyHE1+zCT+LkWy7i7QcO24dwv0thAdY8bMY8TUbMWgaDrcbh8tNrsONzemiXoCV8AAruq5z/EwOO+PTMBo0An1MhPpZiAy0EupnQdMgxHEKDOAT0bjy/65CCCGEEKL0jGaIaKEe3R6EP7+FRc9A8kE16154C0j+C9DV+nt+grgHIKIVGAzQ/CoZ1lcKZb2OEWUTaFM3v83hTbwciRCiuitzMmr+/PmMHTuWadOm0adPH/773/9yzTXXsHv3bho3LprkOHToENdeey0jR45kzpw5rF69mkcffZR69eoxZIgaH79s2TKGDRtG79698fHxYfLkyQwcOJBdu3bRoEEld/G0+EH/p6HLPfDHa+i7fiDMnsl1xg1FVrU7jOxJasK2xOYk6OG40MjBynY9gv/p9YjXI8jCt3LjLUaYvwWzUeNUevHduE0GjRA/C5+RDEBApPxQEUJUnIq+QbFr1y7++c9/snnzZo4cOcLbb7/N2LFjC32H0+nkpZde4osvviAhIYHo6Gjuv/9+nn/+eQyGmt2LVQgh0DRVY6rl1bD6HVg7TSWlANoNBmcu7F8EG2cWbGMJhOGLIap90e/LSQXfkCoIvHor63WMKLtwZyIA/lFyvSGEOD9N13W9LBv07NmTrl27Mn369Pxlbdu2ZfDgwUyaNKnI+hMmTGDBggXs2bMnf9moUaPYvn07a9euLXYfLpeL0NBQ3n//fe69995SxZWenk5wcDBpaWkEBQWV5ZDO2bkD4jfD0bWQlQQ5Z9BT/kY/tQuDLf2Cm2fgzxlDKDaDL3bNitPlxul04sSg3msWXLqGruv4GRwEGu1YNBcuNzh0A76anQAtF6tuw+S2Y8BJuu7HGT2AHKyAKvRl1tyYNDc2t4YjL6cYSA4hJge5Bh/SdH+S3AGcdARwSg/lV3dX5lteJUTLgkfXQWTbi/8bCSFqpAo7T55l/vz53HPPPYV+2H/00UfnvUHRoUMHRo4cycMPP5x/g2Lu3Ln5Nyg2btzIV199RVxcHOPGjWPChAlFklGvv/46b7/9Np9++int27dn06ZNPPDAA7z22muMGTOmVLFXxt9DCCEqRfpJ+PMbVdg8upNadvBX2PG1Skyd3gen90BQQxj5GwTWB1uG6j21fS4c3wxP7iuY3a+0u61l58myXsecq7b9PSpabm4u5kn1MWo66Y/+SVCkDNUToq4py3myTD2j7HY7mzdvZuLEiYWWDxw4kDVr1hS7zdq1axk4cGChZYMGDWLWrFk4HA7MZnORbbKzs3E4HISFhZUlvIphNEPjS9UjjwZoug5nDqtE1Ymt6g6T7lINfepRSD0CuWkEkkWgOwvOroF+7k16Le8B4Drns2JSg0FaNg21pOLjPfe73RTed95/4af46qwvlIKCQoiK8dZbbzF8+HBGjBgBwNSpU1m8eDHTp08v9of9jBkzaNy4MVOnTgXURcCmTZuYMmVKfjKqe/fudO/eHaBIe+Oxdu1abrrpJq677joAmjZtyty5c9m0aVNFH6IQQnhfUDT0Hl14WYsB6gGQcwY+uhqSD8DH/wCLv0pQuR0F6x9eDa3/UXUxVzMXcx1js9mw2QpGHqSnX/jGdHH2bvyVtPVfXNS2NYnmzKWHpmPXTQRG1NLZyYUQFaZMyaikpCRcLhdRUVGFlkdFRZGQkFDsNgkJCcWu73Q6SUpKIjq66LSfEydOpEGDBgwYMKDEWCqqcSg1TVPj8MNiVbfp4uSmQ3q8mrLXng2ObNAMYDCC2wWOHHDmFKxvtKphgkarSmzpbjD5gjUATD5qphXNCLlpkJNSeDYVg1F9prtUzStdB2uQ+j57tvpRkpOiYkncA/sXqx8kgTHgI3dyhBDlV1U3KIrTt29fZsyYwf79+2nVqhXbt29n1apV+Umu4lR5uyGEEFXFNxTu+go+GgBnDhUsD28BlwyFjrdDaN2u4XMx1zGTJk3i5ZdfLve+M47tomfSd+X+npoi3tiQWIPR22EIIaq5iypgrmlaofe6rhdZdqH1i1sOMHnyZObOncuyZcvw8fEp8TsrqnGoUD5BeYmeajgELitZ1RaQ4XlCiApSVTcoijNhwgTS0tJo06YNRqMRl8vF66+/zrBhw0rcplq2G0IIUVHCmsH9C+HAEjXLXmQ7CGmsbqiKfGW5jnnmmWcYP358/vv09HQaNSr70LPQ5nGsPTOizNvVTBqRPUq4cS+EEGcpUzIqIiICo9FY5CIjMTGxyMWFR/369Ytd32QyER4eXmj5lClTeOONN/j111/p1KnTeWOpqMahzvAPhy53eTsKIUQtVJk3KEoyf/585syZw5dffkn79u3Ztm0bY8eOJSYmhvvuu6/YbaTdEELUepFt1EMUcTHXMVarFavVWu59t7ikLy0u6Vvu7xFCiNqkTFMOWSwW4uLiWLp0aaHlS5cupXfv3sVu06tXryLrL1myhG7duhUajvHmm2/y6quvsmjRIrp163bBWKxWK0FBQYUeQgghqk5l36A4n6eeeoqJEycydOhQOnbsyD333MO4cePOW4BW2g0hhKi7LuY6RgghROUp8/zX48eP56OPPuLjjz9mz549jBs3jqNHj+ZPy/3MM88UmgFv1KhRHDlyhPHjx7Nnzx4+/vhjZs2axZNPPpm/zuTJk3n++ef5+OOPadq0KQkJCSQkJJCZmVkBhyiEEKIyVOYNigvJzs7GYCjchBmNRtxudwlbCCGEqOsudB0jhBCi6pS5ZtQdd9xBcnIyr7zyCidPnqRDhw4sXLiQJk1UUcSTJ09y9OjR/PVjY2NZuHAh48aN44MPPiAmJoZ33303f9YkgGnTpmG327n11sLji1988UVeeumlizw0IYQQlW38+PHcc889dOvWjV69evHhhx8WuUERHx/PZ599BqgbFO+//z7jx49n5MiRrF27llmzZjF37tz877Tb7ezevTv/dXx8PNu2bSMgIIAWLVoAcMMNN/D666/TuHFj2rdvz9atW3nrrbd48MEHq/gvIIQQoqa40HWMEEKIqqPpnmIdNVx6ejrBwcGkpaXJ0AshhChGZZ0np02bxuTJk/N/2L/99ttcdtllANx///0cPnyYZcuW5a+/fPlyxo0bx65du4iJiWHChAmF7kofPnyY2NjYIvvp379//vdkZGTwwgsv8P3335OYmEhMTAzDhg3jn//8JxaLpVRxS7shhBDnJ+fJwuTvIYQQ51eW86Qko4QQoo6Q82Rh8vcQQojzk/NkYfL3EEKI8yvLebLMNaOEEEIIIYQQQgghhLhYkowSQgghhBBCCCGEEFVGklFCCCGEEEIIIYQQospIMkoIIYQQQgghhBBCVBlJRgkhhBBCCCGEEEKIKiPJKCGEEEIIIYQQQghRZUzeDqCi6LoOqKkEhRBCFOU5P3rOl3WdtBtCCHF+0m4UJu2GEEKcX1najVqTjMrIyACgUaNGXo5ECCGqt4yMDIKDg70dhtdJuyGEEKUj7YYi7YYQQpROadoNTa8ltzrcbjcnTpwgMDAQTdPKtG16ejqNGjXi2LFjBAUFVVKElaemxw81/xhqevxQ849B4r8wXdfJyMggJiYGg0FGaUu7UXPjh5p/DDU9fqj5xyDxX5i0G4VJu1Fz44eafwwSv/fV9GOobu1GrekZZTAYaNiwYbm+IygoqEb+T+VR0+OHmn8MNT1+qPnHIPGfn9zZLiDtRs2PH2r+MdT0+KHmH4PEf37SbhSQdqPmxw81/xgkfu+r6cdQXdoNucUhhBBCCCGEEEIIIaqMJKOEEEIIIYQQQgghRJWRZBRgtVp58cUXsVqt3g7lotT0+KHmH0NNjx9q/jFI/KIq1fT/XjU9fqj5x1DT44eafwwSv6hKNf2/V02PH2r+MUj83lfTj6G6xV9rCpgLIYQQQgghhBBCiOpPekYJIYQQQgghhBBCiCojySghhBBCCCGEEEIIUWUkGSWEEEIIIYQQQgghqowko4QQQgghhBBCCCFElanzyahp06YRGxuLj48PcXFxrFy50tshFWvSpEl0796dwMBAIiMjGTx4MPv27Su0jq7rvPTSS8TExODr68vll1/Orl27vBTx+U2aNAlN0xg7dmz+spoQf3x8PHfffTfh4eH4+fnRuXNnNm/enP95dT8Gp9PJ888/T2xsLL6+vjRr1oxXXnkFt9udv051OoYVK1Zwww03EBMTg6Zp/PDDD4U+L02sNpuN0aNHExERgb+/PzfeeCPHjx+vFsfgcDiYMGECHTt2xN/fn5iYGO69915OnDhRrY5BFCbthndIu+Ed0m5IuyHKT9oN75B2wzuk3ZB2o9T0OmzevHm62WzWZ86cqe/evVsfM2aM7u/vrx85csTboRUxaNAgffbs2fqff/6pb9u2Tb/uuuv0xo0b65mZmfnr/Otf/9IDAwP1b7/9Vt+5c6d+xx136NHR0Xp6eroXIy9qw4YNetOmTfVOnTrpY8aMyV9e3eNPSUnRmzRpot9///36+vXr9UOHDum//vqrfvDgwfx1qvsxvPbaa3p4eLj+888/64cOHdK//vprPSAgQJ86dWr+OtXpGBYuXKg/99xz+rfffqsD+vfff1/o89LEOmrUKL1Bgwb60qVL9S1btuhXXHGFfskll+hOp9Prx5CamqoPGDBAnz9/vr5371597dq1es+ePfW4uLhC3+HtYxAFpN3wDmk3vEfaDWk3RPlIu+Ed0m54j7Qb0m6UVp1ORvXo0UMfNWpUoWVt2rTRJ06c6KWISi8xMVEH9OXLl+u6rutut1uvX7++/q9//St/ndzcXD04OFifMWOGt8IsIiMjQ2/ZsqW+dOlSvX///vmNQ02If8KECXrfvn1L/LwmHMN1112nP/jgg4WW3XLLLfrdd9+t63r1PoZzT6yliTU1NVU3m836vHnz8teJj4/XDQaDvmjRoiqL3aO4Bu5cGzZs0IH8H6nV7RjqOmk3qp60G94l7Ya0G6J8pN2oetJueJe0G9JulFadHaZnt9vZvHkzAwcOLLR84MCBrFmzxktRlV5aWhoAYWFhABw6dIiEhIRCx2O1Wunfv3+1Op7HHnuM6667jgEDBhRaXhPiX7BgAd26deO2224jMjKSLl26MHPmzPzPa8Ix9O3bl99++439+/cDsH37dlatWsW1114L1Ixj8ChNrJs3b8bhcBRaJyYmhg4dOlS74/FIS0tD0zRCQkKAmnkMtZW0G94h7YZ3SbtR/c+50m5UX9JueIe0G94l7Ub1P+dWl3bDVGnfXM0lJSXhcrmIiooqtDwqKoqEhAQvRVU6uq4zfvx4+vbtS4cOHQDyYy7ueI4cOVLlMRZn3rx5bNmyhY0bNxb5rCbE//fffzN9+nTGjx/Ps88+y4YNG3jiiSewWq3ce++9NeIYJkyYQFpaGm3atMFoNOJyuXj99dcZNmwYUDP+O3iUJtaEhAQsFguhoaFF1qmO/85zc3OZOHEid955J0FBQUDNO4baTNqNqifthvdJu1GwTnX8dy7tRvUm7UbVk3bD+6TdKFinOv47r07tRp1NRnlomlbova7rRZZVN48//jg7duxg1apVRT6rrsdz7NgxxowZw5IlS/Dx8SlxveoaP4Db7aZbt2688cYbAHTp0oVdu3Yxffp07r333vz1qvMxzJ8/nzlz5vDll1/Svn17tm3bxtixY4mJieG+++7LX686H8O5LibW6ng8DoeDoUOH4na7mTZt2gXXr47HUFfUpH8fHtJueIe0G9XjGM4l7YaoajXp34eHtBveIe1G9TiGc0m7UTnq7DC9iIgIjEZjkUxfYmJikcxndTJ69GgWLFjAH3/8QcOGDfOX169fH6DaHs/mzZtJTEwkLi4Ok8mEyWRi+fLlvPvuu5hMpvwYq2v8ANHR0bRr167QsrZt23L06FGg+v83AHjqqaeYOHEiQ4cOpWPHjtxzzz2MGzeOSZMmATXjGDxKE2v9+vWx2+2cOXOmxHWqA4fDwe23386hQ4dYunRp/l0KqDnHUBdIu1G1pN2oHscg7UbRdaoDaTdqBmk3qpa0G9XjGKTdKLpOdVAd2406m4yyWCzExcWxdOnSQsuXLl1K7969vRRVyXRd5/HHH+e7777j999/JzY2ttDnsbGx1K9fv9Dx2O12li9fXi2O56qrrmLnzp1s27Yt/9GtWzfuuusutm3bRrNmzap1/AB9+vQpMr3t/v37adKkCVD9/xsAZGdnYzAU/mdvNBrzp1qtCcfgUZpY4+LiMJvNhdY5efIkf/75Z7U5Hk/DcODAAX799VfCw8MLfV4TjqGukHajakm7UT2OQdqN6nfOlXaj5pB2o2pJu1E9jkHajep3zq227UallUavATxTrc6aNUvfvXu3PnbsWN3f318/fPiwt0Mr4pFHHtGDg4P1ZcuW6SdPnsx/ZGdn56/zr3/9Sw8ODta/++47fefOnfqwYcOq1TSf5zp7dgtdr/7xb9iwQTeZTPrrr7+uHzhwQP/iiy90Pz8/fc6cOfnrVPdjuO+++/QGDRrkT7X63Xff6REREfrTTz+dv051OoaMjAx969at+tatW3VAf+utt/StW7fmz/xQmlhHjRqlN2zYUP/111/1LVu26FdeeWWVTrV6vmNwOBz6jTfeqDds2FDftm1boX/bNput2hyDKCDthndJu1H1pN2QdkOUj7Qb3iXtRtWTdkPajdKq08koXdf1Dz74QG/SpIlusVj0rl275k9dWt0AxT5mz56dv47b7dZffPFFvX79+rrVatUvu+wyfefOnd4L+gLObRxqQvw//fST3qFDB91qtept2rTRP/zww0KfV/djSE9P18eMGaM3btxY9/Hx0Zs1a6Y/99xzhU5E1ekY/vjjj2L/v7/vvvtKHWtOTo7++OOP62FhYbqvr69+/fXX60ePHq0Wx3Do0KES/23/8ccf1eYYRGHSbniPtBtVT9oNaTdE+Um74T3SblQ9aTek3SgtTdd1/eL7VQkhhBBCCCGEEEIIUXp1tmaUEEIIIYQQQgghhKh6kowSQgghhBBCCCGEEFVGklFCCCGEEEIIIYQQospIMkoIIYQQQgghhBBCVBlJRgkhhBBCCCGEEEKIKiPJKCGEEEIIIYQQQghRZSQZJYQQQgghhBBCCCGqjCSjhBBCCCGEEEIIIUSVkWSUEEIIIYQQQgghhKgykowSQgghhBBCCCGEEFVGklFCCCGEEEIIIYQQospIMkoIIYQQQgghhBBCVJn/BwztSkIzSd23AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "ax[0].plot(logs[\"train_losses\"], label=\"Train\")\n",
    "ax[0].plot(logs[\"test_losses\"], label=\"Validation\")\n",
    "ax[0].set_title(\"Combined loss\")\n",
    "ax[0].legend()\n",
    "ax[1].plot(logs[\"train_recon_losses\"], label=\"Train\")\n",
    "ax[1].plot(logs[\"test_recon_losses\"], label=\"Validation\")\n",
    "ax[1].set_title(\"Reconstruction loss\")\n",
    "ax[1].legend()\n",
    "ax[2].plot(logs[\"train_cov_losses\"], label=\"Train\")\n",
    "ax[2].plot(logs[\"test_cov_losses\"], label=\"Validation\")\n",
    "ax[2].set_title(\"Covariance loss\")\n",
    "ax[2].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
