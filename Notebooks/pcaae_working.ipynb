{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from category_encoders import BinaryEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from kneed import KneeLocator\n",
    "import matplotlib.cm as cm\n",
    "import os\n",
    "from typing import Tuple, Union, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PCAAutoencoder(nn.Module):\n",
    "    def __init__(self, encoder: nn.ModuleList, decoder: nn.ModuleList, last_hidden_shape):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.last_hidden_shape = last_hidden_shape\n",
    "        self.bottleneck = nn.ModuleList([nn.Linear(in_features=self.last_hidden_shape, out_features=1),\n",
    "                                         nn.BatchNorm1d(num_features=1, affine=False)])\n",
    "\n",
    "    def increase_latentdim(self):\n",
    "        # Create new bottleneck expansion layer\n",
    "        new_bottleneck = nn.ModuleList([nn.Linear(in_features=self.last_hidden_shape, out_features=self.bottleneck[0].out_features + 1),\n",
    "                                        nn.BatchNorm1d(num_features=self.bottleneck[0].out_features + 1, affine=False)])\n",
    "        # Copying weights while freezing old neurons\n",
    "        with torch.no_grad():\n",
    "            new_bottleneck[0].weight[: self.bottleneck[0].out_features] = self.bottleneck[0].weight\n",
    "            new_bottleneck[0].bias[: self.bottleneck[0].out_features] = self.bottleneck[0].bias\n",
    "\n",
    "        self.bottleneck = new_bottleneck  # Replace the layer\n",
    "        self.bottleneck[0].requires_grad_(True)  # Allow gradients\n",
    "\n",
    "        # Freeze the old neurons using a hook\n",
    "        self.bottleneck[0].weight.register_hook(self._freeze_old_neurons_hook)\n",
    "        self.bottleneck[0].bias.register_hook(self._freeze_old_neurons_hook)\n",
    "\n",
    "        # Turn off gradients for all layers in the encoder (just in case)\n",
    "        for layer in self.encoder:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self._recreate_decoder()\n",
    "\n",
    "    def _freeze_old_neurons_hook(self, grad):\n",
    "        \"\"\"Backward hook: Freeze gradients for old neurons, allowing updates only for new ones\"\"\"\n",
    "        grad[: -1] = 0  # Zero out gradients for old neurons\n",
    "        return grad\n",
    "\n",
    "    def _recreate_decoder(self):\n",
    "        # Copying old decoder to new\n",
    "        new_decoder = nn.ModuleList()\n",
    "        for i, layer in enumerate(self.decoder):\n",
    "            if i == 0 and isinstance(layer, nn.Linear):\n",
    "                new_layer = nn.Linear(layer.in_features + 1, layer.out_features)\n",
    "                nn.init.xavier_uniform_(new_layer.weight)\n",
    "                if new_layer.bias is not None:\n",
    "                    nn.init.zeros_(new_layer.bias)\n",
    "                new_decoder.append(new_layer)\n",
    "            else:\n",
    "                new_decoder.append(layer)\n",
    "        \n",
    "        self.decoder = new_decoder  # Ensure it's still a ModuleList\n",
    "\n",
    "    def encode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "        for layer in self.bottleneck:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def decode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        for layer in self.decoder:\n",
    "            x = layer(x)\n",
    "        return x  # Return the output\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        enc = self.encode(x)\n",
    "        out = self.decode(enc)\n",
    "        return out, enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCAAE_Loss(nn.Module):\n",
    "    def __init__(self, loss_func, lambda_cov=0.01):\n",
    "        super().__init__()\n",
    "        self.loss_func = loss_func\n",
    "        self.lambda_cov = lambda_cov\n",
    "\n",
    "    \n",
    "    def forward(self, y_hat, y, z):\n",
    "        recon_loss = self.loss_func(y_hat, y)\n",
    "\n",
    "        batch_size, latent_dim = z.shape\n",
    "        z_mean = torch.mean(z, dim=0, keepdim=True)\n",
    "        z_centered = z - z_mean\n",
    "\n",
    "        covariance_matrix = (z_centered.T @ z_centered) / batch_size\n",
    "        covariance_loss = torch.sum(covariance_matrix**2) - torch.sum(torch.diagonal(covariance_matrix)**2)\n",
    "\n",
    "        total_loss = recon_loss + self.lambda_cov * covariance_loss\n",
    "        return total_loss, recon_loss, covariance_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: PCAAutoencoder, goal_hidden_dim: int, optimizer: torch.optim.Optimizer, loss_func: Union[nn.Module, Callable], \n",
    "                epochs: int, trainloader: DataLoader, testloader: DataLoader, print_every: int) -> dict:\n",
    "    writer = SummaryWriter()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    outer_steps = 0\n",
    "    total_steps = 0\n",
    "    total_epochs = 0\n",
    "    total_train_losses, total_test_losses = [], []\n",
    "    if isinstance(loss_func, PCAAE_Loss):\n",
    "        total_train_recon_losses, total_test_recon_losses = [], []\n",
    "        total_train_cov_losses, total_test_cov_losses = [], []\n",
    "    hidden_dim = 1\n",
    "    \n",
    "    while hidden_dim != goal_hidden_dim:\n",
    "        if not outer_steps == 0:\n",
    "            # Increasing latent space\n",
    "            # Reloading best weight before increasing the latent dim\n",
    "            model.load_state_dict(torch.load(f\"model_checkpoints/PCAAE_hidden_dim{hidden_dim}.pt\"))\n",
    "            model.increase_latentdim()\n",
    "            hidden_dim += 1\n",
    "            model.to(device)\n",
    "\n",
    "        outer_steps += 1\n",
    "        print(f\"Training with hidden dim: {hidden_dim}\")\n",
    "        steps = 0\n",
    "        train_losses, test_losses = [], []\n",
    "        if isinstance(loss_func, PCAAE_Loss):\n",
    "            train_recon_losses, test_recon_losses = [], []\n",
    "            train_cov_losses, test_cov_losses = [], []\n",
    "        min_test_loss = np.Inf\n",
    "        min_test_recon_loss = np.Inf\n",
    "\n",
    "        # Training loop\n",
    "        for e in range(epochs):\n",
    "            total_epochs += 1\n",
    "            running_loss = 0\n",
    "            # Only for printing it\n",
    "            running_loss_ = 0\n",
    "            if isinstance(loss_func, PCAAE_Loss):\n",
    "                running_recon_loss = 0\n",
    "                running_cov_loss = 0\n",
    "                running_recon_loss_ = 0\n",
    "                running_cov_loss_ = 0\n",
    "\n",
    "            for X, y in trainloader:\n",
    "                steps += 1\n",
    "                total_steps += 1\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                y_hat, hidden = model(X)\n",
    "                if isinstance(loss_func, PCAAE_Loss):\n",
    "                    loss, recon_loss, cov_loss = loss_func(y_hat, y, hidden)\n",
    "                    running_recon_loss += recon_loss.item()*X.size(0)\n",
    "                    running_cov_loss += cov_loss.item()*X.size(0)\n",
    "                    running_recon_loss_ += recon_loss.item()\n",
    "                    running_cov_loss_ += cov_loss.item()\n",
    "                else:\n",
    "                    loss = loss_func(y_hat, y)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()*X.size(0)\n",
    "                running_loss_ += loss.item()\n",
    "\n",
    "                if steps % print_every == 0:\n",
    "                    writer.add_scalar(\"Loss x steps/train\", running_loss_/print_every, total_steps)\n",
    "                    if isinstance(loss_func, PCAAE_Loss):\n",
    "                        print(f\"Epoch: {e + 1}/{epochs}, Step {steps}, Train loss: {running_loss_/print_every:.3f} \" \n",
    "                              f\"Train reconstruction loss: {running_recon_loss_/print_every:.3f} \"\n",
    "                              f\"Train covariance loss: {running_cov_loss_/print_every:.3f}\")\n",
    "                        writer.add_scalar(\"Reconstruction loss x steps/train\", running_recon_loss_/print_every, total_steps)\n",
    "                        writer.add_scalar(\"Covariance loss x steps/train\", running_cov_loss_/print_every, total_steps)\n",
    "                    else:\n",
    "                        print(f\"Epoch: {e + 1}/{epochs}, Step {steps}, Train loss: {running_loss_/print_every:.3f}\")\n",
    "\n",
    "                    running_loss_ = 0\n",
    "\n",
    "                    if isinstance(loss_func, PCAAE_Loss):\n",
    "                        running_recon_loss_ = 0\n",
    "                        running_cov_loss_ = 0\n",
    "\n",
    "            # Running model on the test data  \n",
    "            else:\n",
    "                running_testloss = 0\n",
    "                if isinstance(loss_func, PCAAE_Loss):\n",
    "                    running_test_recon_loss = 0\n",
    "                    running_test_cov_loss = 0\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    for X, y in testloader:\n",
    "                        X, y = X.to(device), y.to(device)\n",
    "                        y_hat, hidden = model(X)\n",
    "                        if isinstance(loss_func, PCAAE_Loss):\n",
    "                            test_loss, test_recon_loss, test_cov_loss = loss_func(y_hat, y, hidden)\n",
    "                            running_test_recon_loss += test_recon_loss.item()*X.size(0)\n",
    "                            running_test_cov_loss += test_cov_loss.item()*X.size(0)\n",
    "                        else:\n",
    "                            loss = loss_func(y_hat, y)\n",
    "                        running_testloss += test_loss.item()*X.size(0)\n",
    "\n",
    "\n",
    "                model.train()\n",
    "\n",
    "                train_losses.append(running_loss/len(trainloader.dataset))\n",
    "                total_train_losses.append(running_loss/len(trainloader.dataset))\n",
    "                test_losses.append(running_testloss/len(testloader.dataset))\n",
    "                total_test_losses.append(running_testloss/len(testloader.dataset))\n",
    "\n",
    "                if isinstance(loss_func, PCAAE_Loss):\n",
    "                    train_recon_losses.append(running_recon_loss/len(trainloader.dataset))\n",
    "                    total_train_recon_losses.append(running_recon_loss/len(trainloader.dataset))\n",
    "                    train_cov_losses.append(running_cov_loss/len(trainloader.dataset))\n",
    "                    total_train_cov_losses.append(running_cov_loss/len(trainloader.dataset))\n",
    "                    test_recon_losses.append(running_test_recon_loss/len(testloader.dataset))\n",
    "                    total_test_recon_losses.append(running_test_recon_loss/len(testloader.dataset))\n",
    "                    test_cov_losses.append(running_test_cov_loss/len(testloader.dataset))\n",
    "                    total_test_cov_losses.append(running_test_cov_loss/len(testloader.dataset))\n",
    "\n",
    "                # Saving model when test loss improved # TODO: Make this monitor reconstruction loss when PCAAE_Loss is applied\n",
    "                if isinstance(loss_func, PCAAE_Loss):\n",
    "                    if test_recon_losses[-1] <= min_test_recon_loss:\n",
    "                        print('Test reconstruction loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(min_test_recon_loss, test_recon_losses[-1]))\n",
    "                else:\n",
    "                    if test_losses[-1] <= min_test_loss:\n",
    "                        print('Test loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(min_test_loss, test_losses[-1]))\n",
    "\n",
    "                    if not os.path.exists(\"model_checkpoints\"):\n",
    "                        os.mkdir(\"model_checkpoints\")\n",
    "                    torch.save(model.state_dict(), f\"model_checkpoints/PCAAE_hidden_dim{hidden_dim}.pt\")\n",
    "                    min_test_loss = test_losses[-1]\n",
    "                \n",
    "                #TODO - Add logging of test losses to the tensorboard session as well\n",
    "                writer.add_scalar(\"Loss x epochs/train\", running_loss/len(trainloader.dataset), total_epochs)\n",
    "                writer.add_scalar(\"Loss x epochs/test\", running_testloss/len(testloader.dataset), total_epochs)\n",
    "                if isinstance(loss_func, PCAAE_Loss):\n",
    "                    print(f\"Epoch {e+1}/{epochs},\\nTrain Loss: {running_loss/len(trainloader.dataset):.3f} \"\n",
    "                        f\"Train reconstruction loss: {running_recon_loss_/len(trainloader.dataset):.3f} \"\n",
    "                        f\"Train covariance loss: {running_cov_loss_/len(trainloader.dataset):.3f}\\n\"\n",
    "                        f\"Test Loss: {running_testloss/len(testloader.dataset):.3f} \"\n",
    "                        f\"Test reconstruction loss: {running_test_recon_loss/len(testloader.dataset):.3f} \"\n",
    "                        f\"Test covariance loss: {running_test_cov_loss/len(testloader.dataset):.3f}\")\n",
    "                    writer.add_scalar(\"Reconstruction loss x epochs/train\", running_recon_loss/len(trainloader.dataset), total_epochs)\n",
    "                    writer.add_scalar(\"Covariance loss x epochs/train\", running_cov_loss/len(trainloader.dataset), total_epochs)\n",
    "                    writer.add_scalar(\"Reconstruction loss x epochs/test\", running_test_recon_loss/len(trainloader.dataset), total_epochs)\n",
    "                    writer.add_scalar(\"Covariance loss x epochs/test\", running_test_cov_loss/len(testloader.dataset), total_epochs)    \n",
    "                else:\n",
    "                    print(f\"Epoch {e+1}/{epochs}\\nTrain Loss: {running_loss/len(trainloader.dataset):.3f} \"\n",
    "                          f\"Test Loss: {running_testloss/len(testloader.dataset):.3f}\")\n",
    "                \n",
    "\n",
    "    logs =  {\"train_losses\": total_train_losses, \n",
    "             \"train_recon_losses\": total_train_recon_losses, \n",
    "             \"train_cov_losses\": total_train_cov_losses, \n",
    "             \"test_losses\": total_test_losses, \n",
    "             \"test_recon_losses\": total_test_recon_losses, \n",
    "             \"test_cov_losses\": total_test_cov_losses, \n",
    "             \"steps\": total_steps}\n",
    "    \n",
    "    writer.close()\n",
    "    return logs           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for tabular data\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "inputFeature = pd.read_csv('../Data/NIBRS_ND_2021/processed/input.csv', index_col='Unnamed: 0')\n",
    "# Separating numerical and categorical features\n",
    "numerical_features=['population','victim_seq_num','age_num_victim','incident_hour','incident_month','incident_day','incident_dayofmonth','incident_weekofyear']\n",
    "categorical_features = ['resident_status_code','race_desc_victim',\n",
    "'ethnicity_name_victim','pub_agency_name','offense_name','location_name','weapon_name'\n",
    ",'injury_name','relationship_name','incident_isweekend']\n",
    "# Onehot-encoding categorical features\n",
    "inputFeature_1h = pd.get_dummies(inputFeature, columns=categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert object columns to numeric if they represent categories\n",
    "for column in inputFeature_1h.select_dtypes(include=['object']):\n",
    "    inputFeature_1h[column] = inputFeature_1h[column].astype('category').cat.codes\n",
    "\n",
    "# Train-test split\n",
    "train, test = train_test_split(inputFeature_1h, test_size=0.1, random_state=42)\n",
    "\n",
    "# Normalizing numerical features\n",
    "for feature in numerical_features:\n",
    "  train[feature] = (train[feature] - train[feature].min()) / (train[feature].max() - train[feature].min())\n",
    "  test[feature] = (test[feature] - test[feature].min()) / (test[feature].max() - test[feature].min())\n",
    "\n",
    "# Converting data to tensors\n",
    "X_train = torch.nan_to_num(torch.Tensor(train.values.astype(np.float32)))\n",
    "y_train = torch.nan_to_num(torch.Tensor(train.values.astype(np.float32)))\n",
    "\n",
    "X_test = torch.nan_to_num(torch.Tensor(test.values.astype(np.float32)))\n",
    "y_test = torch.nan_to_num(torch.Tensor(test.values.astype(np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "trainset = MyDataset(X_train, y_train)\n",
    "testset = MyDataset(X_test, y_test)\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sizes for the layers\n",
    "layer_sizes = [227, 64, 32]  # Example decreasing sizes for the encoder\n",
    "\n",
    "# Create the encoder ModuleList\n",
    "encoder = nn.ModuleList()\n",
    "for i in range(len(layer_sizes) - 1):\n",
    "    encoder.append(nn.Linear(layer_sizes[i], layer_sizes[i + 1]))\n",
    "    encoder.append(nn.ReLU())\n",
    "\n",
    "# Create the decoder ModuleList (mirror of the encoder)\n",
    "decoder = nn.ModuleList()\n",
    "decoder.append(nn.Linear(1, layer_sizes[len(layer_sizes) - 1]))\n",
    "for i in range(len(layer_sizes) - 1, 0, -1):\n",
    "    decoder.append(nn.Linear(layer_sizes[i], layer_sizes[i - 1]))\n",
    "    decoder.append(nn.ReLU())\n",
    "\n",
    "# Remove the last ReLU from the decoder (optional, depending on use case)\n",
    "decoder = decoder[:-1]\n",
    "criterion = PCAAE_Loss(nn.MSELoss())\n",
    "model = PCAAutoencoder(encoder, decoder, 32)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 25\n",
    "print_every = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 18:05:14.580274: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\CSANADANSYS\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "E0329 18:05:26.478990 20896 program.py:298] TensorBoard could not bind to port 6006, it was already in use\n",
      "ERROR: TensorBoard could not bind to port 6006, it was already in use\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hidden dim: 1\n",
      "Epoch: 1/25, Step 40, Train loss: 0.044 Train reconstruction loss: 0.044 Train covariance loss: 0.000\n",
      "Epoch: 1/25, Step 80, Train loss: 0.024 Train reconstruction loss: 0.024 Train covariance loss: 0.000\n",
      "Epoch: 1/25, Step 120, Train loss: 0.023 Train reconstruction loss: 0.023 Train covariance loss: 0.000\n",
      "Epoch: 1/25, Step 160, Train loss: 0.023 Train reconstruction loss: 0.023 Train covariance loss: 0.000\n",
      "Epoch: 1/25, Step 200, Train loss: 0.023 Train reconstruction loss: 0.023 Train covariance loss: 0.000\n",
      "Epoch: 1/25, Step 240, Train loss: 0.023 Train reconstruction loss: 0.023 Train covariance loss: 0.000\n",
      "Epoch: 1/25, Step 280, Train loss: 0.023 Train reconstruction loss: 0.023 Train covariance loss: 0.000\n",
      "Epoch: 1/25, Step 320, Train loss: 0.023 Train reconstruction loss: 0.023 Train covariance loss: 0.000\n",
      "Epoch: 1/25, Step 360, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 1/25, Step 400, Train loss: 0.023 Train reconstruction loss: 0.023 Train covariance loss: 0.000\n",
      "Epoch: 1/25, Step 440, Train loss: 0.023 Train reconstruction loss: 0.023 Train covariance loss: 0.000\n",
      "Epoch: 1/25, Step 480, Train loss: 0.023 Train reconstruction loss: 0.023 Train covariance loss: 0.000\n",
      "Test reconstruction loss decreased (inf --> 0.022435).  Saving model ...\n",
      "Epoch 1/25,\n",
      "Train Loss: 0.025 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.022 Test reconstruction loss: 0.022 Test covariance loss: 0.000\n",
      "Epoch: 2/25, Step 520, Train loss: 0.023 Train reconstruction loss: 0.023 Train covariance loss: 0.000\n",
      "Epoch: 2/25, Step 560, Train loss: 0.023 Train reconstruction loss: 0.023 Train covariance loss: 0.000\n",
      "Epoch: 2/25, Step 600, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 2/25, Step 640, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 2/25, Step 680, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 2/25, Step 720, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 2/25, Step 760, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 2/25, Step 800, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 2/25, Step 840, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 2/25, Step 880, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 2/25, Step 920, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 2/25, Step 960, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Test reconstruction loss decreased (inf --> 0.021687).  Saving model ...\n",
      "Epoch 2/25,\n",
      "Train Loss: 0.022 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.022 Test reconstruction loss: 0.022 Test covariance loss: 0.000\n",
      "Epoch: 3/25, Step 1000, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 3/25, Step 1040, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 3/25, Step 1080, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 3/25, Step 1120, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 3/25, Step 1160, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 3/25, Step 1200, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 3/25, Step 1240, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 3/25, Step 1280, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 3/25, Step 1320, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 3/25, Step 1360, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 3/25, Step 1400, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 3/25, Step 1440, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Test reconstruction loss decreased (inf --> 0.021476).  Saving model ...\n",
      "Epoch 3/25,\n",
      "Train Loss: 0.022 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 4/25, Step 1480, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 4/25, Step 1520, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 4/25, Step 1560, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 4/25, Step 1600, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 4/25, Step 1640, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 4/25, Step 1680, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 4/25, Step 1720, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 4/25, Step 1760, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 4/25, Step 1800, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 4/25, Step 1840, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 4/25, Step 1880, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 4/25, Step 1920, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Test reconstruction loss decreased (inf --> 0.021411).  Saving model ...\n",
      "Epoch 4/25,\n",
      "Train Loss: 0.022 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 5/25, Step 1960, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 5/25, Step 2000, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 5/25, Step 2040, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 5/25, Step 2080, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 5/25, Step 2120, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 5/25, Step 2160, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 5/25, Step 2200, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 5/25, Step 2240, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 5/25, Step 2280, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 5/25, Step 2320, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 5/25, Step 2360, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 5/25, Step 2400, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Test reconstruction loss decreased (inf --> 0.021378).  Saving model ...\n",
      "Epoch 5/25,\n",
      "Train Loss: 0.022 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 6/25, Step 2440, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 6/25, Step 2480, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 6/25, Step 2520, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 6/25, Step 2560, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 6/25, Step 2600, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 6/25, Step 2640, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 6/25, Step 2680, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 6/25, Step 2720, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 6/25, Step 2760, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 6/25, Step 2800, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 6/25, Step 2840, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 6/25, Step 2880, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Test reconstruction loss decreased (inf --> 0.021341).  Saving model ...\n",
      "Epoch 6/25,\n",
      "Train Loss: 0.022 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 7/25, Step 2920, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 7/25, Step 2960, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 7/25, Step 3000, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 7/25, Step 3040, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 7/25, Step 3080, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 7/25, Step 3120, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 7/25, Step 3160, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 7/25, Step 3200, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 7/25, Step 3240, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 7/25, Step 3280, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 7/25, Step 3320, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 7/25, Step 3360, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Test reconstruction loss decreased (inf --> 0.020989).  Saving model ...\n",
      "Epoch 7/25,\n",
      "Train Loss: 0.022 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 8/25, Step 3400, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 8/25, Step 3440, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 8/25, Step 3480, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 8/25, Step 3520, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 8/25, Step 3560, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 8/25, Step 3600, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 8/25, Step 3640, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 8/25, Step 3680, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 8/25, Step 3720, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 8/25, Step 3760, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 8/25, Step 3800, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 8/25, Step 3840, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Test reconstruction loss decreased (inf --> 0.020843).  Saving model ...\n",
      "Epoch 8/25,\n",
      "Train Loss: 0.022 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 9/25, Step 3880, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 9/25, Step 3920, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 9/25, Step 3960, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 9/25, Step 4000, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 9/25, Step 4040, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 9/25, Step 4080, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 9/25, Step 4120, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 9/25, Step 4160, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 9/25, Step 4200, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 9/25, Step 4240, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 9/25, Step 4280, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 9/25, Step 4320, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Test reconstruction loss decreased (inf --> 0.020795).  Saving model ...\n",
      "Epoch 9/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 10/25, Step 4360, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 10/25, Step 4400, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 10/25, Step 4440, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 10/25, Step 4480, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 10/25, Step 4520, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 10/25, Step 4560, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 10/25, Step 4600, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 10/25, Step 4640, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 10/25, Step 4680, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 10/25, Step 4720, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 10/25, Step 4760, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 10/25, Step 4800, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Test reconstruction loss decreased (inf --> 0.020741).  Saving model ...\n",
      "Epoch 10/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 11/25, Step 4840, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 11/25, Step 4880, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 11/25, Step 4920, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 11/25, Step 4960, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 11/25, Step 5000, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 11/25, Step 5040, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 11/25, Step 5080, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 11/25, Step 5120, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 11/25, Step 5160, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 11/25, Step 5200, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 11/25, Step 5240, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 11/25, Step 5280, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Test reconstruction loss decreased (inf --> 0.020677).  Saving model ...\n",
      "Epoch 11/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 12/25, Step 5320, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 12/25, Step 5360, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 12/25, Step 5400, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 12/25, Step 5440, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 12/25, Step 5480, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 12/25, Step 5520, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 12/25, Step 5560, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 12/25, Step 5600, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 12/25, Step 5640, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 12/25, Step 5680, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 12/25, Step 5720, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 12/25, Step 5760, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Test reconstruction loss decreased (inf --> 0.020557).  Saving model ...\n",
      "Epoch 12/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 13/25, Step 5800, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 13/25, Step 5840, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 13/25, Step 5880, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 13/25, Step 5920, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 13/25, Step 5960, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 13/25, Step 6000, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 13/25, Step 6040, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 13/25, Step 6080, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 13/25, Step 6120, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 13/25, Step 6160, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 13/25, Step 6200, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 13/25, Step 6240, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Test reconstruction loss decreased (inf --> 0.020650).  Saving model ...\n",
      "Epoch 13/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 14/25, Step 6280, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 14/25, Step 6320, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 14/25, Step 6360, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 14/25, Step 6400, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 14/25, Step 6440, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 14/25, Step 6480, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 14/25, Step 6520, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 14/25, Step 6560, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 14/25, Step 6600, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 14/25, Step 6640, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 14/25, Step 6680, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 14/25, Step 6720, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Test reconstruction loss decreased (inf --> 0.020559).  Saving model ...\n",
      "Epoch 14/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 15/25, Step 6760, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 15/25, Step 6800, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 15/25, Step 6840, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 15/25, Step 6880, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 15/25, Step 6920, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 15/25, Step 6960, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 15/25, Step 7000, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 15/25, Step 7040, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 15/25, Step 7080, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 15/25, Step 7120, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 15/25, Step 7160, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 15/25, Step 7200, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Test reconstruction loss decreased (inf --> 0.020468).  Saving model ...\n",
      "Epoch 15/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.020 Test reconstruction loss: 0.020 Test covariance loss: 0.000\n",
      "Epoch: 16/25, Step 7240, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 16/25, Step 7280, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 16/25, Step 7320, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 16/25, Step 7360, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 16/25, Step 7400, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 16/25, Step 7440, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 16/25, Step 7480, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 16/25, Step 7520, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 16/25, Step 7560, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 16/25, Step 7600, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 16/25, Step 7640, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 16/25, Step 7680, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Test reconstruction loss decreased (inf --> 0.020507).  Saving model ...\n",
      "Epoch 16/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.021 Test reconstruction loss: 0.021 Test covariance loss: 0.000\n",
      "Epoch: 17/25, Step 7720, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 17/25, Step 7760, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 17/25, Step 7800, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 17/25, Step 7840, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 17/25, Step 7880, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 17/25, Step 7920, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 17/25, Step 7960, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 17/25, Step 8000, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 17/25, Step 8040, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 17/25, Step 8080, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 17/25, Step 8120, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 17/25, Step 8160, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Test reconstruction loss decreased (inf --> 0.020430).  Saving model ...\n",
      "Epoch 17/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.020 Test reconstruction loss: 0.020 Test covariance loss: 0.000\n",
      "Epoch: 18/25, Step 8200, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 18/25, Step 8240, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 18/25, Step 8280, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 18/25, Step 8320, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 18/25, Step 8360, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 18/25, Step 8400, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 18/25, Step 8440, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 18/25, Step 8480, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 18/25, Step 8520, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 18/25, Step 8560, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 18/25, Step 8600, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 18/25, Step 8640, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Test reconstruction loss decreased (inf --> 0.020337).  Saving model ...\n",
      "Epoch 18/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.020 Test reconstruction loss: 0.020 Test covariance loss: 0.000\n",
      "Epoch: 19/25, Step 8680, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 19/25, Step 8720, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 19/25, Step 8760, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 19/25, Step 8800, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 19/25, Step 8840, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 19/25, Step 8880, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 19/25, Step 8920, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 19/25, Step 8960, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 19/25, Step 9000, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 19/25, Step 9040, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 19/25, Step 9080, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 19/25, Step 9120, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Test reconstruction loss decreased (inf --> 0.020347).  Saving model ...\n",
      "Epoch 19/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.020 Test reconstruction loss: 0.020 Test covariance loss: 0.000\n",
      "Epoch: 20/25, Step 9160, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 20/25, Step 9200, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 20/25, Step 9240, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 20/25, Step 9280, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 20/25, Step 9320, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 20/25, Step 9360, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 20/25, Step 9400, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 20/25, Step 9440, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 20/25, Step 9480, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 20/25, Step 9520, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 20/25, Step 9560, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 20/25, Step 9600, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Test reconstruction loss decreased (inf --> 0.020212).  Saving model ...\n",
      "Epoch 20/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.020 Test reconstruction loss: 0.020 Test covariance loss: 0.000\n",
      "Epoch: 21/25, Step 9640, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 21/25, Step 9680, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 21/25, Step 9720, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 21/25, Step 9760, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 21/25, Step 9800, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 21/25, Step 9840, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 21/25, Step 9880, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 21/25, Step 9920, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 21/25, Step 9960, Train loss: 0.022 Train reconstruction loss: 0.022 Train covariance loss: 0.000\n",
      "Epoch: 21/25, Step 10000, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 21/25, Step 10040, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 21/25, Step 10080, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Test reconstruction loss decreased (inf --> 0.020273).  Saving model ...\n",
      "Epoch 21/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.020 Test reconstruction loss: 0.020 Test covariance loss: 0.000\n",
      "Epoch: 22/25, Step 10120, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 22/25, Step 10160, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 22/25, Step 10200, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 22/25, Step 10240, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 22/25, Step 10280, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 22/25, Step 10320, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 22/25, Step 10360, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 22/25, Step 10400, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 22/25, Step 10440, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 22/25, Step 10480, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 22/25, Step 10520, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 22/25, Step 10560, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Test reconstruction loss decreased (inf --> 0.020195).  Saving model ...\n",
      "Epoch 22/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.020 Test reconstruction loss: 0.020 Test covariance loss: 0.000\n",
      "Epoch: 23/25, Step 10600, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 23/25, Step 10640, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 23/25, Step 10680, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 23/25, Step 10720, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 23/25, Step 10760, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 23/25, Step 10800, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 23/25, Step 10840, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 23/25, Step 10880, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 23/25, Step 10920, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 23/25, Step 10960, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 23/25, Step 11000, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 23/25, Step 11040, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Test reconstruction loss decreased (inf --> 0.020043).  Saving model ...\n",
      "Epoch 23/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.020 Test reconstruction loss: 0.020 Test covariance loss: 0.000\n",
      "Epoch: 24/25, Step 11080, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 24/25, Step 11120, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 24/25, Step 11160, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 24/25, Step 11200, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 24/25, Step 11240, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 24/25, Step 11280, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 24/25, Step 11320, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 24/25, Step 11360, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 24/25, Step 11400, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 24/25, Step 11440, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 24/25, Step 11480, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 24/25, Step 11520, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Test reconstruction loss decreased (inf --> 0.019988).  Saving model ...\n",
      "Epoch 24/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.020 Test reconstruction loss: 0.020 Test covariance loss: 0.000\n",
      "Epoch: 25/25, Step 11560, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 25/25, Step 11600, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 25/25, Step 11640, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 25/25, Step 11680, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 25/25, Step 11720, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 25/25, Step 11760, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 25/25, Step 11800, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 25/25, Step 11840, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 25/25, Step 11880, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 25/25, Step 11920, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 25/25, Step 11960, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Epoch: 25/25, Step 12000, Train loss: 0.021 Train reconstruction loss: 0.021 Train covariance loss: 0.000\n",
      "Test reconstruction loss decreased (inf --> 0.019758).  Saving model ...\n",
      "Epoch 25/25,\n",
      "Train Loss: 0.021 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.020 Test reconstruction loss: 0.020 Test covariance loss: 0.000\n",
      "Training with hidden dim: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CSANADANSYS\\AppData\\Local\\Temp\\ipykernel_24636\\1242558709.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f\"model_checkpoints/PCAAE_hidden_dim{hidden_dim}.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/25, Step 40, Train loss: 0.043 Train reconstruction loss: 0.028 Train covariance loss: 1.511\n",
      "Epoch: 1/25, Step 80, Train loss: 0.038 Train reconstruction loss: 0.023 Train covariance loss: 1.529\n",
      "Epoch: 1/25, Step 120, Train loss: 0.037 Train reconstruction loss: 0.021 Train covariance loss: 1.512\n",
      "Epoch: 1/25, Step 160, Train loss: 0.036 Train reconstruction loss: 0.021 Train covariance loss: 1.540\n",
      "Epoch: 1/25, Step 200, Train loss: 0.036 Train reconstruction loss: 0.021 Train covariance loss: 1.513\n",
      "Epoch: 1/25, Step 240, Train loss: 0.037 Train reconstruction loss: 0.021 Train covariance loss: 1.521\n",
      "Epoch: 1/25, Step 280, Train loss: 0.036 Train reconstruction loss: 0.021 Train covariance loss: 1.496\n",
      "Epoch: 1/25, Step 320, Train loss: 0.036 Train reconstruction loss: 0.021 Train covariance loss: 1.474\n",
      "Epoch: 1/25, Step 360, Train loss: 0.036 Train reconstruction loss: 0.021 Train covariance loss: 1.546\n",
      "Epoch: 1/25, Step 400, Train loss: 0.036 Train reconstruction loss: 0.021 Train covariance loss: 1.512\n",
      "Epoch: 1/25, Step 440, Train loss: 0.036 Train reconstruction loss: 0.021 Train covariance loss: 1.503\n",
      "Epoch: 1/25, Step 480, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.489\n",
      "Test reconstruction loss decreased (inf --> 0.020216).  Saving model ...\n",
      "Epoch 1/25,\n",
      "Train Loss: 0.037 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.035 Test reconstruction loss: 0.020 Test covariance loss: 1.430\n",
      "Epoch: 2/25, Step 520, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.508\n",
      "Epoch: 2/25, Step 560, Train loss: 0.036 Train reconstruction loss: 0.021 Train covariance loss: 1.519\n",
      "Epoch: 2/25, Step 600, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.493\n",
      "Epoch: 2/25, Step 640, Train loss: 0.035 Train reconstruction loss: 0.021 Train covariance loss: 1.476\n",
      "Epoch: 2/25, Step 680, Train loss: 0.036 Train reconstruction loss: 0.021 Train covariance loss: 1.540\n",
      "Epoch: 2/25, Step 720, Train loss: 0.036 Train reconstruction loss: 0.021 Train covariance loss: 1.505\n",
      "Epoch: 2/25, Step 760, Train loss: 0.036 Train reconstruction loss: 0.021 Train covariance loss: 1.536\n",
      "Epoch: 2/25, Step 800, Train loss: 0.036 Train reconstruction loss: 0.021 Train covariance loss: 1.514\n",
      "Epoch: 2/25, Step 840, Train loss: 0.036 Train reconstruction loss: 0.020 Train covariance loss: 1.537\n",
      "Epoch: 2/25, Step 880, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.487\n",
      "Epoch: 2/25, Step 920, Train loss: 0.036 Train reconstruction loss: 0.020 Train covariance loss: 1.523\n",
      "Epoch: 2/25, Step 960, Train loss: 0.036 Train reconstruction loss: 0.021 Train covariance loss: 1.503\n",
      "Test reconstruction loss decreased (inf --> 0.020027).  Saving model ...\n",
      "Epoch 2/25,\n",
      "Train Loss: 0.036 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.033 Test reconstruction loss: 0.020 Test covariance loss: 1.339\n",
      "Epoch: 3/25, Step 1000, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.523\n",
      "Epoch: 3/25, Step 1040, Train loss: 0.036 Train reconstruction loss: 0.020 Train covariance loss: 1.528\n",
      "Epoch: 3/25, Step 1080, Train loss: 0.036 Train reconstruction loss: 0.021 Train covariance loss: 1.509\n",
      "Epoch: 3/25, Step 1120, Train loss: 0.036 Train reconstruction loss: 0.020 Train covariance loss: 1.519\n",
      "Epoch: 3/25, Step 1160, Train loss: 0.036 Train reconstruction loss: 0.021 Train covariance loss: 1.508\n",
      "Epoch: 3/25, Step 1200, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.495\n",
      "Epoch: 3/25, Step 1240, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.503\n",
      "Epoch: 3/25, Step 1280, Train loss: 0.036 Train reconstruction loss: 0.020 Train covariance loss: 1.519\n",
      "Epoch: 3/25, Step 1320, Train loss: 0.036 Train reconstruction loss: 0.020 Train covariance loss: 1.512\n",
      "Epoch: 3/25, Step 1360, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.467\n",
      "Epoch: 3/25, Step 1400, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.525\n",
      "Epoch: 3/25, Step 1440, Train loss: 0.035 Train reconstruction loss: 0.021 Train covariance loss: 1.487\n",
      "Test reconstruction loss decreased (inf --> 0.019855).  Saving model ...\n",
      "Epoch 3/25,\n",
      "Train Loss: 0.035 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.037 Test reconstruction loss: 0.020 Test covariance loss: 1.743\n",
      "Epoch: 4/25, Step 1480, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.494\n",
      "Epoch: 4/25, Step 1520, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.514\n",
      "Epoch: 4/25, Step 1560, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.496\n",
      "Epoch: 4/25, Step 1600, Train loss: 0.035 Train reconstruction loss: 0.021 Train covariance loss: 1.480\n",
      "Epoch: 4/25, Step 1640, Train loss: 0.036 Train reconstruction loss: 0.020 Train covariance loss: 1.540\n",
      "Epoch: 4/25, Step 1680, Train loss: 0.036 Train reconstruction loss: 0.020 Train covariance loss: 1.542\n",
      "Epoch: 4/25, Step 1720, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.507\n",
      "Epoch: 4/25, Step 1760, Train loss: 0.036 Train reconstruction loss: 0.020 Train covariance loss: 1.524\n",
      "Epoch: 4/25, Step 1800, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.500\n",
      "Epoch: 4/25, Step 1840, Train loss: 0.036 Train reconstruction loss: 0.020 Train covariance loss: 1.521\n",
      "Epoch: 4/25, Step 1880, Train loss: 0.036 Train reconstruction loss: 0.020 Train covariance loss: 1.521\n",
      "Epoch: 4/25, Step 1920, Train loss: 0.035 Train reconstruction loss: 0.021 Train covariance loss: 1.489\n",
      "Test reconstruction loss decreased (inf --> 0.019761).  Saving model ...\n",
      "Epoch 4/25,\n",
      "Train Loss: 0.035 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.035 Test reconstruction loss: 0.020 Test covariance loss: 1.512\n",
      "Epoch: 5/25, Step 1960, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.506\n",
      "Epoch: 5/25, Step 2000, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.527\n",
      "Epoch: 5/25, Step 2040, Train loss: 0.036 Train reconstruction loss: 0.021 Train covariance loss: 1.537\n",
      "Epoch: 5/25, Step 2080, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.514\n",
      "Epoch: 5/25, Step 2120, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.523\n",
      "Epoch: 5/25, Step 2160, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.486\n",
      "Epoch: 5/25, Step 2200, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.498\n",
      "Epoch: 5/25, Step 2240, Train loss: 0.036 Train reconstruction loss: 0.020 Train covariance loss: 1.518\n",
      "Epoch: 5/25, Step 2280, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.527\n",
      "Epoch: 5/25, Step 2320, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.517\n",
      "Epoch: 5/25, Step 2360, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.495\n",
      "Epoch: 5/25, Step 2400, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.454\n",
      "Test reconstruction loss decreased (inf --> 0.019653).  Saving model ...\n",
      "Epoch 5/25,\n",
      "Train Loss: 0.035 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.035 Test reconstruction loss: 0.020 Test covariance loss: 1.546\n",
      "Epoch: 6/25, Step 2440, Train loss: 0.036 Train reconstruction loss: 0.021 Train covariance loss: 1.500\n",
      "Epoch: 6/25, Step 2480, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.501\n",
      "Epoch: 6/25, Step 2520, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.515\n",
      "Epoch: 6/25, Step 2560, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.513\n",
      "Epoch: 6/25, Step 2600, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.530\n",
      "Epoch: 6/25, Step 2640, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.508\n",
      "Epoch: 6/25, Step 2680, Train loss: 0.036 Train reconstruction loss: 0.020 Train covariance loss: 1.534\n",
      "Epoch: 6/25, Step 2720, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.527\n",
      "Epoch: 6/25, Step 2760, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.525\n",
      "Epoch: 6/25, Step 2800, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.500\n",
      "Epoch: 6/25, Step 2840, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.470\n",
      "Epoch: 6/25, Step 2880, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.531\n",
      "Test reconstruction loss decreased (inf --> 0.019575).  Saving model ...\n",
      "Epoch 6/25,\n",
      "Train Loss: 0.035 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.033 Test reconstruction loss: 0.020 Test covariance loss: 1.355\n",
      "Epoch: 7/25, Step 2920, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.485\n",
      "Epoch: 7/25, Step 2960, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.523\n",
      "Epoch: 7/25, Step 3000, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.494\n",
      "Epoch: 7/25, Step 3040, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.543\n",
      "Epoch: 7/25, Step 3080, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.506\n",
      "Epoch: 7/25, Step 3120, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.493\n",
      "Epoch: 7/25, Step 3160, Train loss: 0.036 Train reconstruction loss: 0.020 Train covariance loss: 1.563\n",
      "Epoch: 7/25, Step 3200, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.506\n",
      "Epoch: 7/25, Step 3240, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.515\n",
      "Epoch: 7/25, Step 3280, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.503\n",
      "Epoch: 7/25, Step 3320, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.504\n",
      "Epoch: 7/25, Step 3360, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.518\n",
      "Test reconstruction loss decreased (inf --> 0.019514).  Saving model ...\n",
      "Epoch 7/25,\n",
      "Train Loss: 0.035 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.035 Test reconstruction loss: 0.020 Test covariance loss: 1.517\n",
      "Epoch: 8/25, Step 3400, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.505\n",
      "Epoch: 8/25, Step 3440, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.530\n",
      "Epoch: 8/25, Step 3480, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.512\n",
      "Epoch: 8/25, Step 3520, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.518\n",
      "Epoch: 8/25, Step 3560, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.512\n",
      "Epoch: 8/25, Step 3600, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.500\n",
      "Epoch: 8/25, Step 3640, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.536\n",
      "Epoch: 8/25, Step 3680, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.523\n",
      "Epoch: 8/25, Step 3720, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.494\n",
      "Epoch: 8/25, Step 3760, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.509\n",
      "Epoch: 8/25, Step 3800, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.504\n",
      "Epoch: 8/25, Step 3840, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.524\n",
      "Test reconstruction loss decreased (inf --> 0.019470).  Saving model ...\n",
      "Epoch 8/25,\n",
      "Train Loss: 0.035 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.033 Test reconstruction loss: 0.019 Test covariance loss: 1.379\n",
      "Epoch: 9/25, Step 3880, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.508\n",
      "Epoch: 9/25, Step 3920, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.520\n",
      "Epoch: 9/25, Step 3960, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.516\n",
      "Epoch: 9/25, Step 4000, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.526\n",
      "Epoch: 9/25, Step 4040, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.490\n",
      "Epoch: 9/25, Step 4080, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.532\n",
      "Epoch: 9/25, Step 4120, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.476\n",
      "Epoch: 9/25, Step 4160, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.525\n",
      "Epoch: 9/25, Step 4200, Train loss: 0.036 Train reconstruction loss: 0.020 Train covariance loss: 1.538\n",
      "Epoch: 9/25, Step 4240, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.518\n",
      "Epoch: 9/25, Step 4280, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.514\n",
      "Epoch: 9/25, Step 4320, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.476\n",
      "Test reconstruction loss decreased (inf --> 0.019421).  Saving model ...\n",
      "Epoch 9/25,\n",
      "Train Loss: 0.035 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.035 Test reconstruction loss: 0.019 Test covariance loss: 1.516\n",
      "Epoch: 10/25, Step 4360, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.511\n",
      "Epoch: 10/25, Step 4400, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.506\n",
      "Epoch: 10/25, Step 4440, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.512\n",
      "Epoch: 10/25, Step 4480, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.509\n",
      "Epoch: 10/25, Step 4520, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.519\n",
      "Epoch: 10/25, Step 4560, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.502\n",
      "Epoch: 10/25, Step 4600, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.527\n",
      "Epoch: 10/25, Step 4640, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.490\n",
      "Epoch: 10/25, Step 4680, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.564\n",
      "Epoch: 10/25, Step 4720, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.534\n",
      "Epoch: 10/25, Step 4760, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.503\n",
      "Epoch: 10/25, Step 4800, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.505\n",
      "Test reconstruction loss decreased (inf --> 0.019381).  Saving model ...\n",
      "Epoch 10/25,\n",
      "Train Loss: 0.035 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.033 Test reconstruction loss: 0.019 Test covariance loss: 1.358\n",
      "Epoch: 11/25, Step 4840, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.524\n",
      "Epoch: 11/25, Step 4880, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.509\n",
      "Epoch: 11/25, Step 4920, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.520\n",
      "Epoch: 11/25, Step 4960, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.538\n",
      "Epoch: 11/25, Step 5000, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.518\n",
      "Epoch: 11/25, Step 5040, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.488\n",
      "Epoch: 11/25, Step 5080, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.516\n",
      "Epoch: 11/25, Step 5120, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.487\n",
      "Epoch: 11/25, Step 5160, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.525\n",
      "Epoch: 11/25, Step 5200, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.499\n",
      "Epoch: 11/25, Step 5240, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.514\n",
      "Epoch: 11/25, Step 5280, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.471\n",
      "Test reconstruction loss decreased (inf --> 0.019427).  Saving model ...\n",
      "Epoch 11/25,\n",
      "Train Loss: 0.035 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.035 Test reconstruction loss: 0.019 Test covariance loss: 1.539\n",
      "Epoch: 12/25, Step 5320, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.507\n",
      "Epoch: 12/25, Step 5360, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.494\n",
      "Epoch: 12/25, Step 5400, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.504\n",
      "Epoch: 12/25, Step 5440, Train loss: 0.036 Train reconstruction loss: 0.021 Train covariance loss: 1.500\n",
      "Epoch: 12/25, Step 5480, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.504\n",
      "Epoch: 12/25, Step 5520, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.517\n",
      "Epoch: 12/25, Step 5560, Train loss: 0.036 Train reconstruction loss: 0.020 Train covariance loss: 1.553\n",
      "Epoch: 12/25, Step 5600, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.501\n",
      "Epoch: 12/25, Step 5640, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.489\n",
      "Epoch: 12/25, Step 5680, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.535\n",
      "Epoch: 12/25, Step 5720, Train loss: 0.035 Train reconstruction loss: 0.019 Train covariance loss: 1.526\n",
      "Epoch: 12/25, Step 5760, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.509\n",
      "Test reconstruction loss decreased (inf --> 0.019381).  Saving model ...\n",
      "Epoch 12/25,\n",
      "Train Loss: 0.035 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.035 Test reconstruction loss: 0.019 Test covariance loss: 1.579\n",
      "Epoch: 13/25, Step 5800, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.498\n",
      "Epoch: 13/25, Step 5840, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.492\n",
      "Epoch: 13/25, Step 5880, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.508\n",
      "Epoch: 13/25, Step 5920, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.504\n",
      "Epoch: 13/25, Step 5960, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.506\n",
      "Epoch: 13/25, Step 6000, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.546\n",
      "Epoch: 13/25, Step 6040, Train loss: 0.035 Train reconstruction loss: 0.019 Train covariance loss: 1.537\n",
      "Epoch: 13/25, Step 6080, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.519\n",
      "Epoch: 13/25, Step 6120, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.492\n",
      "Epoch: 13/25, Step 6160, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.558\n",
      "Epoch: 13/25, Step 6200, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.511\n",
      "Epoch: 13/25, Step 6240, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.496\n",
      "Test reconstruction loss decreased (inf --> 0.019345).  Saving model ...\n",
      "Epoch 13/25,\n",
      "Train Loss: 0.035 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.036 Test reconstruction loss: 0.019 Test covariance loss: 1.661\n",
      "Epoch: 14/25, Step 6280, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.515\n",
      "Epoch: 14/25, Step 6320, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.506\n",
      "Epoch: 14/25, Step 6360, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.499\n",
      "Epoch: 14/25, Step 6400, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.519\n",
      "Epoch: 14/25, Step 6440, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.553\n",
      "Epoch: 14/25, Step 6480, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.500\n",
      "Epoch: 14/25, Step 6520, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.507\n",
      "Epoch: 14/25, Step 6560, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.521\n",
      "Epoch: 14/25, Step 6600, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.483\n",
      "Epoch: 14/25, Step 6640, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.508\n",
      "Epoch: 14/25, Step 6680, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.528\n",
      "Epoch: 14/25, Step 6720, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.509\n",
      "Test reconstruction loss decreased (inf --> 0.019283).  Saving model ...\n",
      "Epoch 14/25,\n",
      "Train Loss: 0.035 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.033 Test reconstruction loss: 0.019 Test covariance loss: 1.398\n",
      "Epoch: 15/25, Step 6760, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.509\n",
      "Epoch: 15/25, Step 6800, Train loss: 0.034 Train reconstruction loss: 0.020 Train covariance loss: 1.484\n",
      "Epoch: 15/25, Step 6840, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.545\n",
      "Epoch: 15/25, Step 6880, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.514\n",
      "Epoch: 15/25, Step 6920, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.492\n",
      "Epoch: 15/25, Step 6960, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.515\n",
      "Epoch: 15/25, Step 7000, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.489\n",
      "Epoch: 15/25, Step 7040, Train loss: 0.035 Train reconstruction loss: 0.019 Train covariance loss: 1.555\n",
      "Epoch: 15/25, Step 7080, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.529\n",
      "Epoch: 15/25, Step 7120, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.515\n",
      "Epoch: 15/25, Step 7160, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.539\n",
      "Epoch: 15/25, Step 7200, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.466\n",
      "Test reconstruction loss decreased (inf --> 0.019317).  Saving model ...\n",
      "Epoch 15/25,\n",
      "Train Loss: 0.035 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.035 Test reconstruction loss: 0.019 Test covariance loss: 1.552\n",
      "Epoch: 16/25, Step 7240, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.493\n",
      "Epoch: 16/25, Step 7280, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.498\n",
      "Epoch: 16/25, Step 7320, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.484\n",
      "Epoch: 16/25, Step 7360, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.546\n",
      "Epoch: 16/25, Step 7400, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.505\n",
      "Epoch: 16/25, Step 7440, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.503\n",
      "Epoch: 16/25, Step 7480, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.512\n",
      "Epoch: 16/25, Step 7520, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.504\n",
      "Epoch: 16/25, Step 7560, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.505\n",
      "Epoch: 16/25, Step 7600, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.519\n",
      "Epoch: 16/25, Step 7640, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.543\n",
      "Epoch: 16/25, Step 7680, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.530\n",
      "Test reconstruction loss decreased (inf --> 0.019254).  Saving model ...\n",
      "Epoch 16/25,\n",
      "Train Loss: 0.035 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.033 Test reconstruction loss: 0.019 Test covariance loss: 1.332\n",
      "Epoch: 17/25, Step 7720, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.525\n",
      "Epoch: 17/25, Step 7760, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.543\n",
      "Epoch: 17/25, Step 7800, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.507\n",
      "Epoch: 17/25, Step 7840, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.503\n",
      "Epoch: 17/25, Step 7880, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.496\n",
      "Epoch: 17/25, Step 7920, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.496\n",
      "Epoch: 17/25, Step 7960, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.475\n",
      "Epoch: 17/25, Step 8000, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.547\n",
      "Epoch: 17/25, Step 8040, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.531\n",
      "Epoch: 17/25, Step 8080, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.513\n",
      "Epoch: 17/25, Step 8120, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.499\n",
      "Epoch: 17/25, Step 8160, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.518\n",
      "Test reconstruction loss decreased (inf --> 0.019248).  Saving model ...\n",
      "Epoch 17/25,\n",
      "Train Loss: 0.035 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.034 Test reconstruction loss: 0.019 Test covariance loss: 1.426\n",
      "Epoch: 18/25, Step 8200, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.499\n",
      "Epoch: 18/25, Step 8240, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.527\n",
      "Epoch: 18/25, Step 8280, Train loss: 0.034 Train reconstruction loss: 0.020 Train covariance loss: 1.491\n",
      "Epoch: 18/25, Step 8320, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.480\n",
      "Epoch: 18/25, Step 8360, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.519\n",
      "Epoch: 18/25, Step 8400, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.510\n",
      "Epoch: 18/25, Step 8440, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.543\n",
      "Epoch: 18/25, Step 8480, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.475\n",
      "Epoch: 18/25, Step 8520, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.551\n",
      "Epoch: 18/25, Step 8560, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.563\n",
      "Epoch: 18/25, Step 8600, Train loss: 0.034 Train reconstruction loss: 0.020 Train covariance loss: 1.473\n",
      "Epoch: 18/25, Step 8640, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.502\n",
      "Test reconstruction loss decreased (inf --> 0.019277).  Saving model ...\n",
      "Epoch 18/25,\n",
      "Train Loss: 0.035 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.033 Test reconstruction loss: 0.019 Test covariance loss: 1.325\n",
      "Epoch: 19/25, Step 8680, Train loss: 0.035 Train reconstruction loss: 0.019 Train covariance loss: 1.538\n",
      "Epoch: 19/25, Step 8720, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.524\n",
      "Epoch: 19/25, Step 8760, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.493\n",
      "Epoch: 19/25, Step 8800, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.548\n",
      "Epoch: 19/25, Step 8840, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.512\n",
      "Epoch: 19/25, Step 8880, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.498\n",
      "Epoch: 19/25, Step 8920, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.512\n",
      "Epoch: 19/25, Step 8960, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.534\n",
      "Epoch: 19/25, Step 9000, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.502\n",
      "Epoch: 19/25, Step 9040, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.501\n",
      "Epoch: 19/25, Step 9080, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.484\n",
      "Epoch: 19/25, Step 9120, Train loss: 0.034 Train reconstruction loss: 0.019 Train covariance loss: 1.490\n",
      "Test reconstruction loss decreased (inf --> 0.019202).  Saving model ...\n",
      "Epoch 19/25,\n",
      "Train Loss: 0.035 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.033 Test reconstruction loss: 0.019 Test covariance loss: 1.413\n",
      "Epoch: 20/25, Step 9160, Train loss: 0.036 Train reconstruction loss: 0.020 Train covariance loss: 1.528\n",
      "Epoch: 20/25, Step 9200, Train loss: 0.035 Train reconstruction loss: 0.019 Train covariance loss: 1.513\n",
      "Epoch: 20/25, Step 9240, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.481\n",
      "Epoch: 20/25, Step 9280, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.505\n",
      "Epoch: 20/25, Step 9320, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.550\n",
      "Epoch: 20/25, Step 9360, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.492\n",
      "Epoch: 20/25, Step 9400, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.502\n",
      "Epoch: 20/25, Step 9440, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.489\n",
      "Epoch: 20/25, Step 9480, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.530\n",
      "Epoch: 20/25, Step 9520, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.498\n",
      "Epoch: 20/25, Step 9560, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.508\n",
      "Epoch: 20/25, Step 9600, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.518\n",
      "Test reconstruction loss decreased (inf --> 0.019173).  Saving model ...\n",
      "Epoch 20/25,\n",
      "Train Loss: 0.035 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.034 Test reconstruction loss: 0.019 Test covariance loss: 1.503\n",
      "Epoch: 21/25, Step 9640, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.508\n",
      "Epoch: 21/25, Step 9680, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.499\n",
      "Epoch: 21/25, Step 9720, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.528\n",
      "Epoch: 21/25, Step 9760, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.505\n",
      "Epoch: 21/25, Step 9800, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.500\n",
      "Epoch: 21/25, Step 9840, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.505\n",
      "Epoch: 21/25, Step 9880, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.515\n",
      "Epoch: 21/25, Step 9920, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.526\n",
      "Epoch: 21/25, Step 9960, Train loss: 0.035 Train reconstruction loss: 0.019 Train covariance loss: 1.523\n",
      "Epoch: 21/25, Step 10000, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.503\n",
      "Epoch: 21/25, Step 10040, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.495\n",
      "Epoch: 21/25, Step 10080, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.520\n",
      "Test reconstruction loss decreased (inf --> 0.019161).  Saving model ...\n",
      "Epoch 21/25,\n",
      "Train Loss: 0.035 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.034 Test reconstruction loss: 0.019 Test covariance loss: 1.445\n",
      "Epoch: 22/25, Step 10120, Train loss: 0.035 Train reconstruction loss: 0.019 Train covariance loss: 1.537\n",
      "Epoch: 22/25, Step 10160, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.518\n",
      "Epoch: 22/25, Step 10200, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.516\n",
      "Epoch: 22/25, Step 10240, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.522\n",
      "Epoch: 22/25, Step 10280, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.492\n",
      "Epoch: 22/25, Step 10320, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.511\n",
      "Epoch: 22/25, Step 10360, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.488\n",
      "Epoch: 22/25, Step 10400, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.525\n",
      "Epoch: 22/25, Step 10440, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.501\n",
      "Epoch: 22/25, Step 10480, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.501\n",
      "Epoch: 22/25, Step 10520, Train loss: 0.035 Train reconstruction loss: 0.019 Train covariance loss: 1.532\n",
      "Epoch: 22/25, Step 10560, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.512\n",
      "Test reconstruction loss decreased (inf --> 0.019164).  Saving model ...\n",
      "Epoch 22/25,\n",
      "Train Loss: 0.035 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.034 Test reconstruction loss: 0.019 Test covariance loss: 1.470\n",
      "Epoch: 23/25, Step 10600, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.520\n",
      "Epoch: 23/25, Step 10640, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.506\n",
      "Epoch: 23/25, Step 10680, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.510\n",
      "Epoch: 23/25, Step 10720, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.518\n",
      "Epoch: 23/25, Step 10760, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.515\n",
      "Epoch: 23/25, Step 10800, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.498\n",
      "Epoch: 23/25, Step 10840, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.510\n",
      "Epoch: 23/25, Step 10880, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.478\n",
      "Epoch: 23/25, Step 10920, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.501\n",
      "Epoch: 23/25, Step 10960, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.551\n",
      "Epoch: 23/25, Step 11000, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.517\n",
      "Epoch: 23/25, Step 11040, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.510\n",
      "Test reconstruction loss decreased (inf --> 0.019228).  Saving model ...\n",
      "Epoch 23/25,\n",
      "Train Loss: 0.035 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.032 Test reconstruction loss: 0.019 Test covariance loss: 1.289\n",
      "Epoch: 24/25, Step 11080, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.518\n",
      "Epoch: 24/25, Step 11120, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.500\n",
      "Epoch: 24/25, Step 11160, Train loss: 0.034 Train reconstruction loss: 0.020 Train covariance loss: 1.495\n",
      "Epoch: 24/25, Step 11200, Train loss: 0.034 Train reconstruction loss: 0.019 Train covariance loss: 1.511\n",
      "Epoch: 24/25, Step 11240, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.504\n",
      "Epoch: 24/25, Step 11280, Train loss: 0.034 Train reconstruction loss: 0.020 Train covariance loss: 1.491\n",
      "Epoch: 24/25, Step 11320, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.518\n",
      "Epoch: 24/25, Step 11360, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.547\n",
      "Epoch: 24/25, Step 11400, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.524\n",
      "Epoch: 24/25, Step 11440, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.514\n",
      "Epoch: 24/25, Step 11480, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.503\n",
      "Epoch: 24/25, Step 11520, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.533\n",
      "Test reconstruction loss decreased (inf --> 0.019196).  Saving model ...\n",
      "Epoch 24/25,\n",
      "Train Loss: 0.035 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.032 Test reconstruction loss: 0.019 Test covariance loss: 1.295\n",
      "Epoch: 25/25, Step 11560, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.510\n",
      "Epoch: 25/25, Step 11600, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.541\n",
      "Epoch: 25/25, Step 11640, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.527\n",
      "Epoch: 25/25, Step 11680, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.492\n",
      "Epoch: 25/25, Step 11720, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.517\n",
      "Epoch: 25/25, Step 11760, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.504\n",
      "Epoch: 25/25, Step 11800, Train loss: 0.035 Train reconstruction loss: 0.019 Train covariance loss: 1.517\n",
      "Epoch: 25/25, Step 11840, Train loss: 0.035 Train reconstruction loss: 0.019 Train covariance loss: 1.524\n",
      "Epoch: 25/25, Step 11880, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.539\n",
      "Epoch: 25/25, Step 11920, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.493\n",
      "Epoch: 25/25, Step 11960, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.499\n",
      "Epoch: 25/25, Step 12000, Train loss: 0.035 Train reconstruction loss: 0.020 Train covariance loss: 1.513\n",
      "Test reconstruction loss decreased (inf --> 0.019175).  Saving model ...\n",
      "Epoch 25/25,\n",
      "Train Loss: 0.035 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.033 Test reconstruction loss: 0.019 Test covariance loss: 1.360\n",
      "Training with hidden dim: 3\n",
      "Epoch: 1/25, Step 40, Train loss: 0.065 Train reconstruction loss: 0.030 Train covariance loss: 3.489\n",
      "Epoch: 1/25, Step 80, Train loss: 0.054 Train reconstruction loss: 0.021 Train covariance loss: 3.290\n",
      "Epoch: 1/25, Step 120, Train loss: 0.055 Train reconstruction loss: 0.021 Train covariance loss: 3.420\n",
      "Epoch: 1/25, Step 160, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.304\n",
      "Epoch: 1/25, Step 200, Train loss: 0.053 Train reconstruction loss: 0.021 Train covariance loss: 3.270\n",
      "Epoch: 1/25, Step 240, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.364\n",
      "Epoch: 1/25, Step 280, Train loss: 0.052 Train reconstruction loss: 0.020 Train covariance loss: 3.223\n",
      "Epoch: 1/25, Step 320, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.304\n",
      "Epoch: 1/25, Step 360, Train loss: 0.057 Train reconstruction loss: 0.020 Train covariance loss: 3.631\n",
      "Epoch: 1/25, Step 400, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.321\n",
      "Epoch: 1/25, Step 440, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.384\n",
      "Epoch: 1/25, Step 480, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.399\n",
      "Test reconstruction loss decreased (inf --> 0.019419).  Saving model ...\n",
      "Epoch 1/25,\n",
      "Train Loss: 0.055 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.052 Test reconstruction loss: 0.019 Test covariance loss: 3.277\n",
      "Epoch: 2/25, Step 520, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.405\n",
      "Epoch: 2/25, Step 560, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.337\n",
      "Epoch: 2/25, Step 600, Train loss: 0.052 Train reconstruction loss: 0.020 Train covariance loss: 3.172\n",
      "Epoch: 2/25, Step 640, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.356\n",
      "Epoch: 2/25, Step 680, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.387\n",
      "Epoch: 2/25, Step 720, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.380\n",
      "Epoch: 2/25, Step 760, Train loss: 0.055 Train reconstruction loss: 0.020 Train covariance loss: 3.453\n",
      "Epoch: 2/25, Step 800, Train loss: 0.052 Train reconstruction loss: 0.020 Train covariance loss: 3.226\n",
      "Epoch: 2/25, Step 840, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.376\n",
      "Epoch: 2/25, Step 880, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.497\n",
      "Epoch: 2/25, Step 920, Train loss: 0.052 Train reconstruction loss: 0.020 Train covariance loss: 3.269\n",
      "Epoch: 2/25, Step 960, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.443\n",
      "Test reconstruction loss decreased (inf --> 0.019274).  Saving model ...\n",
      "Epoch 2/25,\n",
      "Train Loss: 0.053 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.052 Test reconstruction loss: 0.019 Test covariance loss: 3.231\n",
      "Epoch: 3/25, Step 1000, Train loss: 0.052 Train reconstruction loss: 0.020 Train covariance loss: 3.246\n",
      "Epoch: 3/25, Step 1040, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.370\n",
      "Epoch: 3/25, Step 1080, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.454\n",
      "Epoch: 3/25, Step 1120, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.400\n",
      "Epoch: 3/25, Step 1160, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.367\n",
      "Epoch: 3/25, Step 1200, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.317\n",
      "Epoch: 3/25, Step 1240, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.398\n",
      "Epoch: 3/25, Step 1280, Train loss: 0.052 Train reconstruction loss: 0.020 Train covariance loss: 3.270\n",
      "Epoch: 3/25, Step 1320, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.312\n",
      "Epoch: 3/25, Step 1360, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.329\n",
      "Epoch: 3/25, Step 1400, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.447\n",
      "Epoch: 3/25, Step 1440, Train loss: 0.055 Train reconstruction loss: 0.020 Train covariance loss: 3.515\n",
      "Test reconstruction loss decreased (inf --> 0.019149).  Saving model ...\n",
      "Epoch 3/25,\n",
      "Train Loss: 0.053 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.053 Test reconstruction loss: 0.019 Test covariance loss: 3.368\n",
      "Epoch: 4/25, Step 1480, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.462\n",
      "Epoch: 4/25, Step 1520, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.343\n",
      "Epoch: 4/25, Step 1560, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.446\n",
      "Epoch: 4/25, Step 1600, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.419\n",
      "Epoch: 4/25, Step 1640, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.338\n",
      "Epoch: 4/25, Step 1680, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.407\n",
      "Epoch: 4/25, Step 1720, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.383\n",
      "Epoch: 4/25, Step 1760, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.264\n",
      "Epoch: 4/25, Step 1800, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.348\n",
      "Epoch: 4/25, Step 1840, Train loss: 0.052 Train reconstruction loss: 0.020 Train covariance loss: 3.256\n",
      "Epoch: 4/25, Step 1880, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.298\n",
      "Epoch: 4/25, Step 1920, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.364\n",
      "Test reconstruction loss decreased (inf --> 0.019108).  Saving model ...\n",
      "Epoch 4/25,\n",
      "Train Loss: 0.053 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.051 Test reconstruction loss: 0.019 Test covariance loss: 3.189\n",
      "Epoch: 5/25, Step 1960, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.395\n",
      "Epoch: 5/25, Step 2000, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.445\n",
      "Epoch: 5/25, Step 2040, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.404\n",
      "Epoch: 5/25, Step 2080, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.236\n",
      "Epoch: 5/25, Step 2120, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.309\n",
      "Epoch: 5/25, Step 2160, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.429\n",
      "Epoch: 5/25, Step 2200, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.434\n",
      "Epoch: 5/25, Step 2240, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.304\n",
      "Epoch: 5/25, Step 2280, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.424\n",
      "Epoch: 5/25, Step 2320, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.287\n",
      "Epoch: 5/25, Step 2360, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.357\n",
      "Epoch: 5/25, Step 2400, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.328\n",
      "Test reconstruction loss decreased (inf --> 0.019082).  Saving model ...\n",
      "Epoch 5/25,\n",
      "Train Loss: 0.053 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.052 Test reconstruction loss: 0.019 Test covariance loss: 3.282\n",
      "Epoch: 6/25, Step 2440, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.414\n",
      "Epoch: 6/25, Step 2480, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.506\n",
      "Epoch: 6/25, Step 2520, Train loss: 0.055 Train reconstruction loss: 0.020 Train covariance loss: 3.534\n",
      "Epoch: 6/25, Step 2560, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.312\n",
      "Epoch: 6/25, Step 2600, Train loss: 0.055 Train reconstruction loss: 0.020 Train covariance loss: 3.524\n",
      "Epoch: 6/25, Step 2640, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.341\n",
      "Epoch: 6/25, Step 2680, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.241\n",
      "Epoch: 6/25, Step 2720, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.359\n",
      "Epoch: 6/25, Step 2760, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.236\n",
      "Epoch: 6/25, Step 2800, Train loss: 0.052 Train reconstruction loss: 0.020 Train covariance loss: 3.234\n",
      "Epoch: 6/25, Step 2840, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.444\n",
      "Epoch: 6/25, Step 2880, Train loss: 0.052 Train reconstruction loss: 0.020 Train covariance loss: 3.240\n",
      "Test reconstruction loss decreased (inf --> 0.019054).  Saving model ...\n",
      "Epoch 6/25,\n",
      "Train Loss: 0.053 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.050 Test reconstruction loss: 0.019 Test covariance loss: 3.136\n",
      "Epoch: 7/25, Step 2920, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.354\n",
      "Epoch: 7/25, Step 2960, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.358\n",
      "Epoch: 7/25, Step 3000, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.472\n",
      "Epoch: 7/25, Step 3040, Train loss: 0.052 Train reconstruction loss: 0.020 Train covariance loss: 3.214\n",
      "Epoch: 7/25, Step 3080, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.450\n",
      "Epoch: 7/25, Step 3120, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.370\n",
      "Epoch: 7/25, Step 3160, Train loss: 0.052 Train reconstruction loss: 0.020 Train covariance loss: 3.249\n",
      "Epoch: 7/25, Step 3200, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.448\n",
      "Epoch: 7/25, Step 3240, Train loss: 0.055 Train reconstruction loss: 0.020 Train covariance loss: 3.495\n",
      "Epoch: 7/25, Step 3280, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.228\n",
      "Epoch: 7/25, Step 3320, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.317\n",
      "Epoch: 7/25, Step 3360, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.369\n",
      "Test reconstruction loss decreased (inf --> 0.019107).  Saving model ...\n",
      "Epoch 7/25,\n",
      "Train Loss: 0.053 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.054 Test reconstruction loss: 0.019 Test covariance loss: 3.488\n",
      "Epoch: 8/25, Step 3400, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.463\n",
      "Epoch: 8/25, Step 3440, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.284\n",
      "Epoch: 8/25, Step 3480, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.353\n",
      "Epoch: 8/25, Step 3520, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.411\n",
      "Epoch: 8/25, Step 3560, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.352\n",
      "Epoch: 8/25, Step 3600, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.419\n",
      "Epoch: 8/25, Step 3640, Train loss: 0.052 Train reconstruction loss: 0.020 Train covariance loss: 3.293\n",
      "Epoch: 8/25, Step 3680, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.409\n",
      "Epoch: 8/25, Step 3720, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.356\n",
      "Epoch: 8/25, Step 3760, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.323\n",
      "Epoch: 8/25, Step 3800, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.380\n",
      "Epoch: 8/25, Step 3840, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.449\n",
      "Test reconstruction loss decreased (inf --> 0.019075).  Saving model ...\n",
      "Epoch 8/25,\n",
      "Train Loss: 0.053 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.050 Test reconstruction loss: 0.019 Test covariance loss: 3.122\n",
      "Epoch: 9/25, Step 3880, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.316\n",
      "Epoch: 9/25, Step 3920, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.391\n",
      "Epoch: 9/25, Step 3960, Train loss: 0.051 Train reconstruction loss: 0.020 Train covariance loss: 3.126\n",
      "Epoch: 9/25, Step 4000, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.429\n",
      "Epoch: 9/25, Step 4040, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.332\n",
      "Epoch: 9/25, Step 4080, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.451\n",
      "Epoch: 9/25, Step 4120, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.389\n",
      "Epoch: 9/25, Step 4160, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.492\n",
      "Epoch: 9/25, Step 4200, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.372\n",
      "Epoch: 9/25, Step 4240, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.222\n",
      "Epoch: 9/25, Step 4280, Train loss: 0.055 Train reconstruction loss: 0.020 Train covariance loss: 3.505\n",
      "Epoch: 9/25, Step 4320, Train loss: 0.055 Train reconstruction loss: 0.020 Train covariance loss: 3.496\n",
      "Test reconstruction loss decreased (inf --> 0.018997).  Saving model ...\n",
      "Epoch 9/25,\n",
      "Train Loss: 0.053 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.054 Test reconstruction loss: 0.019 Test covariance loss: 3.522\n",
      "Epoch: 10/25, Step 4360, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.293\n",
      "Epoch: 10/25, Step 4400, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.276\n",
      "Epoch: 10/25, Step 4440, Train loss: 0.055 Train reconstruction loss: 0.019 Train covariance loss: 3.513\n",
      "Epoch: 10/25, Step 4480, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.441\n",
      "Epoch: 10/25, Step 4520, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.421\n",
      "Epoch: 10/25, Step 4560, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.259\n",
      "Epoch: 10/25, Step 4600, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.355\n",
      "Epoch: 10/25, Step 4640, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.371\n",
      "Epoch: 10/25, Step 4680, Train loss: 0.055 Train reconstruction loss: 0.019 Train covariance loss: 3.578\n",
      "Epoch: 10/25, Step 4720, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.284\n",
      "Epoch: 10/25, Step 4760, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.336\n",
      "Epoch: 10/25, Step 4800, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.367\n",
      "Test reconstruction loss decreased (inf --> 0.018974).  Saving model ...\n",
      "Epoch 10/25,\n",
      "Train Loss: 0.053 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.053 Test reconstruction loss: 0.019 Test covariance loss: 3.433\n",
      "Epoch: 11/25, Step 4840, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.347\n",
      "Epoch: 11/25, Step 4880, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.314\n",
      "Epoch: 11/25, Step 4920, Train loss: 0.051 Train reconstruction loss: 0.019 Train covariance loss: 3.158\n",
      "Epoch: 11/25, Step 4960, Train loss: 0.051 Train reconstruction loss: 0.020 Train covariance loss: 3.184\n",
      "Epoch: 11/25, Step 5000, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.335\n",
      "Epoch: 11/25, Step 5040, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.451\n",
      "Epoch: 11/25, Step 5080, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.280\n",
      "Epoch: 11/25, Step 5120, Train loss: 0.055 Train reconstruction loss: 0.019 Train covariance loss: 3.578\n",
      "Epoch: 11/25, Step 5160, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.463\n",
      "Epoch: 11/25, Step 5200, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.459\n",
      "Epoch: 11/25, Step 5240, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.377\n",
      "Epoch: 11/25, Step 5280, Train loss: 0.055 Train reconstruction loss: 0.019 Train covariance loss: 3.604\n",
      "Test reconstruction loss decreased (inf --> 0.018978).  Saving model ...\n",
      "Epoch 11/25,\n",
      "Train Loss: 0.053 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.051 Test reconstruction loss: 0.019 Test covariance loss: 3.204\n",
      "Epoch: 12/25, Step 5320, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.395\n",
      "Epoch: 12/25, Step 5360, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.269\n",
      "Epoch: 12/25, Step 5400, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.266\n",
      "Epoch: 12/25, Step 5440, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.299\n",
      "Epoch: 12/25, Step 5480, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.385\n",
      "Epoch: 12/25, Step 5520, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.321\n",
      "Epoch: 12/25, Step 5560, Train loss: 0.055 Train reconstruction loss: 0.020 Train covariance loss: 3.506\n",
      "Epoch: 12/25, Step 5600, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.325\n",
      "Epoch: 12/25, Step 5640, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.266\n",
      "Epoch: 12/25, Step 5680, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.482\n",
      "Epoch: 12/25, Step 5720, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.360\n",
      "Epoch: 12/25, Step 5760, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.455\n",
      "Test reconstruction loss decreased (inf --> 0.018873).  Saving model ...\n",
      "Epoch 12/25,\n",
      "Train Loss: 0.053 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.052 Test reconstruction loss: 0.019 Test covariance loss: 3.278\n",
      "Epoch: 13/25, Step 5800, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.342\n",
      "Epoch: 13/25, Step 5840, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.256\n",
      "Epoch: 13/25, Step 5880, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.364\n",
      "Epoch: 13/25, Step 5920, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.410\n",
      "Epoch: 13/25, Step 5960, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.371\n",
      "Epoch: 13/25, Step 6000, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.337\n",
      "Epoch: 13/25, Step 6040, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.509\n",
      "Epoch: 13/25, Step 6080, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.448\n",
      "Epoch: 13/25, Step 6120, Train loss: 0.052 Train reconstruction loss: 0.020 Train covariance loss: 3.239\n",
      "Epoch: 13/25, Step 6160, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.381\n",
      "Epoch: 13/25, Step 6200, Train loss: 0.055 Train reconstruction loss: 0.020 Train covariance loss: 3.494\n",
      "Epoch: 13/25, Step 6240, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.378\n",
      "Test reconstruction loss decreased (inf --> 0.018906).  Saving model ...\n",
      "Epoch 13/25,\n",
      "Train Loss: 0.053 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.050 Test reconstruction loss: 0.019 Test covariance loss: 3.140\n",
      "Epoch: 14/25, Step 6280, Train loss: 0.052 Train reconstruction loss: 0.020 Train covariance loss: 3.254\n",
      "Epoch: 14/25, Step 6320, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.330\n",
      "Epoch: 14/25, Step 6360, Train loss: 0.055 Train reconstruction loss: 0.020 Train covariance loss: 3.493\n",
      "Epoch: 14/25, Step 6400, Train loss: 0.055 Train reconstruction loss: 0.020 Train covariance loss: 3.501\n",
      "Epoch: 14/25, Step 6440, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.441\n",
      "Epoch: 14/25, Step 6480, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.361\n",
      "Epoch: 14/25, Step 6520, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.493\n",
      "Epoch: 14/25, Step 6560, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.349\n",
      "Epoch: 14/25, Step 6600, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.327\n",
      "Epoch: 14/25, Step 6640, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.420\n",
      "Epoch: 14/25, Step 6680, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.325\n",
      "Epoch: 14/25, Step 6720, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.427\n",
      "Test reconstruction loss decreased (inf --> 0.018918).  Saving model ...\n",
      "Epoch 14/25,\n",
      "Train Loss: 0.053 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.050 Test reconstruction loss: 0.019 Test covariance loss: 3.079\n",
      "Epoch: 15/25, Step 6760, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.509\n",
      "Epoch: 15/25, Step 6800, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.468\n",
      "Epoch: 15/25, Step 6840, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.272\n",
      "Epoch: 15/25, Step 6880, Train loss: 0.051 Train reconstruction loss: 0.019 Train covariance loss: 3.177\n",
      "Epoch: 15/25, Step 6920, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.271\n",
      "Epoch: 15/25, Step 6960, Train loss: 0.055 Train reconstruction loss: 0.019 Train covariance loss: 3.532\n",
      "Epoch: 15/25, Step 7000, Train loss: 0.051 Train reconstruction loss: 0.019 Train covariance loss: 3.196\n",
      "Epoch: 15/25, Step 7040, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.441\n",
      "Epoch: 15/25, Step 7080, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.379\n",
      "Epoch: 15/25, Step 7120, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.424\n",
      "Epoch: 15/25, Step 7160, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.406\n",
      "Epoch: 15/25, Step 7200, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.366\n",
      "Test reconstruction loss decreased (inf --> 0.018961).  Saving model ...\n",
      "Epoch 15/25,\n",
      "Train Loss: 0.053 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.052 Test reconstruction loss: 0.019 Test covariance loss: 3.262\n",
      "Epoch: 16/25, Step 7240, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.481\n",
      "Epoch: 16/25, Step 7280, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.444\n",
      "Epoch: 16/25, Step 7320, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.383\n",
      "Epoch: 16/25, Step 7360, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.498\n",
      "Epoch: 16/25, Step 7400, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.311\n",
      "Epoch: 16/25, Step 7440, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.359\n",
      "Epoch: 16/25, Step 7480, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.458\n",
      "Epoch: 16/25, Step 7520, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.313\n",
      "Epoch: 16/25, Step 7560, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.286\n",
      "Epoch: 16/25, Step 7600, Train loss: 0.052 Train reconstruction loss: 0.020 Train covariance loss: 3.267\n",
      "Epoch: 16/25, Step 7640, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.340\n",
      "Epoch: 16/25, Step 7680, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.290\n",
      "Test reconstruction loss decreased (inf --> 0.018869).  Saving model ...\n",
      "Epoch 16/25,\n",
      "Train Loss: 0.053 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.052 Test reconstruction loss: 0.019 Test covariance loss: 3.321\n",
      "Epoch: 17/25, Step 7720, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.363\n",
      "Epoch: 17/25, Step 7760, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.229\n",
      "Epoch: 17/25, Step 7800, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.445\n",
      "Epoch: 17/25, Step 7840, Train loss: 0.055 Train reconstruction loss: 0.019 Train covariance loss: 3.526\n",
      "Epoch: 17/25, Step 7880, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.339\n",
      "Epoch: 17/25, Step 7920, Train loss: 0.055 Train reconstruction loss: 0.019 Train covariance loss: 3.532\n",
      "Epoch: 17/25, Step 7960, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.415\n",
      "Epoch: 17/25, Step 8000, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.378\n",
      "Epoch: 17/25, Step 8040, Train loss: 0.051 Train reconstruction loss: 0.019 Train covariance loss: 3.182\n",
      "Epoch: 17/25, Step 8080, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.363\n",
      "Epoch: 17/25, Step 8120, Train loss: 0.055 Train reconstruction loss: 0.019 Train covariance loss: 3.505\n",
      "Epoch: 17/25, Step 8160, Train loss: 0.051 Train reconstruction loss: 0.019 Train covariance loss: 3.191\n",
      "Test reconstruction loss decreased (inf --> 0.018927).  Saving model ...\n",
      "Epoch 17/25,\n",
      "Train Loss: 0.053 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.050 Test reconstruction loss: 0.019 Test covariance loss: 3.081\n",
      "Epoch: 18/25, Step 8200, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.354\n",
      "Epoch: 18/25, Step 8240, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.358\n",
      "Epoch: 18/25, Step 8280, Train loss: 0.055 Train reconstruction loss: 0.020 Train covariance loss: 3.519\n",
      "Epoch: 18/25, Step 8320, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.219\n",
      "Epoch: 18/25, Step 8360, Train loss: 0.052 Train reconstruction loss: 0.020 Train covariance loss: 3.292\n",
      "Epoch: 18/25, Step 8400, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.425\n",
      "Epoch: 18/25, Step 8440, Train loss: 0.051 Train reconstruction loss: 0.019 Train covariance loss: 3.217\n",
      "Epoch: 18/25, Step 8480, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.317\n",
      "Epoch: 18/25, Step 8520, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.543\n",
      "Epoch: 18/25, Step 8560, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.444\n",
      "Epoch: 18/25, Step 8600, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.353\n",
      "Epoch: 18/25, Step 8640, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.404\n",
      "Test reconstruction loss decreased (inf --> 0.018833).  Saving model ...\n",
      "Epoch 18/25,\n",
      "Train Loss: 0.053 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.052 Test reconstruction loss: 0.019 Test covariance loss: 3.267\n",
      "Epoch: 19/25, Step 8680, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.308\n",
      "Epoch: 19/25, Step 8720, Train loss: 0.051 Train reconstruction loss: 0.019 Train covariance loss: 3.209\n",
      "Epoch: 19/25, Step 8760, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.407\n",
      "Epoch: 19/25, Step 8800, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.364\n",
      "Epoch: 19/25, Step 8840, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.490\n",
      "Epoch: 19/25, Step 8880, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.330\n",
      "Epoch: 19/25, Step 8920, Train loss: 0.051 Train reconstruction loss: 0.019 Train covariance loss: 3.154\n",
      "Epoch: 19/25, Step 8960, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.386\n",
      "Epoch: 19/25, Step 9000, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.395\n",
      "Epoch: 19/25, Step 9040, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.475\n",
      "Epoch: 19/25, Step 9080, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.456\n",
      "Epoch: 19/25, Step 9120, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.387\n",
      "Test reconstruction loss decreased (inf --> 0.018856).  Saving model ...\n",
      "Epoch 19/25,\n",
      "Train Loss: 0.053 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.050 Test reconstruction loss: 0.019 Test covariance loss: 3.126\n",
      "Epoch: 20/25, Step 9160, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.382\n",
      "Epoch: 20/25, Step 9200, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.434\n",
      "Epoch: 20/25, Step 9240, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.266\n",
      "Epoch: 20/25, Step 9280, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.324\n",
      "Epoch: 20/25, Step 9320, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.349\n",
      "Epoch: 20/25, Step 9360, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.363\n",
      "Epoch: 20/25, Step 9400, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.428\n",
      "Epoch: 20/25, Step 9440, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.333\n",
      "Epoch: 20/25, Step 9480, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.269\n",
      "Epoch: 20/25, Step 9520, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.440\n",
      "Epoch: 20/25, Step 9560, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.428\n",
      "Epoch: 20/25, Step 9600, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.405\n",
      "Test reconstruction loss decreased (inf --> 0.018837).  Saving model ...\n",
      "Epoch 20/25,\n",
      "Train Loss: 0.053 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.051 Test reconstruction loss: 0.019 Test covariance loss: 3.180\n",
      "Epoch: 21/25, Step 9640, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.491\n",
      "Epoch: 21/25, Step 9680, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.372\n",
      "Epoch: 21/25, Step 9720, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.430\n",
      "Epoch: 21/25, Step 9760, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.256\n",
      "Epoch: 21/25, Step 9800, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.526\n",
      "Epoch: 21/25, Step 9840, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.289\n",
      "Epoch: 21/25, Step 9880, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.241\n",
      "Epoch: 21/25, Step 9920, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.460\n",
      "Epoch: 21/25, Step 9960, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.346\n",
      "Epoch: 21/25, Step 10000, Train loss: 0.052 Train reconstruction loss: 0.020 Train covariance loss: 3.223\n",
      "Epoch: 21/25, Step 10040, Train loss: 0.055 Train reconstruction loss: 0.019 Train covariance loss: 3.546\n",
      "Epoch: 21/25, Step 10080, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.364\n",
      "Test reconstruction loss decreased (inf --> 0.018811).  Saving model ...\n",
      "Epoch 21/25,\n",
      "Train Loss: 0.053 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.052 Test reconstruction loss: 0.019 Test covariance loss: 3.305\n",
      "Epoch: 22/25, Step 10120, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.466\n",
      "Epoch: 22/25, Step 10160, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.302\n",
      "Epoch: 22/25, Step 10200, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.268\n",
      "Epoch: 22/25, Step 10240, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.300\n",
      "Epoch: 22/25, Step 10280, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.378\n",
      "Epoch: 22/25, Step 10320, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.427\n",
      "Epoch: 22/25, Step 10360, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.371\n",
      "Epoch: 22/25, Step 10400, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.465\n",
      "Epoch: 22/25, Step 10440, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.422\n",
      "Epoch: 22/25, Step 10480, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.328\n",
      "Epoch: 22/25, Step 10520, Train loss: 0.055 Train reconstruction loss: 0.019 Train covariance loss: 3.557\n",
      "Epoch: 22/25, Step 10560, Train loss: 0.051 Train reconstruction loss: 0.019 Train covariance loss: 3.254\n",
      "Test reconstruction loss decreased (inf --> 0.018869).  Saving model ...\n",
      "Epoch 22/25,\n",
      "Train Loss: 0.053 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.049 Test reconstruction loss: 0.019 Test covariance loss: 3.000\n",
      "Epoch: 23/25, Step 10600, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.336\n",
      "Epoch: 23/25, Step 10640, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.466\n",
      "Epoch: 23/25, Step 10680, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.474\n",
      "Epoch: 23/25, Step 10720, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.274\n",
      "Epoch: 23/25, Step 10760, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.407\n",
      "Epoch: 23/25, Step 10800, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.318\n",
      "Epoch: 23/25, Step 10840, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.292\n",
      "Epoch: 23/25, Step 10880, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.445\n",
      "Epoch: 23/25, Step 10920, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.418\n",
      "Epoch: 23/25, Step 10960, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.293\n",
      "Epoch: 23/25, Step 11000, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.414\n",
      "Epoch: 23/25, Step 11040, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.457\n",
      "Test reconstruction loss decreased (inf --> 0.018889).  Saving model ...\n",
      "Epoch 23/25,\n",
      "Train Loss: 0.053 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.049 Test reconstruction loss: 0.019 Test covariance loss: 3.056\n",
      "Epoch: 24/25, Step 11080, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.529\n",
      "Epoch: 24/25, Step 11120, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.247\n",
      "Epoch: 24/25, Step 11160, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.408\n",
      "Epoch: 24/25, Step 11200, Train loss: 0.054 Train reconstruction loss: 0.020 Train covariance loss: 3.407\n",
      "Epoch: 24/25, Step 11240, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.332\n",
      "Epoch: 24/25, Step 11280, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.350\n",
      "Epoch: 24/25, Step 11320, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.495\n",
      "Epoch: 24/25, Step 11360, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.350\n",
      "Epoch: 24/25, Step 11400, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.260\n",
      "Epoch: 24/25, Step 11440, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.286\n",
      "Epoch: 24/25, Step 11480, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.332\n",
      "Epoch: 24/25, Step 11520, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.437\n",
      "Test reconstruction loss decreased (inf --> 0.018774).  Saving model ...\n",
      "Epoch 24/25,\n",
      "Train Loss: 0.053 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.051 Test reconstruction loss: 0.019 Test covariance loss: 3.185\n",
      "Epoch: 25/25, Step 11560, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.304\n",
      "Epoch: 25/25, Step 11600, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.440\n",
      "Epoch: 25/25, Step 11640, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.406\n",
      "Epoch: 25/25, Step 11680, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.424\n",
      "Epoch: 25/25, Step 11720, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.346\n",
      "Epoch: 25/25, Step 11760, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.289\n",
      "Epoch: 25/25, Step 11800, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.438\n",
      "Epoch: 25/25, Step 11840, Train loss: 0.054 Train reconstruction loss: 0.019 Train covariance loss: 3.442\n",
      "Epoch: 25/25, Step 11880, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.408\n",
      "Epoch: 25/25, Step 11920, Train loss: 0.053 Train reconstruction loss: 0.019 Train covariance loss: 3.375\n",
      "Epoch: 25/25, Step 11960, Train loss: 0.053 Train reconstruction loss: 0.020 Train covariance loss: 3.358\n",
      "Epoch: 25/25, Step 12000, Train loss: 0.052 Train reconstruction loss: 0.019 Train covariance loss: 3.341\n",
      "Test reconstruction loss decreased (inf --> 0.018803).  Saving model ...\n",
      "Epoch 25/25,\n",
      "Train Loss: 0.053 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.049 Test reconstruction loss: 0.019 Test covariance loss: 3.066\n",
      "Training with hidden dim: 4\n",
      "Epoch: 1/25, Step 40, Train loss: 0.089 Train reconstruction loss: 0.039 Train covariance loss: 5.016\n",
      "Epoch: 1/25, Step 80, Train loss: 0.075 Train reconstruction loss: 0.022 Train covariance loss: 5.331\n",
      "Epoch: 1/25, Step 120, Train loss: 0.072 Train reconstruction loss: 0.021 Train covariance loss: 5.098\n",
      "Epoch: 1/25, Step 160, Train loss: 0.070 Train reconstruction loss: 0.021 Train covariance loss: 4.881\n",
      "Epoch: 1/25, Step 200, Train loss: 0.072 Train reconstruction loss: 0.021 Train covariance loss: 5.129\n",
      "Epoch: 1/25, Step 240, Train loss: 0.069 Train reconstruction loss: 0.020 Train covariance loss: 4.873\n",
      "Epoch: 1/25, Step 280, Train loss: 0.069 Train reconstruction loss: 0.020 Train covariance loss: 4.967\n",
      "Epoch: 1/25, Step 320, Train loss: 0.069 Train reconstruction loss: 0.020 Train covariance loss: 4.935\n",
      "Epoch: 1/25, Step 360, Train loss: 0.068 Train reconstruction loss: 0.020 Train covariance loss: 4.824\n",
      "Epoch: 1/25, Step 400, Train loss: 0.072 Train reconstruction loss: 0.019 Train covariance loss: 5.285\n",
      "Epoch: 1/25, Step 440, Train loss: 0.068 Train reconstruction loss: 0.020 Train covariance loss: 4.775\n",
      "Epoch: 1/25, Step 480, Train loss: 0.071 Train reconstruction loss: 0.020 Train covariance loss: 5.147\n",
      "Test reconstruction loss decreased (inf --> 0.019204).  Saving model ...\n",
      "Epoch 1/25,\n",
      "Train Loss: 0.072 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.071 Test reconstruction loss: 0.019 Test covariance loss: 5.168\n",
      "Epoch: 2/25, Step 520, Train loss: 0.072 Train reconstruction loss: 0.020 Train covariance loss: 5.211\n",
      "Epoch: 2/25, Step 560, Train loss: 0.071 Train reconstruction loss: 0.019 Train covariance loss: 5.160\n",
      "Epoch: 2/25, Step 600, Train loss: 0.072 Train reconstruction loss: 0.020 Train covariance loss: 5.199\n",
      "Epoch: 2/25, Step 640, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.066\n",
      "Epoch: 2/25, Step 680, Train loss: 0.066 Train reconstruction loss: 0.019 Train covariance loss: 4.686\n",
      "Epoch: 2/25, Step 720, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.052\n",
      "Epoch: 2/25, Step 760, Train loss: 0.070 Train reconstruction loss: 0.020 Train covariance loss: 4.997\n",
      "Epoch: 2/25, Step 800, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.083\n",
      "Epoch: 2/25, Step 840, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.013\n",
      "Epoch: 2/25, Step 880, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.901\n",
      "Epoch: 2/25, Step 920, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.025\n",
      "Epoch: 2/25, Step 960, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.902\n",
      "Test reconstruction loss decreased (inf --> 0.018865).  Saving model ...\n",
      "Epoch 2/25,\n",
      "Train Loss: 0.070 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.066 Test reconstruction loss: 0.019 Test covariance loss: 4.673\n",
      "Epoch: 3/25, Step 1000, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.083\n",
      "Epoch: 3/25, Step 1040, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.101\n",
      "Epoch: 3/25, Step 1080, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.811\n",
      "Epoch: 3/25, Step 1120, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.877\n",
      "Epoch: 3/25, Step 1160, Train loss: 0.072 Train reconstruction loss: 0.019 Train covariance loss: 5.310\n",
      "Epoch: 3/25, Step 1200, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.880\n",
      "Epoch: 3/25, Step 1240, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 4.970\n",
      "Epoch: 3/25, Step 1280, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.080\n",
      "Epoch: 3/25, Step 1320, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 4.952\n",
      "Epoch: 3/25, Step 1360, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.837\n",
      "Epoch: 3/25, Step 1400, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.848\n",
      "Epoch: 3/25, Step 1440, Train loss: 0.072 Train reconstruction loss: 0.019 Train covariance loss: 5.258\n",
      "Test reconstruction loss decreased (inf --> 0.018721).  Saving model ...\n",
      "Epoch 3/25,\n",
      "Train Loss: 0.069 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.069 Test reconstruction loss: 0.019 Test covariance loss: 5.018\n",
      "Epoch: 4/25, Step 1480, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.840\n",
      "Epoch: 4/25, Step 1520, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.000\n",
      "Epoch: 4/25, Step 1560, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.039\n",
      "Epoch: 4/25, Step 1600, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.041\n",
      "Epoch: 4/25, Step 1640, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.017\n",
      "Epoch: 4/25, Step 1680, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.116\n",
      "Epoch: 4/25, Step 1720, Train loss: 0.074 Train reconstruction loss: 0.019 Train covariance loss: 5.477\n",
      "Epoch: 4/25, Step 1760, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 4.991\n",
      "Epoch: 4/25, Step 1800, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.876\n",
      "Epoch: 4/25, Step 1840, Train loss: 0.071 Train reconstruction loss: 0.020 Train covariance loss: 5.114\n",
      "Epoch: 4/25, Step 1880, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 4.940\n",
      "Epoch: 4/25, Step 1920, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.034\n",
      "Test reconstruction loss decreased (inf --> 0.018730).  Saving model ...\n",
      "Epoch 4/25,\n",
      "Train Loss: 0.070 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.062 Test reconstruction loss: 0.019 Test covariance loss: 4.364\n",
      "Epoch: 5/25, Step 1960, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.837\n",
      "Epoch: 5/25, Step 2000, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.090\n",
      "Epoch: 5/25, Step 2040, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.070\n",
      "Epoch: 5/25, Step 2080, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.071\n",
      "Epoch: 5/25, Step 2120, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 4.991\n",
      "Epoch: 5/25, Step 2160, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.082\n",
      "Epoch: 5/25, Step 2200, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.053\n",
      "Epoch: 5/25, Step 2240, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 4.954\n",
      "Epoch: 5/25, Step 2280, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.109\n",
      "Epoch: 5/25, Step 2320, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.032\n",
      "Epoch: 5/25, Step 2360, Train loss: 0.066 Train reconstruction loss: 0.019 Train covariance loss: 4.696\n",
      "Epoch: 5/25, Step 2400, Train loss: 0.071 Train reconstruction loss: 0.019 Train covariance loss: 5.137\n",
      "Test reconstruction loss decreased (inf --> 0.018702).  Saving model ...\n",
      "Epoch 5/25,\n",
      "Train Loss: 0.069 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.071 Test reconstruction loss: 0.019 Test covariance loss: 5.277\n",
      "Epoch: 6/25, Step 2440, Train loss: 0.066 Train reconstruction loss: 0.019 Train covariance loss: 4.639\n",
      "Epoch: 6/25, Step 2480, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.108\n",
      "Epoch: 6/25, Step 2520, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.073\n",
      "Epoch: 6/25, Step 2560, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.035\n",
      "Epoch: 6/25, Step 2600, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.887\n",
      "Epoch: 6/25, Step 2640, Train loss: 0.071 Train reconstruction loss: 0.019 Train covariance loss: 5.164\n",
      "Epoch: 6/25, Step 2680, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.160\n",
      "Epoch: 6/25, Step 2720, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 4.985\n",
      "Epoch: 6/25, Step 2760, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.046\n",
      "Epoch: 6/25, Step 2800, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.111\n",
      "Epoch: 6/25, Step 2840, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.001\n",
      "Epoch: 6/25, Step 2880, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.053\n",
      "Test reconstruction loss decreased (inf --> 0.018690).  Saving model ...\n",
      "Epoch 6/25,\n",
      "Train Loss: 0.069 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.064 Test reconstruction loss: 0.019 Test covariance loss: 4.518\n",
      "Epoch: 7/25, Step 2920, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.057\n",
      "Epoch: 7/25, Step 2960, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.018\n",
      "Epoch: 7/25, Step 3000, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.792\n",
      "Epoch: 7/25, Step 3040, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.055\n",
      "Epoch: 7/25, Step 3080, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.845\n",
      "Epoch: 7/25, Step 3120, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.916\n",
      "Epoch: 7/25, Step 3160, Train loss: 0.071 Train reconstruction loss: 0.019 Train covariance loss: 5.187\n",
      "Epoch: 7/25, Step 3200, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.875\n",
      "Epoch: 7/25, Step 3240, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 4.922\n",
      "Epoch: 7/25, Step 3280, Train loss: 0.075 Train reconstruction loss: 0.019 Train covariance loss: 5.592\n",
      "Epoch: 7/25, Step 3320, Train loss: 0.066 Train reconstruction loss: 0.019 Train covariance loss: 4.776\n",
      "Epoch: 7/25, Step 3360, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.089\n",
      "Test reconstruction loss decreased (inf --> 0.018584).  Saving model ...\n",
      "Epoch 7/25,\n",
      "Train Loss: 0.069 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.066 Test reconstruction loss: 0.019 Test covariance loss: 4.782\n",
      "Epoch: 8/25, Step 3400, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.809\n",
      "Epoch: 8/25, Step 3440, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.836\n",
      "Epoch: 8/25, Step 3480, Train loss: 0.071 Train reconstruction loss: 0.019 Train covariance loss: 5.162\n",
      "Epoch: 8/25, Step 3520, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.890\n",
      "Epoch: 8/25, Step 3560, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.943\n",
      "Epoch: 8/25, Step 3600, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.889\n",
      "Epoch: 8/25, Step 3640, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.163\n",
      "Epoch: 8/25, Step 3680, Train loss: 0.071 Train reconstruction loss: 0.019 Train covariance loss: 5.174\n",
      "Epoch: 8/25, Step 3720, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.012\n",
      "Epoch: 8/25, Step 3760, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.855\n",
      "Epoch: 8/25, Step 3800, Train loss: 0.071 Train reconstruction loss: 0.019 Train covariance loss: 5.215\n",
      "Epoch: 8/25, Step 3840, Train loss: 0.072 Train reconstruction loss: 0.019 Train covariance loss: 5.283\n",
      "Test reconstruction loss decreased (inf --> 0.018597).  Saving model ...\n",
      "Epoch 8/25,\n",
      "Train Loss: 0.069 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.065 Test reconstruction loss: 0.019 Test covariance loss: 4.634\n",
      "Epoch: 9/25, Step 3880, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.078\n",
      "Epoch: 9/25, Step 3920, Train loss: 0.071 Train reconstruction loss: 0.019 Train covariance loss: 5.227\n",
      "Epoch: 9/25, Step 3960, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.012\n",
      "Epoch: 9/25, Step 4000, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.796\n",
      "Epoch: 9/25, Step 4040, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.047\n",
      "Epoch: 9/25, Step 4080, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.802\n",
      "Epoch: 9/25, Step 4120, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.933\n",
      "Epoch: 9/25, Step 4160, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.940\n",
      "Epoch: 9/25, Step 4200, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.912\n",
      "Epoch: 9/25, Step 4240, Train loss: 0.071 Train reconstruction loss: 0.019 Train covariance loss: 5.145\n",
      "Epoch: 9/25, Step 4280, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.913\n",
      "Epoch: 9/25, Step 4320, Train loss: 0.071 Train reconstruction loss: 0.018 Train covariance loss: 5.271\n",
      "Test reconstruction loss decreased (inf --> 0.018589).  Saving model ...\n",
      "Epoch 9/25,\n",
      "Train Loss: 0.069 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.064 Test reconstruction loss: 0.019 Test covariance loss: 4.552\n",
      "Epoch: 10/25, Step 4360, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.774\n",
      "Epoch: 10/25, Step 4400, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.884\n",
      "Epoch: 10/25, Step 4440, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.962\n",
      "Epoch: 10/25, Step 4480, Train loss: 0.072 Train reconstruction loss: 0.018 Train covariance loss: 5.379\n",
      "Epoch: 10/25, Step 4520, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.823\n",
      "Epoch: 10/25, Step 4560, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.947\n",
      "Epoch: 10/25, Step 4600, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.105\n",
      "Epoch: 10/25, Step 4640, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.894\n",
      "Epoch: 10/25, Step 4680, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 4.972\n",
      "Epoch: 10/25, Step 4720, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.936\n",
      "Epoch: 10/25, Step 4760, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.923\n",
      "Epoch: 10/25, Step 4800, Train loss: 0.072 Train reconstruction loss: 0.019 Train covariance loss: 5.301\n",
      "Test reconstruction loss decreased (inf --> 0.018514).  Saving model ...\n",
      "Epoch 10/25,\n",
      "Train Loss: 0.069 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.062 Test reconstruction loss: 0.019 Test covariance loss: 4.304\n",
      "Epoch: 11/25, Step 4840, Train loss: 0.071 Train reconstruction loss: 0.019 Train covariance loss: 5.242\n",
      "Epoch: 11/25, Step 4880, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.857\n",
      "Epoch: 11/25, Step 4920, Train loss: 0.071 Train reconstruction loss: 0.019 Train covariance loss: 5.257\n",
      "Epoch: 11/25, Step 4960, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 4.959\n",
      "Epoch: 11/25, Step 5000, Train loss: 0.074 Train reconstruction loss: 0.019 Train covariance loss: 5.489\n",
      "Epoch: 11/25, Step 5040, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.010\n",
      "Epoch: 11/25, Step 5080, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.969\n",
      "Epoch: 11/25, Step 5120, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 4.969\n",
      "Epoch: 11/25, Step 5160, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.884\n",
      "Epoch: 11/25, Step 5200, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.877\n",
      "Epoch: 11/25, Step 5240, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.957\n",
      "Epoch: 11/25, Step 5280, Train loss: 0.066 Train reconstruction loss: 0.019 Train covariance loss: 4.677\n",
      "Test reconstruction loss decreased (inf --> 0.018574).  Saving model ...\n",
      "Epoch 11/25,\n",
      "Train Loss: 0.069 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.072 Test reconstruction loss: 0.019 Test covariance loss: 5.301\n",
      "Epoch: 12/25, Step 5320, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.940\n",
      "Epoch: 12/25, Step 5360, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.944\n",
      "Epoch: 12/25, Step 5400, Train loss: 0.072 Train reconstruction loss: 0.019 Train covariance loss: 5.306\n",
      "Epoch: 12/25, Step 5440, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 4.999\n",
      "Epoch: 12/25, Step 5480, Train loss: 0.072 Train reconstruction loss: 0.019 Train covariance loss: 5.326\n",
      "Epoch: 12/25, Step 5520, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.918\n",
      "Epoch: 12/25, Step 5560, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.911\n",
      "Epoch: 12/25, Step 5600, Train loss: 0.072 Train reconstruction loss: 0.019 Train covariance loss: 5.341\n",
      "Epoch: 12/25, Step 5640, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.835\n",
      "Epoch: 12/25, Step 5680, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.061\n",
      "Epoch: 12/25, Step 5720, Train loss: 0.066 Train reconstruction loss: 0.019 Train covariance loss: 4.787\n",
      "Epoch: 12/25, Step 5760, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.757\n",
      "Test reconstruction loss decreased (inf --> 0.018496).  Saving model ...\n",
      "Epoch 12/25,\n",
      "Train Loss: 0.069 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.064 Test reconstruction loss: 0.018 Test covariance loss: 4.510\n",
      "Epoch: 13/25, Step 5800, Train loss: 0.071 Train reconstruction loss: 0.019 Train covariance loss: 5.225\n",
      "Epoch: 13/25, Step 5840, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.138\n",
      "Epoch: 13/25, Step 5880, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.007\n",
      "Epoch: 13/25, Step 5920, Train loss: 0.069 Train reconstruction loss: 0.020 Train covariance loss: 4.919\n",
      "Epoch: 13/25, Step 5960, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.874\n",
      "Epoch: 13/25, Step 6000, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.013\n",
      "Epoch: 13/25, Step 6040, Train loss: 0.071 Train reconstruction loss: 0.019 Train covariance loss: 5.212\n",
      "Epoch: 13/25, Step 6080, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.947\n",
      "Epoch: 13/25, Step 6120, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.789\n",
      "Epoch: 13/25, Step 6160, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.760\n",
      "Epoch: 13/25, Step 6200, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 4.979\n",
      "Epoch: 13/25, Step 6240, Train loss: 0.072 Train reconstruction loss: 0.019 Train covariance loss: 5.258\n",
      "Test reconstruction loss decreased (inf --> 0.018578).  Saving model ...\n",
      "Epoch 13/25,\n",
      "Train Loss: 0.069 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.067 Test reconstruction loss: 0.019 Test covariance loss: 4.805\n",
      "Epoch: 14/25, Step 6280, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.961\n",
      "Epoch: 14/25, Step 6320, Train loss: 0.068 Train reconstruction loss: 0.018 Train covariance loss: 4.912\n",
      "Epoch: 14/25, Step 6360, Train loss: 0.073 Train reconstruction loss: 0.019 Train covariance loss: 5.370\n",
      "Epoch: 14/25, Step 6400, Train loss: 0.066 Train reconstruction loss: 0.019 Train covariance loss: 4.776\n",
      "Epoch: 14/25, Step 6440, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.941\n",
      "Epoch: 14/25, Step 6480, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.087\n",
      "Epoch: 14/25, Step 6520, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.957\n",
      "Epoch: 14/25, Step 6560, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.924\n",
      "Epoch: 14/25, Step 6600, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.016\n",
      "Epoch: 14/25, Step 6640, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.023\n",
      "Epoch: 14/25, Step 6680, Train loss: 0.072 Train reconstruction loss: 0.019 Train covariance loss: 5.296\n",
      "Epoch: 14/25, Step 6720, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.866\n",
      "Test reconstruction loss decreased (inf --> 0.018608).  Saving model ...\n",
      "Epoch 14/25,\n",
      "Train Loss: 0.069 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.068 Test reconstruction loss: 0.019 Test covariance loss: 4.942\n",
      "Epoch: 15/25, Step 6760, Train loss: 0.071 Train reconstruction loss: 0.019 Train covariance loss: 5.243\n",
      "Epoch: 15/25, Step 6800, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.867\n",
      "Epoch: 15/25, Step 6840, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.128\n",
      "Epoch: 15/25, Step 6880, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.034\n",
      "Epoch: 15/25, Step 6920, Train loss: 0.071 Train reconstruction loss: 0.019 Train covariance loss: 5.210\n",
      "Epoch: 15/25, Step 6960, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 4.970\n",
      "Epoch: 15/25, Step 7000, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.098\n",
      "Epoch: 15/25, Step 7040, Train loss: 0.071 Train reconstruction loss: 0.019 Train covariance loss: 5.195\n",
      "Epoch: 15/25, Step 7080, Train loss: 0.066 Train reconstruction loss: 0.019 Train covariance loss: 4.687\n",
      "Epoch: 15/25, Step 7120, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.167\n",
      "Epoch: 15/25, Step 7160, Train loss: 0.066 Train reconstruction loss: 0.019 Train covariance loss: 4.733\n",
      "Epoch: 15/25, Step 7200, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.065\n",
      "Test reconstruction loss decreased (inf --> 0.018523).  Saving model ...\n",
      "Epoch 15/25,\n",
      "Train Loss: 0.069 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.063 Test reconstruction loss: 0.019 Test covariance loss: 4.464\n",
      "Epoch: 16/25, Step 7240, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.888\n",
      "Epoch: 16/25, Step 7280, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.088\n",
      "Epoch: 16/25, Step 7320, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.900\n",
      "Epoch: 16/25, Step 7360, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.046\n",
      "Epoch: 16/25, Step 7400, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.094\n",
      "Epoch: 16/25, Step 7440, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.143\n",
      "Epoch: 16/25, Step 7480, Train loss: 0.072 Train reconstruction loss: 0.019 Train covariance loss: 5.283\n",
      "Epoch: 16/25, Step 7520, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.867\n",
      "Epoch: 16/25, Step 7560, Train loss: 0.066 Train reconstruction loss: 0.019 Train covariance loss: 4.770\n",
      "Epoch: 16/25, Step 7600, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 4.996\n",
      "Epoch: 16/25, Step 7640, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.148\n",
      "Epoch: 16/25, Step 7680, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.111\n",
      "Test reconstruction loss decreased (inf --> 0.018467).  Saving model ...\n",
      "Epoch 16/25,\n",
      "Train Loss: 0.069 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.066 Test reconstruction loss: 0.018 Test covariance loss: 4.800\n",
      "Epoch: 17/25, Step 7720, Train loss: 0.065 Train reconstruction loss: 0.019 Train covariance loss: 4.612\n",
      "Epoch: 17/25, Step 7760, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.150\n",
      "Epoch: 17/25, Step 7800, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.041\n",
      "Epoch: 17/25, Step 7840, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.874\n",
      "Epoch: 17/25, Step 7880, Train loss: 0.071 Train reconstruction loss: 0.019 Train covariance loss: 5.216\n",
      "Epoch: 17/25, Step 7920, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.123\n",
      "Epoch: 17/25, Step 7960, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.958\n",
      "Epoch: 17/25, Step 8000, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.909\n",
      "Epoch: 17/25, Step 8040, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.075\n",
      "Epoch: 17/25, Step 8080, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 4.985\n",
      "Epoch: 17/25, Step 8120, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.034\n",
      "Epoch: 17/25, Step 8160, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.064\n",
      "Test reconstruction loss decreased (inf --> 0.018457).  Saving model ...\n",
      "Epoch 17/25,\n",
      "Train Loss: 0.069 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.066 Test reconstruction loss: 0.018 Test covariance loss: 4.731\n",
      "Epoch: 18/25, Step 8200, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.042\n",
      "Epoch: 18/25, Step 8240, Train loss: 0.071 Train reconstruction loss: 0.019 Train covariance loss: 5.175\n",
      "Epoch: 18/25, Step 8280, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.947\n",
      "Epoch: 18/25, Step 8320, Train loss: 0.068 Train reconstruction loss: 0.018 Train covariance loss: 4.994\n",
      "Epoch: 18/25, Step 8360, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.912\n",
      "Epoch: 18/25, Step 8400, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 4.967\n",
      "Epoch: 18/25, Step 8440, Train loss: 0.066 Train reconstruction loss: 0.019 Train covariance loss: 4.734\n",
      "Epoch: 18/25, Step 8480, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.165\n",
      "Epoch: 18/25, Step 8520, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.976\n",
      "Epoch: 18/25, Step 8560, Train loss: 0.071 Train reconstruction loss: 0.019 Train covariance loss: 5.202\n",
      "Epoch: 18/25, Step 8600, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.942\n",
      "Epoch: 18/25, Step 8640, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.861\n",
      "Test reconstruction loss decreased (inf --> 0.018440).  Saving model ...\n",
      "Epoch 18/25,\n",
      "Train Loss: 0.069 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.063 Test reconstruction loss: 0.018 Test covariance loss: 4.408\n",
      "Epoch: 19/25, Step 8680, Train loss: 0.066 Train reconstruction loss: 0.019 Train covariance loss: 4.717\n",
      "Epoch: 19/25, Step 8720, Train loss: 0.069 Train reconstruction loss: 0.018 Train covariance loss: 5.101\n",
      "Epoch: 19/25, Step 8760, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.042\n",
      "Epoch: 19/25, Step 8800, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.110\n",
      "Epoch: 19/25, Step 8840, Train loss: 0.066 Train reconstruction loss: 0.019 Train covariance loss: 4.737\n",
      "Epoch: 19/25, Step 8880, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.855\n",
      "Epoch: 19/25, Step 8920, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.066\n",
      "Epoch: 19/25, Step 8960, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.113\n",
      "Epoch: 19/25, Step 9000, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.054\n",
      "Epoch: 19/25, Step 9040, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.145\n",
      "Epoch: 19/25, Step 9080, Train loss: 0.073 Train reconstruction loss: 0.019 Train covariance loss: 5.424\n",
      "Epoch: 19/25, Step 9120, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.944\n",
      "Test reconstruction loss decreased (inf --> 0.018450).  Saving model ...\n",
      "Epoch 19/25,\n",
      "Train Loss: 0.069 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.064 Test reconstruction loss: 0.018 Test covariance loss: 4.582\n",
      "Epoch: 20/25, Step 9160, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.076\n",
      "Epoch: 20/25, Step 9200, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.110\n",
      "Epoch: 20/25, Step 9240, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.932\n",
      "Epoch: 20/25, Step 9280, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.132\n",
      "Epoch: 20/25, Step 9320, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.142\n",
      "Epoch: 20/25, Step 9360, Train loss: 0.066 Train reconstruction loss: 0.019 Train covariance loss: 4.720\n",
      "Epoch: 20/25, Step 9400, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.863\n",
      "Epoch: 20/25, Step 9440, Train loss: 0.072 Train reconstruction loss: 0.019 Train covariance loss: 5.288\n",
      "Epoch: 20/25, Step 9480, Train loss: 0.066 Train reconstruction loss: 0.018 Train covariance loss: 4.798\n",
      "Epoch: 20/25, Step 9520, Train loss: 0.068 Train reconstruction loss: 0.018 Train covariance loss: 4.921\n",
      "Epoch: 20/25, Step 9560, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.068\n",
      "Epoch: 20/25, Step 9600, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.125\n",
      "Test reconstruction loss decreased (inf --> 0.018391).  Saving model ...\n",
      "Epoch 20/25,\n",
      "Train Loss: 0.069 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.065 Test reconstruction loss: 0.018 Test covariance loss: 4.656\n",
      "Epoch: 21/25, Step 9640, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.047\n",
      "Epoch: 21/25, Step 9680, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 4.980\n",
      "Epoch: 21/25, Step 9720, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 4.978\n",
      "Epoch: 21/25, Step 9760, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.090\n",
      "Epoch: 21/25, Step 9800, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.950\n",
      "Epoch: 21/25, Step 9840, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.864\n",
      "Epoch: 21/25, Step 9880, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.945\n",
      "Epoch: 21/25, Step 9920, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.866\n",
      "Epoch: 21/25, Step 9960, Train loss: 0.071 Train reconstruction loss: 0.019 Train covariance loss: 5.208\n",
      "Epoch: 21/25, Step 10000, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.131\n",
      "Epoch: 21/25, Step 10040, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.887\n",
      "Epoch: 21/25, Step 10080, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.010\n",
      "Test reconstruction loss decreased (inf --> 0.018481).  Saving model ...\n",
      "Epoch 21/25,\n",
      "Train Loss: 0.069 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.066 Test reconstruction loss: 0.018 Test covariance loss: 4.720\n",
      "Epoch: 22/25, Step 10120, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.080\n",
      "Epoch: 22/25, Step 10160, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.061\n",
      "Epoch: 22/25, Step 10200, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.020\n",
      "Epoch: 22/25, Step 10240, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.968\n",
      "Epoch: 22/25, Step 10280, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 4.980\n",
      "Epoch: 22/25, Step 10320, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.088\n",
      "Epoch: 22/25, Step 10360, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.920\n",
      "Epoch: 22/25, Step 10400, Train loss: 0.069 Train reconstruction loss: 0.018 Train covariance loss: 5.012\n",
      "Epoch: 22/25, Step 10440, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.052\n",
      "Epoch: 22/25, Step 10480, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.893\n",
      "Epoch: 22/25, Step 10520, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.881\n",
      "Epoch: 22/25, Step 10560, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.045\n",
      "Test reconstruction loss decreased (inf --> 0.018437).  Saving model ...\n",
      "Epoch 22/25,\n",
      "Train Loss: 0.069 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.070 Test reconstruction loss: 0.018 Test covariance loss: 5.135\n",
      "Epoch: 23/25, Step 10600, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.925\n",
      "Epoch: 23/25, Step 10640, Train loss: 0.071 Train reconstruction loss: 0.018 Train covariance loss: 5.258\n",
      "Epoch: 23/25, Step 10680, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.028\n",
      "Epoch: 23/25, Step 10720, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.871\n",
      "Epoch: 23/25, Step 10760, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 4.968\n",
      "Epoch: 23/25, Step 10800, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.006\n",
      "Epoch: 23/25, Step 10840, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.895\n",
      "Epoch: 23/25, Step 10880, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.913\n",
      "Epoch: 23/25, Step 10920, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.029\n",
      "Epoch: 23/25, Step 10960, Train loss: 0.068 Train reconstruction loss: 0.018 Train covariance loss: 4.933\n",
      "Epoch: 23/25, Step 11000, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.101\n",
      "Epoch: 23/25, Step 11040, Train loss: 0.071 Train reconstruction loss: 0.018 Train covariance loss: 5.270\n",
      "Test reconstruction loss decreased (inf --> 0.018424).  Saving model ...\n",
      "Epoch 23/25,\n",
      "Train Loss: 0.069 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.065 Test reconstruction loss: 0.018 Test covariance loss: 4.624\n",
      "Epoch: 24/25, Step 11080, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.902\n",
      "Epoch: 24/25, Step 11120, Train loss: 0.066 Train reconstruction loss: 0.019 Train covariance loss: 4.711\n",
      "Epoch: 24/25, Step 11160, Train loss: 0.071 Train reconstruction loss: 0.018 Train covariance loss: 5.247\n",
      "Epoch: 24/25, Step 11200, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.982\n",
      "Epoch: 24/25, Step 11240, Train loss: 0.071 Train reconstruction loss: 0.019 Train covariance loss: 5.208\n",
      "Epoch: 24/25, Step 11280, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.970\n",
      "Epoch: 24/25, Step 11320, Train loss: 0.072 Train reconstruction loss: 0.018 Train covariance loss: 5.321\n",
      "Epoch: 24/25, Step 11360, Train loss: 0.071 Train reconstruction loss: 0.019 Train covariance loss: 5.185\n",
      "Epoch: 24/25, Step 11400, Train loss: 0.066 Train reconstruction loss: 0.019 Train covariance loss: 4.712\n",
      "Epoch: 24/25, Step 11440, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.791\n",
      "Epoch: 24/25, Step 11480, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.066\n",
      "Epoch: 24/25, Step 11520, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.082\n",
      "Test reconstruction loss decreased (inf --> 0.018430).  Saving model ...\n",
      "Epoch 24/25,\n",
      "Train Loss: 0.069 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.068 Test reconstruction loss: 0.018 Test covariance loss: 4.944\n",
      "Epoch: 25/25, Step 11560, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.780\n",
      "Epoch: 25/25, Step 11600, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.061\n",
      "Epoch: 25/25, Step 11640, Train loss: 0.068 Train reconstruction loss: 0.019 Train covariance loss: 4.877\n",
      "Epoch: 25/25, Step 11680, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.127\n",
      "Epoch: 25/25, Step 11720, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.125\n",
      "Epoch: 25/25, Step 11760, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.167\n",
      "Epoch: 25/25, Step 11800, Train loss: 0.069 Train reconstruction loss: 0.018 Train covariance loss: 5.049\n",
      "Epoch: 25/25, Step 11840, Train loss: 0.069 Train reconstruction loss: 0.019 Train covariance loss: 5.080\n",
      "Epoch: 25/25, Step 11880, Train loss: 0.070 Train reconstruction loss: 0.019 Train covariance loss: 5.076\n",
      "Epoch: 25/25, Step 11920, Train loss: 0.072 Train reconstruction loss: 0.019 Train covariance loss: 5.285\n",
      "Epoch: 25/25, Step 11960, Train loss: 0.067 Train reconstruction loss: 0.019 Train covariance loss: 4.859\n",
      "Epoch: 25/25, Step 12000, Train loss: 0.066 Train reconstruction loss: 0.019 Train covariance loss: 4.768\n",
      "Test reconstruction loss decreased (inf --> 0.018373).  Saving model ...\n",
      "Epoch 25/25,\n",
      "Train Loss: 0.069 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.062 Test reconstruction loss: 0.018 Test covariance loss: 4.371\n",
      "Training with hidden dim: 5\n",
      "Epoch: 1/25, Step 40, Train loss: 0.122 Train reconstruction loss: 0.029 Train covariance loss: 9.303\n",
      "Epoch: 1/25, Step 80, Train loss: 0.111 Train reconstruction loss: 0.020 Train covariance loss: 9.095\n",
      "Epoch: 1/25, Step 120, Train loss: 0.109 Train reconstruction loss: 0.020 Train covariance loss: 8.918\n",
      "Epoch: 1/25, Step 160, Train loss: 0.107 Train reconstruction loss: 0.020 Train covariance loss: 8.771\n",
      "Epoch: 1/25, Step 200, Train loss: 0.108 Train reconstruction loss: 0.020 Train covariance loss: 8.813\n",
      "Epoch: 1/25, Step 240, Train loss: 0.110 Train reconstruction loss: 0.020 Train covariance loss: 9.070\n",
      "Epoch: 1/25, Step 280, Train loss: 0.110 Train reconstruction loss: 0.020 Train covariance loss: 9.020\n",
      "Epoch: 1/25, Step 320, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.823\n",
      "Epoch: 1/25, Step 360, Train loss: 0.108 Train reconstruction loss: 0.020 Train covariance loss: 8.828\n",
      "Epoch: 1/25, Step 400, Train loss: 0.109 Train reconstruction loss: 0.020 Train covariance loss: 8.963\n",
      "Epoch: 1/25, Step 440, Train loss: 0.109 Train reconstruction loss: 0.020 Train covariance loss: 8.954\n",
      "Epoch: 1/25, Step 480, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.035\n",
      "Test reconstruction loss decreased (inf --> 0.018912).  Saving model ...\n",
      "Epoch 1/25,\n",
      "Train Loss: 0.110 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.120 Test reconstruction loss: 0.019 Test covariance loss: 10.142\n",
      "Epoch: 2/25, Step 520, Train loss: 0.108 Train reconstruction loss: 0.020 Train covariance loss: 8.857\n",
      "Epoch: 2/25, Step 560, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.941\n",
      "Epoch: 2/25, Step 600, Train loss: 0.109 Train reconstruction loss: 0.020 Train covariance loss: 8.990\n",
      "Epoch: 2/25, Step 640, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.820\n",
      "Epoch: 2/25, Step 680, Train loss: 0.106 Train reconstruction loss: 0.019 Train covariance loss: 8.682\n",
      "Epoch: 2/25, Step 720, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.120\n",
      "Epoch: 2/25, Step 760, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.018\n",
      "Epoch: 2/25, Step 800, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.014\n",
      "Epoch: 2/25, Step 840, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.110\n",
      "Epoch: 2/25, Step 880, Train loss: 0.110 Train reconstruction loss: 0.020 Train covariance loss: 9.005\n",
      "Epoch: 2/25, Step 920, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.010\n",
      "Epoch: 2/25, Step 960, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.907\n",
      "Test reconstruction loss decreased (inf --> 0.018735).  Saving model ...\n",
      "Epoch 2/25,\n",
      "Train Loss: 0.109 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.101 Test reconstruction loss: 0.019 Test covariance loss: 8.236\n",
      "Epoch: 3/25, Step 1000, Train loss: 0.111 Train reconstruction loss: 0.019 Train covariance loss: 9.207\n",
      "Epoch: 3/25, Step 1040, Train loss: 0.111 Train reconstruction loss: 0.019 Train covariance loss: 9.145\n",
      "Epoch: 3/25, Step 1080, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.035\n",
      "Epoch: 3/25, Step 1120, Train loss: 0.112 Train reconstruction loss: 0.019 Train covariance loss: 9.299\n",
      "Epoch: 3/25, Step 1160, Train loss: 0.104 Train reconstruction loss: 0.019 Train covariance loss: 8.487\n",
      "Epoch: 3/25, Step 1200, Train loss: 0.112 Train reconstruction loss: 0.019 Train covariance loss: 9.273\n",
      "Epoch: 3/25, Step 1240, Train loss: 0.113 Train reconstruction loss: 0.019 Train covariance loss: 9.392\n",
      "Epoch: 3/25, Step 1280, Train loss: 0.111 Train reconstruction loss: 0.019 Train covariance loss: 9.194\n",
      "Epoch: 3/25, Step 1320, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.911\n",
      "Epoch: 3/25, Step 1360, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.798\n",
      "Epoch: 3/25, Step 1400, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.967\n",
      "Epoch: 3/25, Step 1440, Train loss: 0.106 Train reconstruction loss: 0.019 Train covariance loss: 8.662\n",
      "Test reconstruction loss decreased (inf --> 0.018659).  Saving model ...\n",
      "Epoch 3/25,\n",
      "Train Loss: 0.109 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.105 Test reconstruction loss: 0.019 Test covariance loss: 8.586\n",
      "Epoch: 4/25, Step 1480, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.749\n",
      "Epoch: 4/25, Step 1520, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.948\n",
      "Epoch: 4/25, Step 1560, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.824\n",
      "Epoch: 4/25, Step 1600, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.852\n",
      "Epoch: 4/25, Step 1640, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.000\n",
      "Epoch: 4/25, Step 1680, Train loss: 0.111 Train reconstruction loss: 0.018 Train covariance loss: 9.278\n",
      "Epoch: 4/25, Step 1720, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.787\n",
      "Epoch: 4/25, Step 1760, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.946\n",
      "Epoch: 4/25, Step 1800, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.948\n",
      "Epoch: 4/25, Step 1840, Train loss: 0.112 Train reconstruction loss: 0.019 Train covariance loss: 9.293\n",
      "Epoch: 4/25, Step 1880, Train loss: 0.111 Train reconstruction loss: 0.019 Train covariance loss: 9.175\n",
      "Epoch: 4/25, Step 1920, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.926\n",
      "Test reconstruction loss decreased (inf --> 0.018636).  Saving model ...\n",
      "Epoch 4/25,\n",
      "Train Loss: 0.109 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.101 Test reconstruction loss: 0.019 Test covariance loss: 8.242\n",
      "Epoch: 5/25, Step 1960, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.076\n",
      "Epoch: 5/25, Step 2000, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.118\n",
      "Epoch: 5/25, Step 2040, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.086\n",
      "Epoch: 5/25, Step 2080, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 8.993\n",
      "Epoch: 5/25, Step 2120, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.075\n",
      "Epoch: 5/25, Step 2160, Train loss: 0.106 Train reconstruction loss: 0.019 Train covariance loss: 8.776\n",
      "Epoch: 5/25, Step 2200, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.027\n",
      "Epoch: 5/25, Step 2240, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.805\n",
      "Epoch: 5/25, Step 2280, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.100\n",
      "Epoch: 5/25, Step 2320, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.815\n",
      "Epoch: 5/25, Step 2360, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.868\n",
      "Epoch: 5/25, Step 2400, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.040\n",
      "Test reconstruction loss decreased (inf --> 0.018567).  Saving model ...\n",
      "Epoch 5/25,\n",
      "Train Loss: 0.109 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.110 Test reconstruction loss: 0.019 Test covariance loss: 9.153\n",
      "Epoch: 6/25, Step 2440, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.111\n",
      "Epoch: 6/25, Step 2480, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.797\n",
      "Epoch: 6/25, Step 2520, Train loss: 0.106 Train reconstruction loss: 0.019 Train covariance loss: 8.683\n",
      "Epoch: 6/25, Step 2560, Train loss: 0.111 Train reconstruction loss: 0.019 Train covariance loss: 9.197\n",
      "Epoch: 6/25, Step 2600, Train loss: 0.105 Train reconstruction loss: 0.018 Train covariance loss: 8.618\n",
      "Epoch: 6/25, Step 2640, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.073\n",
      "Epoch: 6/25, Step 2680, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.891\n",
      "Epoch: 6/25, Step 2720, Train loss: 0.113 Train reconstruction loss: 0.019 Train covariance loss: 9.368\n",
      "Epoch: 6/25, Step 2760, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.812\n",
      "Epoch: 6/25, Step 2800, Train loss: 0.112 Train reconstruction loss: 0.019 Train covariance loss: 9.321\n",
      "Epoch: 6/25, Step 2840, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.031\n",
      "Epoch: 6/25, Step 2880, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.937\n",
      "Test reconstruction loss decreased (inf --> 0.018533).  Saving model ...\n",
      "Epoch 6/25,\n",
      "Train Loss: 0.109 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.106 Test reconstruction loss: 0.019 Test covariance loss: 8.702\n",
      "Epoch: 7/25, Step 2920, Train loss: 0.108 Train reconstruction loss: 0.018 Train covariance loss: 8.966\n",
      "Epoch: 7/25, Step 2960, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.082\n",
      "Epoch: 7/25, Step 3000, Train loss: 0.104 Train reconstruction loss: 0.019 Train covariance loss: 8.518\n",
      "Epoch: 7/25, Step 3040, Train loss: 0.106 Train reconstruction loss: 0.019 Train covariance loss: 8.718\n",
      "Epoch: 7/25, Step 3080, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.067\n",
      "Epoch: 7/25, Step 3120, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.050\n",
      "Epoch: 7/25, Step 3160, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.003\n",
      "Epoch: 7/25, Step 3200, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.865\n",
      "Epoch: 7/25, Step 3240, Train loss: 0.111 Train reconstruction loss: 0.019 Train covariance loss: 9.210\n",
      "Epoch: 7/25, Step 3280, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.898\n",
      "Epoch: 7/25, Step 3320, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.121\n",
      "Epoch: 7/25, Step 3360, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.042\n",
      "Test reconstruction loss decreased (inf --> 0.018500).  Saving model ...\n",
      "Epoch 7/25,\n",
      "Train Loss: 0.108 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.093 Test reconstruction loss: 0.019 Test covariance loss: 7.446\n",
      "Epoch: 8/25, Step 3400, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.006\n",
      "Epoch: 8/25, Step 3440, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.942\n",
      "Epoch: 8/25, Step 3480, Train loss: 0.105 Train reconstruction loss: 0.018 Train covariance loss: 8.685\n",
      "Epoch: 8/25, Step 3520, Train loss: 0.111 Train reconstruction loss: 0.019 Train covariance loss: 9.192\n",
      "Epoch: 8/25, Step 3560, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.759\n",
      "Epoch: 8/25, Step 3600, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.807\n",
      "Epoch: 8/25, Step 3640, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.184\n",
      "Epoch: 8/25, Step 3680, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.112\n",
      "Epoch: 8/25, Step 3720, Train loss: 0.111 Train reconstruction loss: 0.019 Train covariance loss: 9.262\n",
      "Epoch: 8/25, Step 3760, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.963\n",
      "Epoch: 8/25, Step 3800, Train loss: 0.108 Train reconstruction loss: 0.018 Train covariance loss: 8.958\n",
      "Epoch: 8/25, Step 3840, Train loss: 0.111 Train reconstruction loss: 0.019 Train covariance loss: 9.212\n",
      "Test reconstruction loss decreased (inf --> 0.018445).  Saving model ...\n",
      "Epoch 8/25,\n",
      "Train Loss: 0.109 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.106 Test reconstruction loss: 0.018 Test covariance loss: 8.763\n",
      "Epoch: 9/25, Step 3880, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.866\n",
      "Epoch: 9/25, Step 3920, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 8.985\n",
      "Epoch: 9/25, Step 3960, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.095\n",
      "Epoch: 9/25, Step 4000, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.073\n",
      "Epoch: 9/25, Step 4040, Train loss: 0.106 Train reconstruction loss: 0.018 Train covariance loss: 8.738\n",
      "Epoch: 9/25, Step 4080, Train loss: 0.106 Train reconstruction loss: 0.019 Train covariance loss: 8.728\n",
      "Epoch: 9/25, Step 4120, Train loss: 0.106 Train reconstruction loss: 0.019 Train covariance loss: 8.704\n",
      "Epoch: 9/25, Step 4160, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 8.993\n",
      "Epoch: 9/25, Step 4200, Train loss: 0.112 Train reconstruction loss: 0.019 Train covariance loss: 9.338\n",
      "Epoch: 9/25, Step 4240, Train loss: 0.111 Train reconstruction loss: 0.018 Train covariance loss: 9.256\n",
      "Epoch: 9/25, Step 4280, Train loss: 0.104 Train reconstruction loss: 0.019 Train covariance loss: 8.563\n",
      "Epoch: 9/25, Step 4320, Train loss: 0.108 Train reconstruction loss: 0.018 Train covariance loss: 8.987\n",
      "Test reconstruction loss decreased (inf --> 0.018397).  Saving model ...\n",
      "Epoch 9/25,\n",
      "Train Loss: 0.108 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.104 Test reconstruction loss: 0.018 Test covariance loss: 8.609\n",
      "Epoch: 10/25, Step 4360, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.943\n",
      "Epoch: 10/25, Step 4400, Train loss: 0.111 Train reconstruction loss: 0.019 Train covariance loss: 9.177\n",
      "Epoch: 10/25, Step 4440, Train loss: 0.107 Train reconstruction loss: 0.018 Train covariance loss: 8.809\n",
      "Epoch: 10/25, Step 4480, Train loss: 0.105 Train reconstruction loss: 0.018 Train covariance loss: 8.614\n",
      "Epoch: 10/25, Step 4520, Train loss: 0.112 Train reconstruction loss: 0.019 Train covariance loss: 9.289\n",
      "Epoch: 10/25, Step 4560, Train loss: 0.106 Train reconstruction loss: 0.019 Train covariance loss: 8.748\n",
      "Epoch: 10/25, Step 4600, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 8.990\n",
      "Epoch: 10/25, Step 4640, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.097\n",
      "Epoch: 10/25, Step 4680, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 8.983\n",
      "Epoch: 10/25, Step 4720, Train loss: 0.106 Train reconstruction loss: 0.019 Train covariance loss: 8.737\n",
      "Epoch: 10/25, Step 4760, Train loss: 0.112 Train reconstruction loss: 0.019 Train covariance loss: 9.345\n",
      "Epoch: 10/25, Step 4800, Train loss: 0.106 Train reconstruction loss: 0.019 Train covariance loss: 8.731\n",
      "Test reconstruction loss decreased (inf --> 0.018429).  Saving model ...\n",
      "Epoch 10/25,\n",
      "Train Loss: 0.108 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.105 Test reconstruction loss: 0.018 Test covariance loss: 8.695\n",
      "Epoch: 11/25, Step 4840, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.126\n",
      "Epoch: 11/25, Step 4880, Train loss: 0.111 Train reconstruction loss: 0.019 Train covariance loss: 9.221\n",
      "Epoch: 11/25, Step 4920, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.108\n",
      "Epoch: 11/25, Step 4960, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.029\n",
      "Epoch: 11/25, Step 5000, Train loss: 0.112 Train reconstruction loss: 0.019 Train covariance loss: 9.314\n",
      "Epoch: 11/25, Step 5040, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.957\n",
      "Epoch: 11/25, Step 5080, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.911\n",
      "Epoch: 11/25, Step 5120, Train loss: 0.111 Train reconstruction loss: 0.019 Train covariance loss: 9.196\n",
      "Epoch: 11/25, Step 5160, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.042\n",
      "Epoch: 11/25, Step 5200, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.961\n",
      "Epoch: 11/25, Step 5240, Train loss: 0.106 Train reconstruction loss: 0.018 Train covariance loss: 8.752\n",
      "Epoch: 11/25, Step 5280, Train loss: 0.104 Train reconstruction loss: 0.019 Train covariance loss: 8.549\n",
      "Test reconstruction loss decreased (inf --> 0.018329).  Saving model ...\n",
      "Epoch 11/25,\n",
      "Train Loss: 0.109 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.102 Test reconstruction loss: 0.018 Test covariance loss: 8.361\n",
      "Epoch: 12/25, Step 5320, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.921\n",
      "Epoch: 12/25, Step 5360, Train loss: 0.105 Train reconstruction loss: 0.019 Train covariance loss: 8.667\n",
      "Epoch: 12/25, Step 5400, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.003\n",
      "Epoch: 12/25, Step 5440, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.846\n",
      "Epoch: 12/25, Step 5480, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.084\n",
      "Epoch: 12/25, Step 5520, Train loss: 0.107 Train reconstruction loss: 0.018 Train covariance loss: 8.849\n",
      "Epoch: 12/25, Step 5560, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.007\n",
      "Epoch: 12/25, Step 5600, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.095\n",
      "Epoch: 12/25, Step 5640, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.016\n",
      "Epoch: 12/25, Step 5680, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.045\n",
      "Epoch: 12/25, Step 5720, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.858\n",
      "Epoch: 12/25, Step 5760, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.915\n",
      "Test reconstruction loss decreased (inf --> 0.018452).  Saving model ...\n",
      "Epoch 12/25,\n",
      "Train Loss: 0.108 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.101 Test reconstruction loss: 0.018 Test covariance loss: 8.220\n",
      "Epoch: 13/25, Step 5800, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.109\n",
      "Epoch: 13/25, Step 5840, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.931\n",
      "Epoch: 13/25, Step 5880, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.790\n",
      "Epoch: 13/25, Step 5920, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.969\n",
      "Epoch: 13/25, Step 5960, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.065\n",
      "Epoch: 13/25, Step 6000, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.880\n",
      "Epoch: 13/25, Step 6040, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.800\n",
      "Epoch: 13/25, Step 6080, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.852\n",
      "Epoch: 13/25, Step 6120, Train loss: 0.107 Train reconstruction loss: 0.018 Train covariance loss: 8.871\n",
      "Epoch: 13/25, Step 6160, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.910\n",
      "Epoch: 13/25, Step 6200, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.974\n",
      "Epoch: 13/25, Step 6240, Train loss: 0.107 Train reconstruction loss: 0.018 Train covariance loss: 8.864\n",
      "Test reconstruction loss decreased (inf --> 0.018309).  Saving model ...\n",
      "Epoch 13/25,\n",
      "Train Loss: 0.108 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.108 Test reconstruction loss: 0.018 Test covariance loss: 8.931\n",
      "Epoch: 14/25, Step 6280, Train loss: 0.112 Train reconstruction loss: 0.019 Train covariance loss: 9.340\n",
      "Epoch: 14/25, Step 6320, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.944\n",
      "Epoch: 14/25, Step 6360, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.124\n",
      "Epoch: 14/25, Step 6400, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.892\n",
      "Epoch: 14/25, Step 6440, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.840\n",
      "Epoch: 14/25, Step 6480, Train loss: 0.108 Train reconstruction loss: 0.018 Train covariance loss: 8.954\n",
      "Epoch: 14/25, Step 6520, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.936\n",
      "Epoch: 14/25, Step 6560, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.141\n",
      "Epoch: 14/25, Step 6600, Train loss: 0.106 Train reconstruction loss: 0.019 Train covariance loss: 8.781\n",
      "Epoch: 14/25, Step 6640, Train loss: 0.106 Train reconstruction loss: 0.019 Train covariance loss: 8.731\n",
      "Epoch: 14/25, Step 6680, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.015\n",
      "Epoch: 14/25, Step 6720, Train loss: 0.108 Train reconstruction loss: 0.018 Train covariance loss: 9.002\n",
      "Test reconstruction loss decreased (inf --> 0.018335).  Saving model ...\n",
      "Epoch 14/25,\n",
      "Train Loss: 0.108 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.111 Test reconstruction loss: 0.018 Test covariance loss: 9.263\n",
      "Epoch: 15/25, Step 6760, Train loss: 0.107 Train reconstruction loss: 0.018 Train covariance loss: 8.869\n",
      "Epoch: 15/25, Step 6800, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.146\n",
      "Epoch: 15/25, Step 6840, Train loss: 0.108 Train reconstruction loss: 0.018 Train covariance loss: 8.983\n",
      "Epoch: 15/25, Step 6880, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 8.968\n",
      "Epoch: 15/25, Step 6920, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.981\n",
      "Epoch: 15/25, Step 6960, Train loss: 0.111 Train reconstruction loss: 0.019 Train covariance loss: 9.171\n",
      "Epoch: 15/25, Step 7000, Train loss: 0.107 Train reconstruction loss: 0.018 Train covariance loss: 8.911\n",
      "Epoch: 15/25, Step 7040, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.003\n",
      "Epoch: 15/25, Step 7080, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.905\n",
      "Epoch: 15/25, Step 7120, Train loss: 0.112 Train reconstruction loss: 0.019 Train covariance loss: 9.327\n",
      "Epoch: 15/25, Step 7160, Train loss: 0.106 Train reconstruction loss: 0.019 Train covariance loss: 8.761\n",
      "Epoch: 15/25, Step 7200, Train loss: 0.108 Train reconstruction loss: 0.018 Train covariance loss: 8.952\n",
      "Test reconstruction loss decreased (inf --> 0.018331).  Saving model ...\n",
      "Epoch 15/25,\n",
      "Train Loss: 0.109 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.097 Test reconstruction loss: 0.018 Test covariance loss: 7.847\n",
      "Epoch: 16/25, Step 7240, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.906\n",
      "Epoch: 16/25, Step 7280, Train loss: 0.103 Train reconstruction loss: 0.018 Train covariance loss: 8.498\n",
      "Epoch: 16/25, Step 7320, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.084\n",
      "Epoch: 16/25, Step 7360, Train loss: 0.112 Train reconstruction loss: 0.018 Train covariance loss: 9.373\n",
      "Epoch: 16/25, Step 7400, Train loss: 0.111 Train reconstruction loss: 0.019 Train covariance loss: 9.278\n",
      "Epoch: 16/25, Step 7440, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.783\n",
      "Epoch: 16/25, Step 7480, Train loss: 0.108 Train reconstruction loss: 0.018 Train covariance loss: 8.966\n",
      "Epoch: 16/25, Step 7520, Train loss: 0.110 Train reconstruction loss: 0.018 Train covariance loss: 9.156\n",
      "Epoch: 16/25, Step 7560, Train loss: 0.106 Train reconstruction loss: 0.019 Train covariance loss: 8.778\n",
      "Epoch: 16/25, Step 7600, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.965\n",
      "Epoch: 16/25, Step 7640, Train loss: 0.110 Train reconstruction loss: 0.018 Train covariance loss: 9.105\n",
      "Epoch: 16/25, Step 7680, Train loss: 0.106 Train reconstruction loss: 0.018 Train covariance loss: 8.760\n",
      "Test reconstruction loss decreased (inf --> 0.018234).  Saving model ...\n",
      "Epoch 16/25,\n",
      "Train Loss: 0.108 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.094 Test reconstruction loss: 0.018 Test covariance loss: 7.610\n",
      "Epoch: 17/25, Step 7720, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.050\n",
      "Epoch: 17/25, Step 7760, Train loss: 0.106 Train reconstruction loss: 0.019 Train covariance loss: 8.788\n",
      "Epoch: 17/25, Step 7800, Train loss: 0.109 Train reconstruction loss: 0.018 Train covariance loss: 9.016\n",
      "Epoch: 17/25, Step 7840, Train loss: 0.111 Train reconstruction loss: 0.018 Train covariance loss: 9.278\n",
      "Epoch: 17/25, Step 7880, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.924\n",
      "Epoch: 17/25, Step 7920, Train loss: 0.106 Train reconstruction loss: 0.018 Train covariance loss: 8.797\n",
      "Epoch: 17/25, Step 7960, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.106\n",
      "Epoch: 17/25, Step 8000, Train loss: 0.104 Train reconstruction loss: 0.018 Train covariance loss: 8.545\n",
      "Epoch: 17/25, Step 8040, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 8.991\n",
      "Epoch: 17/25, Step 8080, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.198\n",
      "Epoch: 17/25, Step 8120, Train loss: 0.105 Train reconstruction loss: 0.019 Train covariance loss: 8.599\n",
      "Epoch: 17/25, Step 8160, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.063\n",
      "Test reconstruction loss decreased (inf --> 0.018249).  Saving model ...\n",
      "Epoch 17/25,\n",
      "Train Loss: 0.108 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.110 Test reconstruction loss: 0.018 Test covariance loss: 9.218\n",
      "Epoch: 18/25, Step 8200, Train loss: 0.111 Train reconstruction loss: 0.018 Train covariance loss: 9.207\n",
      "Epoch: 18/25, Step 8240, Train loss: 0.110 Train reconstruction loss: 0.018 Train covariance loss: 9.213\n",
      "Epoch: 18/25, Step 8280, Train loss: 0.112 Train reconstruction loss: 0.019 Train covariance loss: 9.346\n",
      "Epoch: 18/25, Step 8320, Train loss: 0.104 Train reconstruction loss: 0.019 Train covariance loss: 8.556\n",
      "Epoch: 18/25, Step 8360, Train loss: 0.106 Train reconstruction loss: 0.019 Train covariance loss: 8.720\n",
      "Epoch: 18/25, Step 8400, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.060\n",
      "Epoch: 18/25, Step 8440, Train loss: 0.109 Train reconstruction loss: 0.018 Train covariance loss: 9.078\n",
      "Epoch: 18/25, Step 8480, Train loss: 0.107 Train reconstruction loss: 0.018 Train covariance loss: 8.823\n",
      "Epoch: 18/25, Step 8520, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.060\n",
      "Epoch: 18/25, Step 8560, Train loss: 0.105 Train reconstruction loss: 0.019 Train covariance loss: 8.589\n",
      "Epoch: 18/25, Step 8600, Train loss: 0.108 Train reconstruction loss: 0.018 Train covariance loss: 9.026\n",
      "Epoch: 18/25, Step 8640, Train loss: 0.109 Train reconstruction loss: 0.018 Train covariance loss: 9.089\n",
      "Test reconstruction loss decreased (inf --> 0.018282).  Saving model ...\n",
      "Epoch 18/25,\n",
      "Train Loss: 0.108 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.104 Test reconstruction loss: 0.018 Test covariance loss: 8.554\n",
      "Epoch: 19/25, Step 8680, Train loss: 0.110 Train reconstruction loss: 0.018 Train covariance loss: 9.116\n",
      "Epoch: 19/25, Step 8720, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.082\n",
      "Epoch: 19/25, Step 8760, Train loss: 0.106 Train reconstruction loss: 0.018 Train covariance loss: 8.720\n",
      "Epoch: 19/25, Step 8800, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.165\n",
      "Epoch: 19/25, Step 8840, Train loss: 0.109 Train reconstruction loss: 0.018 Train covariance loss: 9.065\n",
      "Epoch: 19/25, Step 8880, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.134\n",
      "Epoch: 19/25, Step 8920, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.068\n",
      "Epoch: 19/25, Step 8960, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.931\n",
      "Epoch: 19/25, Step 9000, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.025\n",
      "Epoch: 19/25, Step 9040, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.079\n",
      "Epoch: 19/25, Step 9080, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.009\n",
      "Epoch: 19/25, Step 9120, Train loss: 0.105 Train reconstruction loss: 0.018 Train covariance loss: 8.612\n",
      "Test reconstruction loss decreased (inf --> 0.018288).  Saving model ...\n",
      "Epoch 19/25,\n",
      "Train Loss: 0.109 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.101 Test reconstruction loss: 0.018 Test covariance loss: 8.235\n",
      "Epoch: 20/25, Step 9160, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.859\n",
      "Epoch: 20/25, Step 9200, Train loss: 0.110 Train reconstruction loss: 0.018 Train covariance loss: 9.146\n",
      "Epoch: 20/25, Step 9240, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.151\n",
      "Epoch: 20/25, Step 9280, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 8.998\n",
      "Epoch: 20/25, Step 9320, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.166\n",
      "Epoch: 20/25, Step 9360, Train loss: 0.105 Train reconstruction loss: 0.019 Train covariance loss: 8.667\n",
      "Epoch: 20/25, Step 9400, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.844\n",
      "Epoch: 20/25, Step 9440, Train loss: 0.108 Train reconstruction loss: 0.018 Train covariance loss: 8.921\n",
      "Epoch: 20/25, Step 9480, Train loss: 0.106 Train reconstruction loss: 0.018 Train covariance loss: 8.721\n",
      "Epoch: 20/25, Step 9520, Train loss: 0.108 Train reconstruction loss: 0.018 Train covariance loss: 8.993\n",
      "Epoch: 20/25, Step 9560, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.161\n",
      "Epoch: 20/25, Step 9600, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.013\n",
      "Test reconstruction loss decreased (inf --> 0.018272).  Saving model ...\n",
      "Epoch 20/25,\n",
      "Train Loss: 0.108 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.106 Test reconstruction loss: 0.018 Test covariance loss: 8.776\n",
      "Epoch: 21/25, Step 9640, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.111\n",
      "Epoch: 21/25, Step 9680, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.986\n",
      "Epoch: 21/25, Step 9720, Train loss: 0.106 Train reconstruction loss: 0.018 Train covariance loss: 8.767\n",
      "Epoch: 21/25, Step 9760, Train loss: 0.109 Train reconstruction loss: 0.018 Train covariance loss: 9.064\n",
      "Epoch: 21/25, Step 9800, Train loss: 0.112 Train reconstruction loss: 0.018 Train covariance loss: 9.357\n",
      "Epoch: 21/25, Step 9840, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.934\n",
      "Epoch: 21/25, Step 9880, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.148\n",
      "Epoch: 21/25, Step 9920, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.846\n",
      "Epoch: 21/25, Step 9960, Train loss: 0.103 Train reconstruction loss: 0.018 Train covariance loss: 8.469\n",
      "Epoch: 21/25, Step 10000, Train loss: 0.106 Train reconstruction loss: 0.018 Train covariance loss: 8.803\n",
      "Epoch: 21/25, Step 10040, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.059\n",
      "Epoch: 21/25, Step 10080, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.053\n",
      "Test reconstruction loss decreased (inf --> 0.018174).  Saving model ...\n",
      "Epoch 21/25,\n",
      "Train Loss: 0.108 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.115 Test reconstruction loss: 0.018 Test covariance loss: 9.646\n",
      "Epoch: 22/25, Step 10120, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.967\n",
      "Epoch: 22/25, Step 10160, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 8.989\n",
      "Epoch: 22/25, Step 10200, Train loss: 0.108 Train reconstruction loss: 0.018 Train covariance loss: 8.962\n",
      "Epoch: 22/25, Step 10240, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.921\n",
      "Epoch: 22/25, Step 10280, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.798\n",
      "Epoch: 22/25, Step 10320, Train loss: 0.107 Train reconstruction loss: 0.018 Train covariance loss: 8.832\n",
      "Epoch: 22/25, Step 10360, Train loss: 0.110 Train reconstruction loss: 0.018 Train covariance loss: 9.126\n",
      "Epoch: 22/25, Step 10400, Train loss: 0.107 Train reconstruction loss: 0.018 Train covariance loss: 8.819\n",
      "Epoch: 22/25, Step 10440, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.176\n",
      "Epoch: 22/25, Step 10480, Train loss: 0.111 Train reconstruction loss: 0.019 Train covariance loss: 9.216\n",
      "Epoch: 22/25, Step 10520, Train loss: 0.108 Train reconstruction loss: 0.018 Train covariance loss: 8.992\n",
      "Epoch: 22/25, Step 10560, Train loss: 0.106 Train reconstruction loss: 0.018 Train covariance loss: 8.802\n",
      "Test reconstruction loss decreased (inf --> 0.018186).  Saving model ...\n",
      "Epoch 22/25,\n",
      "Train Loss: 0.108 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.104 Test reconstruction loss: 0.018 Test covariance loss: 8.615\n",
      "Epoch: 23/25, Step 10600, Train loss: 0.111 Train reconstruction loss: 0.019 Train covariance loss: 9.199\n",
      "Epoch: 23/25, Step 10640, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.160\n",
      "Epoch: 23/25, Step 10680, Train loss: 0.111 Train reconstruction loss: 0.019 Train covariance loss: 9.208\n",
      "Epoch: 23/25, Step 10720, Train loss: 0.106 Train reconstruction loss: 0.018 Train covariance loss: 8.802\n",
      "Epoch: 23/25, Step 10760, Train loss: 0.106 Train reconstruction loss: 0.018 Train covariance loss: 8.768\n",
      "Epoch: 23/25, Step 10800, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.126\n",
      "Epoch: 23/25, Step 10840, Train loss: 0.110 Train reconstruction loss: 0.018 Train covariance loss: 9.127\n",
      "Epoch: 23/25, Step 10880, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.103\n",
      "Epoch: 23/25, Step 10920, Train loss: 0.109 Train reconstruction loss: 0.018 Train covariance loss: 9.112\n",
      "Epoch: 23/25, Step 10960, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.805\n",
      "Epoch: 23/25, Step 11000, Train loss: 0.106 Train reconstruction loss: 0.018 Train covariance loss: 8.796\n",
      "Epoch: 23/25, Step 11040, Train loss: 0.109 Train reconstruction loss: 0.018 Train covariance loss: 9.087\n",
      "Test reconstruction loss decreased (inf --> 0.018191).  Saving model ...\n",
      "Epoch 23/25,\n",
      "Train Loss: 0.109 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.095 Test reconstruction loss: 0.018 Test covariance loss: 7.729\n",
      "Epoch: 24/25, Step 11080, Train loss: 0.107 Train reconstruction loss: 0.018 Train covariance loss: 8.857\n",
      "Epoch: 24/25, Step 11120, Train loss: 0.112 Train reconstruction loss: 0.018 Train covariance loss: 9.317\n",
      "Epoch: 24/25, Step 11160, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.792\n",
      "Epoch: 24/25, Step 11200, Train loss: 0.107 Train reconstruction loss: 0.018 Train covariance loss: 8.867\n",
      "Epoch: 24/25, Step 11240, Train loss: 0.108 Train reconstruction loss: 0.018 Train covariance loss: 9.014\n",
      "Epoch: 24/25, Step 11280, Train loss: 0.107 Train reconstruction loss: 0.018 Train covariance loss: 8.904\n",
      "Epoch: 24/25, Step 11320, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.015\n",
      "Epoch: 24/25, Step 11360, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.947\n",
      "Epoch: 24/25, Step 11400, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.963\n",
      "Epoch: 24/25, Step 11440, Train loss: 0.106 Train reconstruction loss: 0.018 Train covariance loss: 8.747\n",
      "Epoch: 24/25, Step 11480, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.967\n",
      "Epoch: 24/25, Step 11520, Train loss: 0.109 Train reconstruction loss: 0.018 Train covariance loss: 9.070\n",
      "Test reconstruction loss decreased (inf --> 0.018194).  Saving model ...\n",
      "Epoch 24/25,\n",
      "Train Loss: 0.108 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.113 Test reconstruction loss: 0.018 Test covariance loss: 9.463\n",
      "Epoch: 25/25, Step 11560, Train loss: 0.108 Train reconstruction loss: 0.018 Train covariance loss: 8.971\n",
      "Epoch: 25/25, Step 11600, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.046\n",
      "Epoch: 25/25, Step 11640, Train loss: 0.108 Train reconstruction loss: 0.018 Train covariance loss: 8.952\n",
      "Epoch: 25/25, Step 11680, Train loss: 0.105 Train reconstruction loss: 0.019 Train covariance loss: 8.656\n",
      "Epoch: 25/25, Step 11720, Train loss: 0.109 Train reconstruction loss: 0.018 Train covariance loss: 9.017\n",
      "Epoch: 25/25, Step 11760, Train loss: 0.110 Train reconstruction loss: 0.019 Train covariance loss: 9.133\n",
      "Epoch: 25/25, Step 11800, Train loss: 0.107 Train reconstruction loss: 0.018 Train covariance loss: 8.854\n",
      "Epoch: 25/25, Step 11840, Train loss: 0.107 Train reconstruction loss: 0.019 Train covariance loss: 8.854\n",
      "Epoch: 25/25, Step 11880, Train loss: 0.109 Train reconstruction loss: 0.019 Train covariance loss: 9.021\n",
      "Epoch: 25/25, Step 11920, Train loss: 0.110 Train reconstruction loss: 0.018 Train covariance loss: 9.124\n",
      "Epoch: 25/25, Step 11960, Train loss: 0.106 Train reconstruction loss: 0.019 Train covariance loss: 8.748\n",
      "Epoch: 25/25, Step 12000, Train loss: 0.108 Train reconstruction loss: 0.019 Train covariance loss: 8.933\n",
      "Test reconstruction loss decreased (inf --> 0.018189).  Saving model ...\n",
      "Epoch 25/25,\n",
      "Train Loss: 0.108 Train reconstruction loss: 0.000 Train covariance loss: 0.000\n",
      "Test Loss: 0.102 Test reconstruction loss: 0.018 Test covariance loss: 8.417\n"
     ]
    }
   ],
   "source": [
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir=runs/ --port=6006\n",
    "!tensorboard --logdir=runs/ --port=6006 --reload_multifile=true\n",
    "logs = train_model(model=model, goal_hidden_dim=5, \n",
    "                                         optimizer=optimizer, loss_func=criterion, epochs=epochs,\n",
    "                                         trainloader=trainloader, testloader=testloader, print_every=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKMAAAGGCAYAAACno0IzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeXhTVfoH8G/2dKf7At0A2feiWLACgmUAERVGRAUVUbE4I6CjgCKKCiOgUx02QRH5CYi7jiKCCIhQlF12BAotpaW00Ba6Zbu/P25uliZdSZs2/X6ep0+Sm5vkpNCcnPe85z0yQRAEEBERERERERERNQC5uxtARERERERERETNB4NRRERERERERETUYBiMIiIiIiIiIiKiBsNgFBERERERERERNRgGo4iIiIiIiIiIqMEwGEVERERERERERA2GwSgiIiIiIiIiImowDEYREREREREREVGDYTCKiIiIiIiIiIgaDINR5BZ//vknHnvsMcTHx0Or1cLX1xe9evXC/PnzceXKlQZvz6uvvgqZTIa8vLxqzx0wYAAGDBhQ/41yYtWqVZDJZDh37lyV50nvh4iooUmfU9KPUqlEZGQkHnjgAfz111/ubp7LLVmyBKtWrXJrG9auXYvU1FSn98lkMrz66qsN2h6g5v0VEZErNLaxRW08+uijiIuLc3czbhjHH1RbSnc3gJqfFStWICUlBe3bt8e//vUvdOrUCXq9Hnv37sWyZcuQlpaGr7/+2t3NrNSSJUvc3QQiokbvo48+QocOHVBWVoadO3fizTffxNatW3HixAkEBga6u3kus2TJEoSEhODRRx91WxvWrl2LI0eOYMqUKQ73paWloVWrVg3fKCKiBtLUxxazZs3Cs88+6+5mEDU4BqOoQaWlpeHpp5/GnXfeiW+++QYajcZy35133onnnnsOGzdudGMLq9epUyd3N4GIqNHr0qULevfuDUDMKDUajZg9eza++eYbPPbYY25unXvo9XpLtlhDufXWWxvstYiIGlpTHluUlJTA29sbbdq0cXdTiNyCy/SoQc2dOxcymQzLly+36ywkarUad999t+W2yWTC/Pnz0aFDB2g0GoSFhWH8+PG4cOGC3eMGDBiALl26IC0tDX379oWXlxfi4uLw0UcfAQB++OEH9OrVC97e3ujatWulnVJmZibuu+8++Pv7IyAgAA8//DAuX77s8Fq2y/TOnTsHmUyGhQsX4p133kF8fDx8fX2RmJiI3bt3O7zG3r17cffddyMoKAharRY9e/bEZ5995nDe7t270a9fP2i1WkRFRWHGjBnQ6/WV/3KrUdPf5YEDB3DXXXchLCwMGo0GUVFRGD58uN15n3/+Ofr06YOAgAB4e3ujdevWmDBhQp3bRkSeTwpMXbp0ye54TT8Ts7Ky8OSTTyI6OhpqtRpRUVEYPXq03fNlZGTg4Ycftnx+dezYEW+//TZMJpPlnNp8Zp89exYPPPAAoqKioNFoEB4ejkGDBuHgwYMAgLi4OBw9ehTbt2+3LEuUllps27YNMpkM//d//4fnnnsOLVu2hEajwenTpytdylDZ0ra1a9ciMTERvr6+8PX1RY8ePfDhhx8CEPukH374AefPn7dbHilxtkzvyJEjGDlyJAIDA6HVatGjRw98/PHHdudI7V+3bh1eeuklREVFwd/fH4MHD8bJkycd2l5TK1euRPfu3aHVahEUFIR7770Xx48ftzunut87APzyyy8YMGAAgoOD4eXlhZiYGIwaNQolJSV1bhsRNT31MbaYMmUKfHx8UFRU5PB8Y8aMQXh4uOU7+fr165GcnIzIyEh4eXmhY8eOmD59OoqLi+0e9+ijj8LX1xeHDx9GcnIy/Pz8MGjQIMt9FZfpLV68GLfffjvCwsLg4+ODrl27Yv78+Q5jAWkMtGfPHiQlJVm+l//73/+26/sAoKCgAM899xxat25tee/Dhg3DiRMnLOfodDq88cYblt9PaGgoHnvsMYfxUE1x/EFVYWYUNRij0YhffvkFCQkJiI6OrtFjnn76aSxfvhzPPPMM7rrrLpw7dw6zZs3Ctm3bsH//foSEhFjOzcnJwWOPPYYXXngBrVq1wn//+19MmDABmZmZ+OKLLzBz5kwEBARgzpw5uOeee3D27FlERUXZvd69996L+++/H5MmTcLRo0cxa9YsHDt2DL///jtUKlWVbV28eDE6dOhgqdsxa9YsDBs2DOnp6QgICAAAbN26FX/729/Qp08fLFu2DAEBAfj0008xZswYlJSUWJZ5HDt2DIMGDUJcXBxWrVoFb29vLFmyBGvXrq3hb7tuv8vi4mLceeediI+Px+LFixEeHo6cnBxs3boV165dAyDOQI0ZMwZjxozBq6++Cq1Wi/Pnz+OXX36pc9uIyPOlp6cDANq1a2c5VtPPxKysLNx8883Q6/WYOXMmunXrhvz8fPz000+4evUqwsPDcfnyZfTt2xc6nQ6vv/464uLi8P333+P555/HmTNnHJZY1+Qze9iwYTAajZg/fz5iYmKQl5eHXbt2oaCgAADw9ddfY/To0QgICLA8f8XB0IwZM5CYmIhly5ZBLpcjLCysVr+3V155Ba+//jruu+8+PPfccwgICMCRI0dw/vx5AOIywSeffBJnzpyp0TKUkydPom/fvggLC8N7772H4OBgfPLJJ3j00Udx6dIlvPDCC3bnz5w5E/369cMHH3yAoqIivPjiixgxYgSOHz8OhUJRq/cyb948zJw5E2PHjsW8efOQn5+PV199FYmJidizZw9uuukmANX/3s+dO4fhw4cjKSkJK1euRIsWLZCVlYWNGzdCp9PB29u7Vu0ioqapvsYWEyZMwLvvvovPPvsMEydOtDy2oKAA3377LSZPnmwZF/z1118YNmyYJYB14sQJvPXWW/jjjz8cvhvrdDrcfffdeOqppzB9+nQYDIZK23nmzBk8+OCDiI+Ph1qtxqFDh/Dmm2/ixIkTWLlypd25OTk5eOihh/Dcc89h9uzZ+PrrrzFjxgxERUVh/PjxAIBr167htttuw7lz5/Diiy+iT58+uH79On799VdkZ2ejQ4cOMJlMGDlyJHbs2IEXXngBffv2xfnz5zF79mwMGDAAe/fuhZeXV41+z7X5fXP80YwJRA0kJydHACA88MADNTr/+PHjAgAhJSXF7vjvv/8uABBmzpxpOda/f38BgLB3717Lsfz8fEGhUAheXl5CVlaW5fjBgwcFAMJ7771nOTZ79mwBgDB16lS711qzZo0AQPjkk0/sXqt///6W2+np6QIAoWvXroLBYLAc/+OPPwQAwrp16yzHOnToIPTs2VPQ6/V2r3PXXXcJkZGRgtFoFARBEMaMGSN4eXkJOTk5lnMMBoPQoUMHAYCQnp5e5e9Oej+Smv4u9+7dKwAQvvnmm0qfe+HChQIAoaCgoMo2EFHz9NFHHwkAhN27dwt6vV64du2asHHjRiEiIkK4/fbb7T7/avqZOGHCBEGlUgnHjh2r9HWnT58uABB+//13u+NPP/20IJPJhJMnTwqCUPPP7Ly8PAGAkJqaWuX77dy5s12fINm6dasAQLj99tsd7qv4GS2RfnfSZ/zZs2cFhUIhPPTQQ1W2Yfjw4UJsbKzT+wAIs2fPttx+4IEHBI1GI2RkZNidN3ToUMHb29vy2S61f9iwYXbnffbZZwIAIS0trco2VXwvV69eFby8vByeLyMjQ9BoNMKDDz4oCELNfu9ffPGFAEA4ePBglW0gIs9Wn2OLXr16CX379rU7b8mSJQIA4fDhw06f32QyCXq9Xti+fbsAQDh06JDlvkceeUQAIKxcudLhcY888kiln+GCIAhGo1HQ6/XC6tWrBYVCIVy5csVynzQGqtj3derUSRgyZIjl9pw5cwQAwubNmyt9nXXr1gkAhC+//NLu+J49ewQAwpIlSyp9rCBw/EG1x2V61Ght3boVAByKwt5yyy3o2LEjtmzZYnc8MjISCQkJlttBQUEICwtDjx497DKgOnbsCACWWWVbDz30kN3t+++/H0ql0tKWqgwfPtxulrhbt252r3P69GmcOHHC8hoGg8HyM2zYMGRnZ1uWPmzduhWDBg1CeHi45fkUCgXGjBlTbTucqenvsm3btggMDMSLL76IZcuW4dixYw7PdfPNNwMQfzefffYZsrKy6tQmIvJst956K1QqFfz8/PC3v/0NgYGB+Pbbby31kmrzmfjjjz9i4MCBls9vZ3755Rd06tQJt9xyi93xRx99FIIgOMyeVveZHRQUhDZt2mDBggV45513cODAAYclDzUxatSoWj9GsnnzZhiNRkyePLnOz1HRL7/8gkGDBjlkETz66KMoKSlBWlqa3XHb5S2A4++pptLS0lBaWurQD0VHR+OOO+6w9EM1+b336NEDarUaTz75JD7++GOcPXu2Vm0houapNmOLxx57DLt27bJblvzRRx/h5ptvRpcuXSzHzp49iwcffBARERFQKBRQqVTo378/ADgsQQZq3iccOHAAd999N4KDgy3PO378eBiNRpw6dcru3IiICIe+r1u3bnaf0z/++CPatWuHwYMHV/qa33//PVq0aIERI0bY9ck9evRAREQEtm3bVqO2Szj+oOowGEUNJiQkBN7e3palGtXJz88HIAaZKoqKirLcLwkKCnI4T61WOxxXq9UAgLKyMofzIyIi7G4rlUoEBwc7vJYzwcHBdrelpRqlpaUArHVSnn/+eahUKruflJQUAEBeXh4A8b1XbIuz9tVUTX+XAQEB2L59O3r06IGZM2eic+fOiIqKwuzZsy1r1G+//XZ88803MBgMGD9+PFq1aoUuXbpg3bp1dWobEXmm1atXY8+ePfjll1/w1FNP4fjx4xg7dqzl/tp8Jl6+fLnaHeHy8/Mr/YyT7rdV3We2TCbDli1bMGTIEMyfPx+9evVCaGgo/vnPf1qWDdSEszbVlFSjw5W74bn691Sb1wWq74dq8ntv06YNfv75Z4SFhWHy5Mlo06YN2rRpg3fffbdWbSKipq0+xxYPPfQQNBoNVq1aBUAsobFnzx67DTiuX7+OpKQk/P7773jjjTewbds27NmzB1999RUAx89Jb29v+Pv7V9vOjIwMJCUlISsrC++++y527NiBPXv2YPHixU6ft+LnNCB+VtueV5N+9NKlSygoKIBarXbol3Nycix9ck1x/EHVYc0oajAKhQKDBg3Cjz/+iAsXLlT7gSh9sGZnZzuce/HiRbt6Ua6Sk5ODli1bWm4bDAbk5+c7/ZCvLam9M2bMwH333ef0nPbt2wMQ33tOTo7T9tVFbX6XXbt2xaeffgpBEPDnn39i1apVmDNnDry8vDB9+nQAwMiRIzFy5EiUl5dj9+7dmDdvHh588EHExcUhMTGxTm0kIs/SsWNHS9HygQMHwmg04oMPPsAXX3yB0aNH1+ozMTQ01KHYaUXBwcHIzs52OH7x4kUAqFOfERsbaykUfurUKXz22Wd49dVXodPpsGzZsho9h7NC5VqtFgBQXl5uV2Oq4hf90NBQAMCFCxdqXA+lOvXxe6rp6wKo9LVtX7cmv/ekpCQkJSXBaDRi7969+O9//4spU6YgPDwcDzzwQL28ByJqXOpzbBEYGIiRI0di9erVeOONN/DRRx9Bq9XaTar88ssvuHjxIrZt22bJhgJgqW9XkbP+wJlvvvkGxcXF+OqrrxAbG2s5bruJQ23VpB8NCQlBcHBwpRs9+fn51eo1Of6g6jAzihrUjBkzIAgCnnjiCeh0Oof79Xo9/ve//wEA7rjjDgDAJ598YnfOnj17cPz4ccsOFK60Zs0au9ufffYZDAaD3e55ddW+fXvcdNNNOHToEHr37u30R/qQHzhwILZs2WK3S5TRaMT69evr9Np1+V3KZDJ0794d//nPf9CiRQvs37/f4RyNRoP+/fvjrbfeAiCmFBMROTN//nwEBgbilVdegclkqtVn4tChQ7F169Yqd3EbNGgQjh075vBZtXr1ashkMgwcOPCG2t+uXTu8/PLL6Nq1q91rVJx9rglp16Q///zT7rjU/0mSk5OhUCiwdOnSKp+vNm0YNGiQZQBla/Xq1fD29satt95ao+eprcTERHh5eTn0QxcuXLAsHXSmst+7RKFQoE+fPpaMAWfnEJHnqs+xxWOPPYaLFy9iw4YN+OSTT3DvvfeiRYsWlvul4FLFjSvef//9G3pPzp5XEASsWLGizs85dOhQnDp1qsqC33fddRfy8/NhNBqd9snSBFFNcfxB1WFmFDWoxMRELF26FCkpKUhISMDTTz+Nzp07Q6/X48CBA1i+fDm6dOmCESNGoH379njyySfx3//+F3K5HEOHDrXswBAdHY2pU6e6vH1fffUVlEol7rzzTstuet27d8f999/vkud///33MXToUAwZMgSPPvooWrZsiStXruD48ePYv38/Pv/8cwDAyy+/jO+++w533HEHXnnlFXh7e2Px4sUO28TWVE1/l99//z2WLFmCe+65B61bt4YgCPjqq69QUFCAO++8E4C4s9OFCxcwaNAgtGrVCgUFBXj33Xft1sgTEVUUGBiIGTNm4IUXXsDatWvx8MMP1/gzcc6cOfjxxx9x++23Y+bMmejatSsKCgqwceNGTJs2DR06dMDUqVOxevVqDB8+HHPmzEFsbCx++OEHLFmyBE8//bTdLn418eeff+KZZ57B3//+d9x0001Qq9X45Zdf8Oeff1pmaQHrbO769evRunVraLVadO3atcrnHjZsGIKCgvD4449jzpw5UCqVWLVqFTIzM+3Oi4uLw8yZM/H666+jtLQUY8eORUBAAI4dO4a8vDy89tprljZ89dVXWLp0KRISEiCXyy1ZaRXNnj0b33//PQYOHIhXXnkFQUFBWLNmDX744QfMnz/fspOgq7Vo0QKzZs3CzJkzMX78eIwdOxb5+fl47bXXoNVqMXv2bAA1+70vW7YMv/zyC4YPH46YmBiUlZVZdpeqqh4KEXme+hxbJCcno1WrVkhJSbHs2m2rb9++CAwMxKRJkzB79myoVCqsWbMGhw4duqH3dOedd0KtVmPs2LF44YUXUFZWhqVLl+Lq1at1fs4pU6Zg/fr1GDlyJKZPn45bbrkFpaWl2L59O+666y4MHDgQDzzwANasWYNhw4bh2WefxS233AKVSoULFy5g69atGDlyJO69994avybHH1Qt99VOp+bs4MGDwiOPPCLExMQIarVa8PHxEXr27Cm88sorQm5uruU8o9EovPXWW0K7du0ElUolhISECA8//LCQmZlp93z9+/cXOnfu7PA6sbGxwvDhwx2OAxAmT55suS3t/rBv3z5hxIgRgq+vr+Dn5yeMHTtWuHTpksNrOdtNb8GCBU5fx3YXI0EQhEOHDgn333+/EBYWJqhUKiEiIkK44447hGXLltmdt3PnTuHWW28VNBqNEBERIfzrX/8Sli9fXqfd9AShZr/LEydOCGPHjhXatGkjeHl5CQEBAcItt9wirFq1ynLO999/LwwdOlRo2bKloFarhbCwMGHYsGHCjh07qmwTETUP0i5qe/bscbivtLRUiImJEW666SbLTnY1/UzMzMwUJkyYIERERAgqlUqIiooS7r//frvP6PPnzwsPPvigEBwcLKhUKqF9+/bCggULLLvyCULNP7MvXbokPProo0KHDh0EHx8fwdfXV+jWrZvwn//8x24XvnPnzgnJycmCn5+fAMCyI5K0G93nn3/u9Pf0xx9/CH379hV8fHyEli1bCrNnzxY++OADp5/xq1evFm6++WZBq9UKvr6+Qs+ePYWPPvrIcv+VK1eE0aNHCy1atBBkMpnd57+zfujw4cPCiBEjhICAAEGtVgvdu3e3e76q2i/9/iqeX1HF3fQkH3zwgdCtWzdBrVYLAQEBwsiRI4WjR49a7q/J7z0tLU249957hdjYWEGj0QjBwcFC//79he+++67KNhGR53L12EIyc+ZMAYAQHR1t15dIdu3aJSQmJgre3t5CaGioMHHiRGH//v0On5OPPPKI4OPj4/Q1nO2m97///U/o3r27oNVqhZYtWwr/+te/hB9//FEAIGzdutVyXmVjIGfPefXqVeHZZ58VYmJiBJVKJYSFhQnDhw8XTpw4YTlHr9cLCxcutLy2r6+v0KFDB+Gpp54S/vrrL6ftl3D8QbUlEwRBaNDoFxERERERERERNVusGUVERERERERERA2GwSgiIiIiIiIiImowDEYREREREREREVGDYTCKiIiIiIiIiIgaDINRRERERERERETUYBiMIiIiIiIiIiKiBqN0dwNcxWQy4eLFi/Dz84NMJnN3c4iIGh1BEHDt2jVERUVBLnfdXMSSJUuwYMECZGdno3PnzkhNTUVSUlKl52/fvh3Tpk3D0aNHERUVhRdeeAGTJk2y3L9ixQqsXr0aR44cAQAkJCRg7ty5uOWWWyznvPrqq3jttdfsnjc8PBw5OTk1bjf7DSKiqtVXv9FUsd8gIqpabfoNjwlGXbx4EdHR0e5uBhFRo5eZmYlWrVq55LnWr1+PKVOmYMmSJejXrx/ef/99DB06FMeOHUNMTIzD+enp6Rg2bBieeOIJfPLJJ9i5cydSUlIQGhqKUaNGAQC2bduGsWPHom/fvtBqtZg/fz6Sk5Nx9OhRtGzZ0vJcnTt3xs8//2y5rVAoatV29htERDXjyn6jKWO/QURUMzXpN2SCIAgN1J56VVhYiBYtWiAzMxP+/v7ubg4RUaNTVFSE6OhoFBQUICAgwCXP2adPH/Tq1QtLly61HOvYsSPuuecezJs3z+H8F198Ed999x2OHz9uOTZp0iQcOnQIaWlpTl/DaDQiMDAQixYtwvjx4wGImVHffPMNDh48WOe2s98gIqpaffQbTRn7DSKiqtWm3/CYzCgpVdbf35+dAxFRFVy1tECn02Hfvn2YPn263fHk5GTs2rXL6WPS0tKQnJxsd2zIkCH48MMPodfroVKpHB5TUlICvV6PoKAgu+N//fUXoqKioNFo0KdPH8ydOxetW7eucfvZbxAR1QyXpInYbxAR1UxN+g0u/iYiojrJy8uD0WhEeHi43fGqajfl5OQ4Pd9gMCAvL8/pY6ZPn46WLVti8ODBlmN9+vTB6tWr8dNPP2HFihXIyclB3759kZ+fX2l7y8vLUVRUZPdDREREREQNj8EoIiK6IRVnPgRBqHI2xNn5zo4DwPz587Fu3Tp89dVX0Gq1luNDhw7FqFGj0LVrVwwePBg//PADAODjjz+u9HXnzZuHgIAAyw/rfhARERERuQeDUUREVCchISFQKBQOWVC5ubkO2U+SiIgIp+crlUoEBwfbHV+4cCHmzp2LTZs2oVu3blW2xcfHB127dsVff/1V6TkzZsxAYWGh5SczM7PK5yQiIiIiovrhMTWjasJkMkGn07m7GeQiKpWq1rtnEZHrqNVqJCQkYPPmzbj33nstxzdv3oyRI0c6fUxiYiL+97//2R3btGkTevfubVcvasGCBXjjjTfw008/oXfv3tW2pby8HMePH0dSUlKl52g0Gmg0mmqfi4iqZjQaodfr3d0McgF+l3I9jjc8i1qtrnZ7eiKqm2YTjNLpdEhPT4fJZHJ3U8iFWrRogYiICBbWJHKTadOmYdy4cejduzcSExOxfPlyZGRkYNKkSQDEbKSsrCysXr0agLhz3qJFizBt2jQ88cQTSEtLw4cffoh169ZZnnP+/PmYNWsW1q5di7i4OEsmla+vL3x9fQEAzz//PEaMGIGYmBjk5ubijTfeQFFRER555JEG/g0QNR+CICAnJwcFBQXubgq5EL9LuQ7HG55HLpcjPj4earXa3U0h8jjNIhglCAKys7OhUCgQHR3N6LYHEAQBJSUlyM3NBQBERka6uUVEzdOYMWOQn5+POXPmIDs7G126dMGGDRsQGxsLAMjOzkZGRobl/Pj4eGzYsAFTp07F4sWLERUVhffeew+jRo2ynLNkyRLodDqMHj3a7rVmz56NV199FQBw4cIFjB07Fnl5eQgNDcWtt96K3bt3W16XiFxPCkSFhYXB29ubwYsmjt+lXIvjDc9jMplw8eJFZGdnIyYmhp95RC4mE6TKsU1cUVERAgICUFhY6LDVql6vx+nTpxEVFYWAgAA3tZDqQ35+PnJzc9GuXTummRNVo6rPyeaIvw+imjMajTh16hTCwsIc6rtR01bVdyl+TtrjeKP5KSwsxMWLF9G2bVu7cgJE5Fxt+o1mEbI3Go0AwPRKD+Tt7Q0ArF1BRERUj6R+Vup3yXPwu5RrcLzhmaR/T+nfl4hcp1kEoyRMrfQ8/DclIiJqOOx3PQ//TV2Lv0/Pwn9PovpTp2DUkiVLEB8fD61Wi4SEBOzYsaPSc7Ozs/Hggw+iffv2kMvlmDJlisM5K1asQFJSEgIDAxEYGIjBgwfjjz/+qEvTiIiIiIiIiIioEat1MGr9+vWYMmUKXnrpJRw4cABJSUkYOnSoXYFaW+Xl5QgNDcVLL72E7t27Oz1n27ZtGDt2LLZu3Yq0tDTExMQgOTkZWVlZtW0eVWPAgAFOA4JEREREVDP8PkVUOf59EFFN1DoY9c477+Dxxx/HxIkT0bFjR6SmpiI6OhpLly51en5cXBzeffddjB8/vtJifmvWrEFKSgp69OiBDh06YMWKFTCZTNiyZUttm+cxZDJZlT+PPvponZ73q6++wuuvv+7axhI1Bv97FvhyIuAZezJQI7bpaA5unbsFk9fsd3dTiKga/D5FVDn+fRDVgiAAn40HNvzL3S3xGLUKRul0Ouzbtw/Jycl2x5OTk7Fr1y6XNaqkpAR6vR5BQUGVnlNeXo6ioiK7H0+SnZ1t+UlNTYW/v7/dsXfffdfu/JoWnQwKCoKfn199NJnIfYx6YN8q4PDnQHGeu1tDHk5vFJBTVIa86+XubgoRVYPfp5qPX3/9FSNGjEBUVBRkMhm++eYbu/sFQcCrr76KqKgoeHl5YcCAATh69Kh7GttI8O+DqBau5QDHvgX+WA6YTO5ujUeoVTAqLy8PRqMR4eHhdsfDw8ORk5PjskZNnz4dLVu2xODBgys9Z968eQgICLD8REdHu+z1G4OIiAjLT0BAAGQymeV2WVkZWrRogc8++wwDBgyAVqvFJ598gvz8fIwdOxatWrWCt7c3unbtinXr1tk9b8W02bi4OMydOxcTJkyAn58fYmJisHz58gZ+t0Q3yGSwXtcXu68d1CwoFWIxU72RX0SIGjt+n2o+iouL0b17dyxatMjp/fPnz8c777yDRYsWYc+ePYiIiMCdd96Ja9euNXBLGw/+fRDVgskmGGsodV87PEidCphX3FVAEASX7TQwf/58rFu3Dl999RW0Wm2l582YMQOFhYWWn8zMzBq/hiAIKNEZ3PIjuHAJ0Ysvvoh//vOfOH78OIYMGYKysjIkJCTg+++/x5EjR/Dkk09i3Lhx+P3336t8nrfffhu9e/fGgQMHkJKSgqeffhonTpxwWTuJ6p3JZrtdXYn72kHNglohdp0GE5eEUvPG71P2+H3KvYYOHYo33ngD9913n8N9giAgNTUVL730Eu677z506dIFH3/8MUpKSrB27dp6aQ//Puzx74OaPLvxBie/XUFZm5NDQkKgUCgcsqByc3MdsqXqYuHChZg7dy5+/vlndOvWrcpzNRoNNBpNnV6nVG9Ep1d+qtNjb9SxOUPgra7Vr71SU6ZMcehwn3/+ecv1f/zjH9i4cSM+//xz9OnTp9LnGTZsGFJSUgCIHc5//vMfbNu2DR06dHBJO4nqnV1mFINRVL+kzCidgZlR1Lzx+5Q9fp9qvNLT05GTk2NXakSj0aB///7YtWsXnnrqKaePKy8vR3m5dUl2bcqC8O/DHv8+qMljMMrlapUZpVarkZCQgM2bN9sd37x5M/r27XtDDVmwYAFef/11bNy4Eb17976h52ouKv6ejEYj3nzzTXTr1g3BwcHw9fXFpk2bKt3pUGIb+JPSc3Nzc+ulzUT1QrAJCrBzoHqmlDMzisiT8PuU55Mm0mtbasTTy4LUBP8+iMw4+e1ytQ6ZT5s2DePGjUPv3r2RmJiI5cuXIyMjA5MmTQIgLp/LysrC6tWrLY85ePAgAOD69eu4fPkyDh48CLVajU6dOgEQl+bNmjULa9euRVxcnKVT8PX1ha+v742+RwdeKgWOzRni8uet6Wu7io+Pj93tt99+G//5z3+QmpqKrl27wsfHB1OmTIFOp6vyeVQqld1tmUwGE4uyUVPCzoEakFrJmlFEAL9PVcTvU41fbUuNzJgxA9OmTbPcLioqqnFAin8f9vj3QU2ewLIgrlbrYNSYMWOQn5+POXPmIDs7G126dMGGDRsQGxsLQNyVoWJkvGfPnpbr+/btw9q1axEbG4tz584BAJYsWQKdTofRo0fbPW727Nl49dVXa9vEaslkMpelrjYmO3bswMiRI/Hwww8DAEwmE/766y907NjRzS0jqme2wShmRlE9s2RGGZkZRc0bv09RUxEREQFAzJCKjIy0HK+u1MiNlAXh3weRh+GGSS5Xp0/IlJQUy5rfilatWuVwrLoielJQim5M27Zt8eWXX2LXrl0IDAzEO++8g5ycHHYO5Pls13AzM4rqmcpcwJyZUUSeid+nPE98fDwiIiKwefNmyyS5TqfD9u3b8dZbb7m5dU0L/z6o2bKb/OZ4wxU8L1zfjM2aNQvp6ekYMmQIvL298eSTT+Kee+5BYWGhu5tGVL/YOVADUim4TI/Ik/H7VNN0/fp1nD592nI7PT0dBw8eRFBQEGJiYjBlyhTMnTsXN910E2666SbMnTsX3t7eePDBB93Y6qaHfx/UbNkuK+Xkt0vIBFfu/elGRUVFCAgIQGFhIfz9/e3uKysrQ3p6OuLj46HVat3UQqoP/LclAEDeaWBRgnh90CtA0nPubU8jVdXnZHNU199Hel4xBi7cBj+NEodfc089EKKGxv7Wc1X1b9uU+o1t27Zh4MCBDscfeeQRrFq1CoIg4LXXXsP777+Pq1evok+fPli8eDG6dOlS49fgeKP54b8rWZxPAz76m3h9xLtAwqNubU5jVZt+g5lRRNT0saAgNSApM0rHzCgiokZjwIABVZYGkclkePXVV+ulHi0RNQNcieFycnc3gIjohnE3PWpAUs0og8kjEouJiIiIqDq2k98sYO4SDEYRUdNnW8Ccu+lRPZOCUUaTABMDUkRERESej5lRLsdgFBE1fcyMogakNC/TAwC9iUv1iIiIiDyeJ+zeXVYInNwIGPXubgkABqOIyBPYdQ6l7msHNQtqhbXr1BuZGUVERETk8ewyo5roSoxf3gTWjQEOf+7ulgBgMIqIPIHgIcv0DDp3t4BqQCm3ZkYZWMSciIiIyPN5QmZU3inxMv+Me9thxmAUETV9nrBM78/PgblRwLFv3d0SqobCJhjFzCgiIiKiZsATMqOu54qXJXnubYcZg1FE1PTZFTBvosGos9sAkx4495u7W0LVkMlklqV6emZGEREREXk+T9gw6XqOeFmS7952mDEYRURNn11mVFPtHC6Jl42kc6CqSUXMDcyMIiIiIvJ8QhNfpmfUW8cZxZWMN4SG/V7LYJQHGzBgAKZMmWK5HRcXh9TU1CofI5PJ8M0339zwa7vqeYhqxBMyo6SZiuLGkTZLVVOZM6N0zIwi8nj8PkVUOf59ULNht0yvCY43pCV6gPPJ79zjwPzWwM53G6xJDEY1UiNGjMDgwYOd3peWlgaZTIb9+/fX6jn37NmDJ5980hXNs3j11VfRo0cPh+PZ2dkYOnSoS1+LqFJNfaYCsFnDfcW97aAaUUmZUSYGo4gaM36fIqoc/z6IaqGpr8SQVmEAzmtGZewGSq8Ap35qsCYxGNVIPf744/jll19w/vx5h/tWrlyJHj16oFevXrV6ztDQUHh7e7uqiVWKiIiARqNpkNcicigo2MAppjfMZASKL4vXnXUOuhLg60nA8f81bLuoUlJmlN7QxP6vETUz/D5FVDn+fRDVQlNfiWGXGXXF/v0AgO66eNmAqzQYjGqk7rrrLoSFhWHVqlV2x0tKSrB+/Xrcc889GDt2LFq1agVvb2907doV69atq/I5K6bN/vXXX7j99tuh1WrRqVMnbN682eExL774Itq1awdvb2+0bt0as2bNgl6vBwCsWrUKr732Gg4dOgSZTAaZTGZpb8W02cOHD+OOO+6Al5cXgoOD8eSTT+L69euW+x999FHcc889WLhwISIjIxEcHIzJkydbXouoSrbBKMEIGHXua0tdFOcBgjnDpiTfMZh27jfg0Dpg+1sN3zZySqoZpWdmFFGjxu9T/D5FlePfB/8+qBZMTXwlhlQSBAAgAKUF9vdLRdkbsH6tssFeqTERBPf9B1J5AzJZtacplUqMHz8eq1atwiuvvAKZ+TGff/45dDodJk6ciHXr1uHFF1+Ev78/fvjhB4wbNw6tW7dGnz59qn1+k8mE++67DyEhIdi9ezeKiors1ntL/Pz8sGrVKkRFReHw4cN44okn4OfnhxdeeAFjxozBkSNHsHHjRvz8888AgICAAIfnKCkpwd/+9jfceuut2LNnD3JzczFx4kQ888wzdp3f1q1bERkZia1bt+L06dMYM2YMevTogSeeeKLa90PNnENkvxhQNqGZMtvOwagTZyY0ftZj5UXiJetJNRoquTiXwwLm1Kzx+xS/T1Hl+PfBvw/yLHbL9EoAkwmQN6HcHtvMKEBcjeETbL0tZUaVXmmw99Y8g1H6EmBulHtee+ZFQO1To1MnTJiABQsWYNu2bRg4cCAAMWX2vvvuQ8uWLfH8889bzv3HP/6BjRs34vPPP69R5/Dzzz/j+PHjOHfuHFq1agUAmDt3rsO665dfftlyPS4uDs899xzWr1+PF154AV5eXvD19YVSqURERESlr7VmzRqUlpZi9erV8PER3/uiRYswYsQIvPXWWwgPDwcABAYGYtGiRVAoFOjQoQOGDx+OLVu2sHOg6lUMRulLAAS5pSl1UrFzKM6zD0ZJnYOUNVWDL5hUvyzL9FjAnJozfp/i9ymqHP8++PdBnkVwMt7Q+Dbc65tMQFEW0CK6bo+/lmN/u2IGlJQZJZiAsgLAu/7HUk0olNf8dOjQAX379sXKlSsBAGfOnMGOHTswYcIEGI1GvPnmm+jWrRuCg4Ph6+uLTZs2ISMjo0bPffz4ccTExFg6BgBITEx0OO+LL77AbbfdhoiICPj6+mLWrFk1fg3b1+revbulYwCAfv36wWQy4eTJk5ZjnTt3hkKhsNyOjIxEbm6FQTqRMxU7h6a2jtuhc6hQxFzqHKSsKXI7yzI9BqOIGj1+n+L3Kaoc/z7490E1ZJsZBTR85uNv7wCpXYDDX9Tt8bYFzAHHFRflNmOMBlqq1zwzo1Te4oyBu167Fh5//HE888wzWLx4MT766CPExsZi0KBBWLBgAf7zn/8gNTUVXbt2hY+PD6ZMmQKdrma1cgQnBZ5lFbItdu/ejQceeACvvfYahgwZgoCAAHz66ad4++23a/UeBEFweG5nr6lSqRzuM7EeC9WEQ+fQwDtcGA1AziEgojugqMPHasXOoWIRc53N+ynJt8+aIrewZkZxmR41Y/w+xe9TVDn+ffDvgzxLxfGGroHHG8e/Ey8vHQW6jra/79ol4NOxQK9HgIRHnD9eWokhU4gT+dWNN3CTS5pdleYZjJLJapy66m73338/nn32WaxduxYff/wxnnjiCchkMuzYsQMjR47Eww8/DEBck/3XX3+hY8eONXreTp06ISMjAxcvXkRUlJhCnJaWZnfOzp07ERsbi5deeslyrOJuG2q1GkZjhawUJ6/18ccfo7i42DJbsXPnTsjlcrRr165G7SWqkkPn0MAzFXtWABunA4NfBW6bWvvHOwSjKqbNVpipCIyr/WuQS6nMmVEGZkZRc8bvU/w+RZXj3wf/PsizVAxaNmRmVGkBkP2neF2qJWsr/Vcga5+4iqLSYJR5JUbITcDlE9WPNxoAl+k1cr6+vhgzZgxmzpyJixcv4tFHHwUAtG3bFps3b8auXbtw/PhxPPXUU8jJyan6yWwMHjwY7du3x/jx43Ho0CHs2LHDrhOQXiMjIwOffvopzpw5g/feew9ff/213TlxcXFIT0/HwYMHkZeXh/LycofXeuihh6DVavHII4/gyJEj2Lp1K/7xj39g3LhxlvXbRDfEac2oBnTyR/Ey/7TjfUY98MNzwLHvKn98rdJmKyzhI7eQMqN0DEYRNQn8PkVUOf59ENVATSe/Lx0F3ukM7FvlutfOSANgzjQscxKMkgJUBZnOHy8I1syoMHMwubiSmlFAg22axGBUE/D444/j6tWrGDx4MGJiYgAAs2bNQq9evTBkyBAMGDAAERERuOeee2r8nHK5HF9//TXKy8txyy23YOLEiXjzzTftzhk5ciSmTp2KZ555Bj169MCuXbswa9Ysu3NGjRqFv/3tbxg4cCBCQ0Odbvfq7e2Nn376CVeuXMHNN9+M0aNHY9CgQVi0aFHtfxlEzjjbTc+Z8uvAd/8ATv/sutc26IDMP8TrzjqHzN+BPR8Am1+p/DmumYNRfuZCp5UVFHR2XyOwZMkSxMfHQ6vVIiEhATt27Kjy/O3btyMhIQFarRatW7fGsmXL7O5fsWIFkpKSEBgYiMDAQAwePBh//PFHpc83b948yGQypzv01BelgrvpETU1/D5FVDn+fRBVo6ZlQU5vAYouAAfWuO61z/1mve4sM0rKaiorAMoKHe8vKwQMZeL1sM7iZSPIjJIJzhbzNkFFRUUICAhAYWEh/P397e4rKytDenq6ZbBEnoP/tgQApl2LIN9kM9N2z1Kgx4OOJx75CvjiMSCiKzDpN8f76yLjd2Blsni99QBg/Lf29x//Hlj/ECBXAi/nAnKFw1Pg3R7A1XSg7WAxUNbzYWDkYuv9nz4EnPhevD5kLpA4uU5Nrepzsq7Wr1+PcePGYcmSJejXrx/ef/99fPDBBzh27Jjly6yt9PR0dOnSBU888QSeeuop7Ny5EykpKVi3bh1GjRoFQJzd7NevH/r27QutVov58+fjq6++wtGjR9GyZUu759uzZw/uv/9++Pv7Y+DAgUhNTa1x22/k9/H4qj3YciIXb43qijE3O75PIk/D/tZzVfVvWx/9RlPG8Ubzw39Xstj8CrDzXevtB9YCHYY7nrfpZWDXfwGVDzDjAiB3Qf7P+7cD2YfE6zF9gQk/2t//y5vAr/PF65N2AhFd7O+/fApYfDOgCQCGvgV8MwlocwcwziYL8T9dgEJzZlXiM8AQ+8BxTdWm32BmFBE1eUaD3u52eck16AwmrPwtHT8dtUknl3atyz0hLp9zhfM2QS1nmVHSLIPJAFzLdv4clrTZTuJlZbvpAQ2WNltT77zzDh5//HFMnDgRHTt2RGpqKqKjo7F06VKn5y9btgwxMTFITU1Fx44dMXHiREyYMAELFy60nLNmzRqkpKSgR48e6NChA1asWAGTyYQtW7bYPdf169fx0EMPYcWKFQgMDKzX91mRdZmeR8znEBEREVFVHFZilEAQBGw5fgmnc69Zj0vf6/XF4mTzjbKtFwVUnRkFAAVOdqKUSoL4hgHeweJ185iiVGdE5pUS1owiIqoLo9E+bfang+n4+7JdmPP9MTz1f/vwyrdHoDOYgGJz52DSA3l/OTyPIAgwmWoZXDi303q9/Jrj/bbHnHUO5desab7h5rTZigGnRrpMT6fTYd++fUhOTrY7npycjF27djl9TFpamsP5Q4YMwd69e6HXOw8QlpSUQK/XIygoyO745MmTMXz4cAwePPgG3kXdKFnAnIiIiKj5qLBMz1h+HS9++Sce/3gv/pa6Awt+OoEyvdEajAKQf3Yfisqs328zr5Rg1jdHsOiXvxy+Q14t1mHa+oO4b8lOnLpkM36Q6kXJzCUiSgqwfk8GfjqaI74e4DDeuFRUhg2Hs/Helr+w63QeTNKEvF8E4GMORpVcwc7Tebjj7W1Imr8VhrKGD0Y1z930iMijmCoEo85k5eKQsRC+GiWulxuwOu08/ki/gpcNx3Cb+Zzln3+H9CgD7unREr1iA/HFvgv475a/4KVW4P1xvdE2zNfyfPnXyzHr2yM4mFGAufd1xYD2YeIdRoNYE8pMKC9C+uXr8NEoEe5vTuWuOFMR2xclOgOOZxehbagfAkrNHZbaF2hhXu5Vkg+TScBHu85h5+k8LCkpgiUxvBEFo/Ly8mA0Gh0Kg4aHh1da4DQnJ8fp+QaDAXl5eYiMjHR4zPTp09GyZUu7oNOnn36K/fv3Y8+ePTVub3l5uV3R06IiJzNLNaQ2Z0bpGYwiIiIi8nwVMqM+TzuJzy6KYwKDScDirWewetd5fI4z6CDOWWLNtz/g3a99cUtcEOJCfPDl/gviBDmAX0/l4b8P9oS3WoFdZ/Ix65sjyL0mfk+9b8kuLHqwpzjmMNeLuhzUC6H5e1FcdAUvfnkYAOCtVmBghzDMvJ4LqZDFN9t2Yco30XZtnea7E/8EcLhAgx1/FCAFgO5aLh76YDcAGVQwQClYg2ZCST5krvvNVYrBKCJq8gSDfTDKS1aOnjEtsOjBXjiRXYQp6w/iRM416FU5gLlkkynnCNZd6Ip1f2TCW61Aic7awdy7ZCfeG9sTrUN88OeFQrz2v2PIuy52DhNW7cHsEZ3xSN84ce227joEmRwywYTy61dxx9vbIZMBfeKDcE+PlhhxrRDSxs4HjxzGgj1x2JN+FTqjCWqlHCnxlzAFQKk6GOmFKnQCYCjOw8Mf7Mbus+JyvcuaK4iWeoRGuJueTGbfXQmC4HCsuvOdHQeA+fPnY926ddi2bZulVkNmZiaeffZZbNq0qVb1G+bNm4fXXnutxudXRcqM0nOZHhEREZHH0+l1UNvczryUD41Sjv+O7QmTIGDWt0dx+Vo5gjUFlnM6yzNhNAhIO5uPtLPihPLNcYE4nn0Nf5y7gn7//gUGm1UZbUJ9EOSjxp5zVzFh1R7c06MlXs3eCn8Ay3LaY5ZqL3xRiptjW+BiYTmyCkrxw5/Z+LsqBy3NYxxt8UXIZUD7CH/Eh3hjx195UJddBpTA73kqLMopQIoWUAs6eKEco25th25BAvCL9b1dyLqAfyzeiYV/74a2YX719jtlMIqImjxjhbTZUV0C8fjfE6FSyNGyhRc2Trkd209eRvedOsCcDDMy8irORUTju0MXUaIzItBbhacHtMGmo5ew9/xVPPaRfcZNu3BftI/wx/8OXcTs745i68lcvNxiM9oC2Gtsh5vlJ6CFDt5KE0oMcuw+ewW7z15BqfIYHjN/0p44fgQ7DX0BAAFeKhSW6vHXmTOAGvizyAuT1p7GAS2gLC/E3rO58FZr0DrUB955pZZ2XMnLxo6DWejbJgShfpp6+53WREhICBQKhUMWVG5ubqXbKEdERDg9X6lUIjg42O74woULMXfuXPz888/o1q2b5fi+ffuQm5uLhIQEyzGj0Yhff/0VixYtQnl5ORQKx0LxM2bMwLRp0yy3i4qKEB0d7XBeTaiYGUVERETUbOj1ertgVJsWMnzy9z64OU4sI9G/XRjOXCpEyMrrgDm+NKjFJfz6yEBsOpaDkznXMKxrJAa0D0V6XjFS1uzHiRxxeV2Irxr39GiJ54e0h1wmw8vfHMZney/ghwPpWKg5BsiAbUICZmENFDIBn0/oBkHti0MXCvHT0RyE7NEB5nn1XgHXsPfpOxHkI7a2TG9E3v+tATKAdm3a4KHQDtDv00AllGPN2Lbo1b0rUJBpF4xqIRThYGYBfDWqev2dNqtglIdsHEg2TCYOBAkQKizTC9UYAYW1JF7LFl54sE8M8Jt1q9PI0tP496huePmuTjh2sQgdI/3gp1Xhkb5xePnrI/hy/wWolXJEBXjhzk7hmHpnO2iUcnSO8sdbG09g28nLGKfajLYKYLOxJ26WnwAAHHzhVlw2+eK7gxex4XA2fC6VWV6zneYqXkruiDs6hqF1iA+OXixC5obfgSygXBMCP+8QmMpkkEPAnfFqTB+dhIgALWRvlls6NVNxPp799CA+ffJWtwej1Go1EhISsHnzZtx7772W45s3b8bIkSOdPiYxMRH/+9//7I5t2rQJvXv3hkpl7fAWLFiAN954Az/99BN69+5td/6gQYNw+PBhu2OPPfYYOnTogBdffNFpIAoANBoNNBrX/M6kYJSBmVHUzLDf9Tz8N3Utjjc8C/89SSKVBdELCqhkRtzXJRCIs9Yz9VIr0CXQAAg2n6lFFxDjVYaJSa3tnqt1qC++/8dtOJdfgnB/Dfy09kGft0Z1w/29o7Hrjz8gPyagFFoseOpe4OMXxNpVZUWQafzQI7oFekS3ANIVgLlGeZjxEuBjDZtpVQq0UopjoNt7dcXt3TsDp0KAoiz0CjGPoaT6tHIlYDLAT1aK9x/ognD/+h1rNItglEqlgkwmw+XLlxEaGlrl8hFqGgRBgE6nw+XLlyGXy6FWq6t/EHksqXMohRpe0FkLgtudZAKKL1tvX88BivPg6xOCW+KtHYlGqcCCv3fH6/d0gUYpd/i8mNS/DZI7hWPt7xlI2CsWQb9l4EgIv38Hmb4YasM1tAwKxdMD2uDpAW1QtmYpYK6V3tO/CL1ut3ZGXVoGoEu8HMgCbu/VBb8OvROYHwSU5GPpPbFAsI9Yl0rQWR4TJLuOPnEtEBfsg8Zg2rRpGDduHHr37o3ExEQsX74cGRkZmDRpEgAxGykrKwurV68GAEyaNAmLFi3CtGnT8MQTTyAtLQ0ffvgh1q1bZ3nO+fPnY9asWVi7di3i4uIsmVS+vr7w9fWFn58funSx37LWx8cHwcHBDsfri1JuXqbHQRw1E2q1GnK5HBcvXkRoaCjUajW/TzVx/C7lWhxveB5BEHD58mXIZDK7CTNqngTzSozrMm8E4pr9BkMSqXi5dwig8gYKM4BLR4H4JIdTlQq5XY1aWzKZDL3jgtDbpAWOAdqQWPSKDQI0/kDpFfOOei2tD7AtYF56VdzhW+vv2C5fc91b72CgKMta/kOqcesbIe7+LRgxpLUaqOfPsWYRjFIoFGjVqhUuXLiAc+fOubs55ELe3t6IiYmBXM6NIZszqXMohrcYjNKVOJ5UViDuogcA/i3FD+BLR4HW/Z0+p1blPLsGEGczXh7cEtgrfnAPTkoCDvqJQbAy+6LYWpO1LbLCC2JQzPb/6zWbrVYBsXMoybcWKq8QWJPDhPXjOwLeNa+VVJ/GjBmD/Px8zJkzB9nZ2ejSpQs2bNiA2NhYAEB2djYyMqy7CMbHx2PDhg2YOnUqFi9ejKioKLz33nsYNWqU5ZwlS5ZAp9Nh9OjRdq81e/ZsvPrqqw3yvqqjUpqX6Rk4Y0rNg1wuR3x8PLKzs3Hx4kV3N4dciN+lXIPjDc8kk8nQqlWrSrOuqfmQVmIUw6uKYJT0vT4cCIw1B6OOOA1G1UjhBQCALMAceNKag1EVxhsOO3oXZgLazk7aFSFeeptLY0g7eEvBKI0fYCwXJ/BL8gB/x42FXKlZBKMAcUb9pptuqnTrcGp6FAoFlEolZ57I0jmUyLwAoQDQOwlGSTMC2hZAVE9zMOpIpcGoahVmiZdegYDGV+wcruc4dgblNrvpmfTiOf5RNu2q2DmEADgldgCAfdqsylucCSm5Anhbs7ncLSUlBSkpKU7vW7VqlcOx/v37Y//+/ZU+X12+xG/btq3Wj7kRKnNmlIGZUdSMqNVqxMTEwGAwwGg0Vv8AavT4Xcq1ON7wPCqVioEoAmCd/C6R+YjlM5yNN6RVGL6hQHgX4OQGIOeI/Tn7PhYnodsPrf5FzcEoBLQSLzXmbKfyCsEoKZjkHSKOIQoygHBzMMqot05y+5pruvqEiJfScWm8ofaxvo8G2MG72QSjALHD5YcJkeeRlukVS52Ds5mKYpv01IiuwInvxcyouirMFC9r2jlICjIqCUaZOwcpyOSsc/AKMgej8gC0rXvb6YaxgDk1V9JyFS5ZIXKO4w0izySYJ2GKZd6VjzekyW8f83gDAC7Z1DktyAT+909ApgCe2QMEt6n6RS3BKPOGO9oA8bLMWgcXBh1gNJf0CO8EpP8qjjcsr2m+rvQSJ9EB8+Q3HCe/1T6A0rz6ogGCUczHJaImTzCJnUOJzFs8UFVmlE+YdaYgx6ZzEATg22eAr58Wl9JVxxKMkjoHczDKIW3WHIxSmWcabDsHwBqM8qswU1EsBaPMj1f7WVNqG6BzoKopLcEoLtMjIiIi8nSWzCi5+Tu908wo28lvcx3T3ONidpLt/YIR+OV18bquBPh1IZBpv5M3gJplRtlOfId1Ei9txxt55uK1wW2tpUIqLtOTVnZo/Gwmxq84tsfFGIwioiZPWqZXKgWjnNWMsi3cJwWjLp8QC4QD4gfugf8DDq0Fjn1d/YtWnKmoNDPK/OEe1kG8LDhvvU9fau0E/MxrsisGnKRgltqHwahGRKUwFzBnZhQRERGR5zNJ4w1zMKq68UaLOEChFrOWrmWLx20zmo5+DWTsBj59UAxMffeM4/NVDEY5m/yWxh5KLyDIvFGS7Xgj3xyMCrFZVeEjjSmkAuY2mVEVA1X1iMEoImrypMyoUrl5Rwpnu+kVV+gcVD5i53DlrHi8rMB67tZ5YpCqOB9YPw7YvdTx+WrSOQDWYJKzmYr8MwAEMeVW+uCvGHBy1jkwGOV20jI9AzOjiIiIiDyfNN5QSJlR1SzTk8vFWrUAUFogXtoGowDg4xHA2a3i9csnrI8HxFUbNcmMksYaGl+gRYx43Wlm1E3WY5YxhZNlehXrSdUjBqOIqMmT0mbL5DXIjPIJFTsHaVmc9CFs2znk/wXsXQmsGQ0c/w7YMseaXiuptHOwXcNdbt3BL9ycqmsXjLLpHKTisQ5ruG0zoyrUkyK3UTIzioiIiKjZsI43KmRGnd1u/X5vKWBu3iXbq4V4KU16S+ON8K6AXCVOjCu11o2Mzv1mfcGSK4ChVLzub7ObHmA/+W0ZK1QSjMo/LV6G2AajpLIgzsYbDTf5zWAUETV95qV2ZdJMhbFcnL24es76IWubNgtUP1Px47+Ai+Yd3/QlQPaf9vdXtkyvzMlMBQCEdRQvCzKtx/KcdQ6VZUb52txX/2u4qWosYE5ERETUjJiDUeXSSgxdsVjnafXd4koKwGZjogrjDWmcIV1GdAEGvCgGoR5YA3S+Vzx+fqf19aT6tD5hgFIjXq8yM8rPOi4pvWodk+SdEi9txxtS+xyCUX6OWVP1iMEoImryBEFMmy2TOgdATEldkgisHimmuVqW6ZkzohxmKsyXkT3ED31ADACFmetLZeyyPrfRABRdFK9XXKYnFQAErPWiVN5AULx4vTDTWiA936agoERaw13MZXqNmVQzymDiMj0iIiIij2f+/l6mNE9+G0qB0z+L17MPihPf0nd0nwqZUdLkt3SpDQBu/xfw/Emg7WAgrp943DYzquIqDKCSzCib4uNaf3H3bUAcZ5QWWLO1bMcbUjCqvFCsYWs33mABcyKimjNnRukVXgDMy91OfC9mNF06IgaAbJfpAZXPVPhFAsMWiNuxjv0U6P6AePy8TTDqWra4C4ZcZQ1uVTVTofYF/KLEbVyNOuusibSG21nabEmeGESTOgeNL4NRjYiUGaUzMDOKiIiIyOOZpPGGj/XYmV+s1098DwgmADLrd3bLeKPAfGkeb2gD7J871hyMunwCuG4OHhVliZe2wSin4w1zMEptnpRvdbN4eW6ndYmeX6QYrLJ9HqVWvH49t0IwijWjiIhqztw5QK4UP0QB4PQW6/3ndzmu4ZY6gYrL9LQBQOd7gEm/AfFJQGxf8XhGmjWjyTJT0dK6RWpVa7g1voBCKZ4PAFfTxUCT1EHYFhSUgmVGndhx2a4Db8DdLahqSvO/OzOjiIiIiJoBKRil9IFl8jtrr/X+o9+Ilz4h4vd+wDEzyjLeaGH/3N5B1vqy0lI9aZmetPQOqGQ3PZvxBgDE3y5epv9qU7zcJisKEGvVSmOi67mVjzeE+v2ey2AUETV95mV6MoUCUHmJxzJ/t95/4gdrwEoK9lRWULDiTEVkd3GZXelVIO+keKxivSig+swoAIjoJl5m7BY/+MuLAMis27ACgEprbYNd5+DDmlGNiFrJAuZEREREzYXMPN6AXCWODQBzJpTZuR3ipbRED6h5ZhQAxN1mfh7zUj1ny/Q05sfZbpikqzDeaN1fvDy/C8g9Kl4Paef4etLqjuuX7ANa0njDpLcvP1IPGIwioqbPHGiSyZU2nYPRev9fm8VLbQtrAcDKlulV7BwUKqBVb/G6w0xFNWu4pcCUlBZrO1Mh1YtqESMGoGzZdg7OtlotL3Tc3Y8alJQZpTcyM4qIiIjI45mkyW8loPa2Ho/oKl5KgSnfUOt9lWZGOQlGxVaoG2W7EkPidLxhUzMKEOvdegcD+mLg8JfiMduSIJLKxhtqb+t4qp6X6jEYRURNn7R8znaZHgC0iBUvpW1RfW1mKurSOZxPEy+dzlQ4yYyqOFMhBaMydgOXjonXq5ypqJAZpQ0AZOaPbWZHuZVSKmDOzCgiIiIijycTxMlvue3kNwB0vs865gCs3+OB2mVGWepGHRfHAFWON65Zl9BZyoKYg1FyORCXJF6/Zt5wKdhZMMp2mZ5NMAoAej4M9JlkrStVTxiMIqKmT8qMUijsO4f2w4CQ9tbbdmmz5k6gJp1DTKJ4eX6X+MHvNDPK/DjddcvMicMa7tAOYhsMpcChteIxpzMVzjoHX0CuALwCxdssYu5WaoWUGcVgFBEREZGnk5kzn+SKCpPfsX2tgSTAWhIEqLpGbUU+wUBUL/H6tnnAtRzxurOaUYLROkaoWMAcsC7Vk4RUqBkFVMiMqjCBPmwBMPQtwD/S8XEuxGAUETV50hpumVxlnzYbmyj+SHydrOGuSefQ6mYx6+raReDquUpqRtnsUCF1ChU/2GUya3bUxQPiZcWCgoA1aFYxbRbgjnqNhFLBZXpEREREzYXM2eS3QgNE9ax8vFHTGrWSQbPEy70rAQji80u72wHi68oU4nVpNUbFyW8AiLcJRik09mOWiu10FoxqIAxGEVHTZwlGKQCVzUxFTF/xR+K0c6imZhQgBrikbVJ3vus8GKXUiB/2gE3nUGENN2ANRklqkxkFAGPWAM/+CUT3cXwcNRiVggXMiYiIiJoLafJbrlBZJ4lbJohjANvMKGfL9EoLAEO5tXRIZcGoNncAHe6y3rbduRsQJ7Yr1o1yFkgKag34m1dwBLcVV1dUJLWzMNO60ZNtxlcDYDCKiJo8aaZCbltQMPgmsYCg7UyFXdpsC/GypjMVd7wsXu77yBpssi0oCNSsc6gYjHK6hruKtNnQdkBgLKBUO28nNQiVOTPKYGJmFBEREZGnsy7TU1i/l8fcKl4GtbZ+f7cNRtlmRkmrMSCz1n5yZshca60m25Igkop1ai2T3zbPabsaw9kSPdt2Xkm3HmsKwaglS5YgPj4eWq0WCQkJ2LFjR6XnZmdn48EHH0T79u0hl8sxZcoUp+d9+eWX6NSpEzQaDTp16oSvv/66Lk0joubI3DnI5Arrh6gUhGoRY50Z8HVSM0pfAhh01Qej4m4Deo233vYKcvzAdugcnKTNBsYBATHidbUv4Bfh+Fq2BczLbQqYU6MhBaP0BmZGEREREXk6qYC5TKkCut0PRHYHejxkvlMm1lnqPcE+S0qa/DYZgGvZ4nWNv322U0WBscBt08TrEd0c7684+W0JRlVYYnfr0+JOfwmPOn8daZJemvhWaMRdxBtQrYNR69evx5QpU/DSSy/hwIEDSEpKwtChQ5GRkeH0/PLycoSGhuKll15C9+7dnZ6TlpaGMWPGYNy4cTh06BDGjRuH+++/H7///nttm0dEzZAlM0qpArqMEtdu955gPeHmCYB/SzGgJLENOhVfFoNSFY9XdOccaz0nZzMVlWVG2S7Ts52pCG4r3q5I2hK22MnuFtQoKOXmZXomBqOIiIiIPJ3cvExPoVABne8BnvrVPuuo00jgrv/Yr15Q+4h1ZwGg4Lx4WdVYQ9L/BeDRDcCAGY73acyPLzdPpFdW7ymyGzDpN3HpnzO2k/SAYzCrAdQ6GPXOO+/g8ccfx8SJE9GxY0ekpqYiOjoaS5cudXp+XFwc3n33XYwfPx4BAc5/8ampqbjzzjsxY8YMdOjQATNmzMCgQYOQmppa2+YRUTMkdQ5yuRJoPQB4cpsYkJIkPQdMOyam0FoepLB+mBfYBNOrSpv1ChQ7GbnSftaj4mMrps1W7By63Cdeth7g/HWkzKjiy9a15Q1cUJCqZlmmxwLmRERNgsFgwMsvv4z4+Hh4eXmhdevWmDNnDkycVCCiGrDbTa/GD5JZs6OumoNRXjUIRslkQFw/5wEih8woJysxakLlZR0LAW6Z+K7FbxLQ6XTYt28fpk+fbnc8OTkZu3btqnMj0tLSMHXqVLtjQ4YMqTIYVV5ejvLycsvtoqKiOr8+ETVtlt30atM5AGJnUF5onalQ+wHVPUfHu4Dn/7J2LLa0FYJRzjKjAKDtIGDqMccZCYl3CACZZfmh2DZmRjUmUgFzg0mAIAiQOctwIyKiRuOtt97CsmXL8PHHH6Nz587Yu3cvHnvsMQQEBODZZ591d/OIqJGzTH7XerzRAijJs8mManFjDbGd/DaZAL20isKv8sdUxjfMmmHlhonvWmVG5eXlwWg0Ijw83O54eHg4cnJy6tyInJycWj/nvHnzEBAQYPmJjnayXSERNQuyunYO2gqZUVKRwep4Bzlf662pZKbC2Yd7QMvK12UrlICPzTaucqW4Uwc1GkqF9d9fz+woIqJGLy0tDSNHjsTw4cMRFxeH0aNHIzk5GXv37nV304ioCZBDLAuiUNZ2vNFCvLxai2V6VT6fzXhDmvgGHCe/a8K22LobJr7rVMC84gywK2aFa/ucM2bMQGFhoeUnMzPzhl6fiJquOs9UuLpzqLhMT1fHtFnAWpsKEDsHZt40Kmq7YBSXeBARNXa33XYbtmzZglOnTgEADh06hN9++w3Dhg1zc8uIqCmQm1csKGpb5Fua7K5Nzaiq2I43pJIgdZ24tl2l4YbMqFqN3EJCQqBQKBwylnJzcx0ym2ojIiKi1s+p0Wig0TBTgIjquIYbsHYOV8+Jl66cqQCqzoyqjm8YkHu07o+neqVUWIODrBtFRNT4vfjiiygsLESHDh2gUChgNBrx5ptvYuzYsZU+hmVBiAgAIAhQQJz8VtY6M8o8vqjPzCi1b90mrptSZpRarUZCQgI2b95sd3zz5s3o27dvnRuRmJjo8JybNm26oeckouZDbu4c5HXtHKRleq6cqTCZKq8ZVRNu7hyoatJuegCgY2YUEVGjt379enzyySdYu3Yt9u/fj48//hgLFy7Exx9/XOljWBaEiADY1XGVK2uZGSWtxDCaA9s3PN4wjyvKi2yKl9dhrAE0rcwoAJg2bRrGjRuH3r17IzExEcuXL0dGRgYmTZoEQFw+l5WVhdWrV1sec/DgQQDA9evXcfnyZRw8eBBqtRqdOnUCADz77LO4/fbb8dZbb2HkyJH49ttv8fPPP+O3335zwVskIk8n1YxSyOu4TK/ogvm2C2cq9MUAzBkzdc2MkjAY1ejIZDKoFDLojQIM3ImJiKjR+9e//oXp06fjgQceAAB07doV58+fx7x58/DII484fcyMGTMwbdo0y+2ioiIGpIiaI5PRcrXWNaMq1qR11eR3WRGgq2Tn7ppy8+R3rYNRY8aMQX5+PubMmYPs7Gx06dIFGzZsQGxsLAAgOzsbGRkZdo/p2dO6xfq+ffuwdu1axMbG4ty5cwCAvn374tNPP8XLL7+MWbNmoU2bNli/fj369OlzA2+NiJoLS82o2s5USJ2DNNvh0jXc5pkKmVzcOrW23DxTQdVTyuXQG41cpkdE1ASUlJRAXmHzEYVCAVMVEwosC0JEAACTwXK19sv0WlS4faOT3+bHlxe6IDPKJhhVlxq3N6jWwSgASElJQUpKitP7Vq1a5XBMEKr/oj569GiMHj26Ls0homZOWsNd590tLLddlBlVfs1mDbdfk1zDTdVTKWQo1XOZHhFRUzBixAi8+eabiImJQefOnXHgwAG88847mDBhgrubRkSNnU0wSqFQ1+6x9ZkZJRUwr2sgqakt0yMiamysu1u4ORilMT/eAzoHqp7KvKMeM6OIiBq///73v5g1axZSUlKQm5uLqKgoPPXUU3jllVfc3TQiauwaU2ZUQEvxsvACcDVdvN5clukRETU2cktmVB2X6UlcVlCw0H53i7pgZlSjJwWj9MyMIiJq9Pz8/JCamorU1FR3N4WImhqbAubKGx5vtHB2Vs0FtAKiegEX9wMH14rH6rpMzydELCkimBr/bnpERI2RHGIHoXR3ZpR3kHhZVgQUZIrX69w5MDOqsVMqxOWXDEYREREReTBzZpRRkEGprGUIxdXjDQDoai5vVGgeb9R1rCBXAN4hN/YcN4DBKCJq2kwmyM271sndvbuFTwgQ3gWAAPy5XjxW12V6XoGAtDsgM6MaJWtmFJfpEREREXksczDKAAXUilqGUFw93gCAzvcBsKlJW9fJbwDwjxQvbzRjqw4YjCKips22oKCylgUFK3YGLukc7hEv07eLl3WeqZBbs6MYjGqUVObMKAMzo4iIiIg8l0ksCWKCHMraBqNsxxcyuWsykPwjgfgk6+0b2Qlv0Gygz9P2z9dAGIwioqZNMFquKpWK2j22PtJmO91rf/tGZip8GYxqzJTmLcK5mx4RERGRB7PJjFLKa7lLttpPDEIB4k54cheFYLqMtnmNGwhGtR0EDP03oNTceJtqicEoImrabiQzSqkGVN7W264IRoW0BcK7Wm/fSOcQcpN4GRB9Y22ieqFScjc9IiIiIo9nzowyQg51bWtGyeXWMYYrxhqSTncDcnMx9RuZ/HYjBqOIqGmzC0bVYYNQ2+wojf+NtwcAOo+0ec4bCEb97d/Ag58BN915422qR0uWLEF8fDy0Wi0SEhKwY8eOKs/fvn07EhISoNVq0bp1ayxbtszu/hUrViApKQmBgYEIDAzE4MGD8ccff9ids3TpUnTr1g3+/v7w9/dHYmIifvzxR5e/t6qozDNjBhMzo4iIiIg8lmANRtU6MwqwjjdcGYzyCgR6PixmXUX1dN3zNiAGo4ioabMJBKhVtdxqFbB2Chp/cUcJV7BdqncjmVE+IUC7Ia5rVz1Yv349pkyZgpdeegkHDhxAUlIShg4dioyMDKfnp6enY9iwYUhKSsKBAwcwc+ZM/POf/8SXX35pOWfbtm0YO3Ystm7dirS0NMTExCA5ORlZWVmWc1q1aoV///vf2Lt3L/bu3Ys77rgDI0eOxNGjR+v9PUukAuY6ZkYREREReS5pNz0oLN//akUqYu7KYBQADH8bmJ4JhLZ37fM2EAajiKhpM3cOJkEGpaIOQZv66Bxsl+q5utNpZN555x08/vjjmDhxIjp27IjU1FRER0dj6dKlTs9ftmwZYmJikJqaio4dO2LixImYMGECFi5caDlnzZo1SElJQY8ePdChQwesWLECJpMJW7ZssZwzYsQIDBs2DO3atUO7du3w5ptvwtfXF7t376739yxRsoA5ERERkeez1IyS1y0YVR+ZUYA4YX0jqzDcjMEoImrabNJmG1XnMPQtoOPdQOd7qz+3idLpdNi3bx+Sk5PtjicnJ2PXrl1OH5OWluZw/pAhQ7B3717o9XqnjykpKYFer0dQUJDT+41GIz799FMUFxcjMTGxDu+kbqT/b3oGo4iIiIg8lmC3m14dlulZJr9buKxNnqAOBVaIiBoRS9rsjXYOLg5GxfUTfzxYXl4ejEYjwsPD7Y6Hh4cjJyfH6WNycnKcnm8wGJCXl4fIyEiHx0yfPh0tW7bE4MGD7Y4fPnwYiYmJKCsrg6+vL77++mt06tSp0vaWl5ejvLzccruoqKja91gVlfn/m57L9IiIiIg8lkGvhwqAQajjMr36mvxu4pgZRURNmmC03Wq1Lp2DtLtFC9c1qpmRyeyDgIIgOByr7nxnxwFg/vz5WLduHb766itotVq7+9q3b4+DBw9i9+7dePrpp/HII4/g2LFjlb7uvHnzEBAQYPmJjr6xXQqVzIwiIiIi8ngGg5i9L67EqMPkd4e7gBaxQPu/ubhlTRuDUUTUpBnNwShTXTsHr0DxkjMVtRYSEgKFQuGQBZWbm+uQ/SSJiIhwer5SqURwcLDd8YULF2Lu3LnYtGkTunXr5vBcarUabdu2Re/evTFv3jx0794d7777bqXtnTFjBgoLCy0/mZmZNX2rTqnNwSgDM6OIiIiIPJbRYF2JUafMqJsGA1P+BOJvd3HLmjYGo4ioSTOY6wwZILdkqtRK53uBuCSg50MubpnnU6vVSEhIwObNm+2Ob968GX379nX6mMTERIfzN23ahN69e0NlsxviggUL8Prrr2Pjxo3o3bt3jdojCILdMryKNBoN/P397X5uhLS1r97EzCgiIiIiT2U0SplRCsv3P7pxrBlFRE2awWhTM6ounUNoe+DR713cquZj2rRpGDduHHr37o3ExEQsX74cGRkZmDRpEgAxGykrKwurV68GAEyaNAmLFi3CtGnT8MQTTyAtLQ0ffvgh1q1bZ3nO+fPnY9asWVi7di3i4uIsmVS+vr7w9RV3DJk5cyaGDh2K6OhoXLt2DZ9++im2bduGjRs3Nth7VynNy/QMzIwiIiIi8lRGgzUYVVUpCqodBqOIqEmz7RzqlDZLN2TMmDHIz8/HnDlzkJ2djS5dumDDhg2IjY0FAGRnZyMjI8Nyfnx8PDZs2ICpU6di8eLFiIqKwnvvvYdRo0ZZzlmyZAl0Oh1Gjx5t91qzZ8/Gq6++CgC4dOkSxo0bh+zsbAQEBKBbt27YuHEj7rzzzvp/02Yqc/DTwMwoIiIiIo9lNJp375Yp3NwSz8JgFBE1abbBKAXTZt0iJSUFKSkpTu9btWqVw7H+/ftj//79lT7fuXPnqn3NDz/8sKbNqzfSslAdC5gTEREReSypgLkg48S3K/G3SURNmsE8U2Hixxk1MBULmBMRERF5PJM5GGUCM6NciaM3ImrSTAYdADEziqghSbs36pkZRUREROSxLLt3c5meSzEYRURNmmWrVabNUgOTMqP0zIwiIiIi8lgmczBKYDDKpTh6I6ImTZqpEJgZRQ1Mac6MMjAzioiIiMhjmZgZVS8YjCKiJs1kyYxi50ANS23JjGIwioiIiMhTSeMNBqNci8EoImrSDJbMKH6cUcNSmndv1Ju4TI+IiIjIU5lMXKZXHzh6I6ImzbK7BTsHamBKKTPKwMwoIiIiIk8ljTfA8YZLMRhFRE0a13CTu0jL9AzMjCIiIiLyWIKRk9/1gcEoImrSjEybJTeRCpizZhQRERGR5zKZjOIVOccbrsRgFBE1aQILCpKbqFjAnIiIiMjjCUZOftcHBqOIqEkzsnMgN1GZM6MMRi7TIyIiIvJUJst4Q+nmlngWBqOIqEkTuEyP3ISZUURERESeT+AyvXrBYBQRNWlMmyV3seymx8woIiIiIo8lFTBnMMq1GIwioiaNy/TIXVRyFjAnIiIi8nTWzCgu03MlBqOIqEljZhS5i0opdqEGEzOjiIiIiDyVJRjF8YZLMRhFRE2apWYU02apgSnNmVE6AzOjiIiIiDyVNPnNZXquxWAUETVpgpEzFeQeUgFzg4nBKCIiIiKPZTLXjFJwmZ4rMRhFRE2aVFBQ4BpuamCWYBQLmBMRERF5LME88SiTcbzhSvxtElGTJghiZpSMmVHUUE5tAra+gcjAzgDugo4FzImIiIg8l7ksCBQcb7gSg1FE1KRZCphzDTc1FEMpkH0IGqjFm8yMIiIiIvJYMnMwSsaVGC7FZXpE1LRxq1VqaF6BAAB5eQEAQM/MKCIiIiKPZVmJwclvl2IwioiaNGk3Pe5uQQ3GKwgAoCi7CgAwmAQIArOjiIiIiDySlBmlULm5IZ6FwSgiatqMzIyiBmbOjJKVFQAQg1B6LtUjIiIi8kgyEzOj6gODUUTUpAmCtIabnQM1ECkYZTLAB2UAAIOJS/WIiIiIPJK0TI+ZUS7FYBQRNW2sGUUNTe0NKLUAgEDZdQDMjCIiIiLyVJbMKO6m51IMRhFR08aaUeQO5uyoAEjBKGZGEREREXkiaTc9OSe/XYrBKCJq2swzFewcqEGZg1HB8mIAgIGZUURERESeSRAnHblMz7UYjCKiJk0m1YxSMBhFDci8o16wgplRRERERJ5MGm/IuUzPpRiMIqKmTaoZxWAUNSSvFgCAIHkJAAajiIiIiDyV3FzAXM7MKJeqUzBqyZIliI+Ph1arRUJCAnbs2FHl+du3b0dCQgK0Wi1at26NZcuWOZyTmpqK9u3bw8vLC9HR0Zg6dSrKysrq0jwiak4sy/Q4U0ENyFvMjApTisGo3Gvl7mwNEREREdUXSzCKk9+uVOtg1Pr16zFlyhS89NJLOHDgAJKSkjB06FBkZGQ4PT89PR3Dhg1DUlISDhw4gJkzZ+Kf//wnvvzyS8s5a9aswfTp0zF79mwcP34cH374IdavX48ZM2bU/Z0RUbMgk7ZaZc0oakjmmlFtfXUAgH3nr7qzNURERERUT6yZUZz8dqVaj97eeecdPP7445g4cSIAMaPpp59+wtKlSzFv3jyH85ctW4aYmBikpqYCADp27Ii9e/di4cKFGDVqFAAgLS0N/fr1w4MPPggAiIuLw9ixY/HHH3/U9X0RUTMhY+dA7mAORkV7iRlRDEYREREReSYpGKVQcpmeK9UqM0qn02Hfvn1ITk62O56cnIxdu3Y5fUxaWprD+UOGDMHevXuh1+sBALfddhv27dtnCT6dPXsWGzZswPDhw2vTPCJqhmQmKTOKnQM1IHMB83DzMr1956/CZOKOekREjVlWVhYefvhhBAcHw9vbGz169MC+ffvc3SwiauRkXKZXL2r128zLy4PRaER4eLjd8fDwcOTk5Dh9TE5OjtPzDQYD8vLyEBkZiQceeACXL1/GbbfdBkEQYDAY8PTTT2P69OmVtqW8vBzl5dYaHUVFRbV5K0TkISy76SnZOVADMmdG+QnX4KVSoLBUjzOXr+OmcD83N4yIiJy5evUq+vXrh4EDB+LHH39EWFgYzpw5gxYtWri7aUTUyMkZjKoXdSpgLpPJ7G4LguBwrLrzbY9v27YNb775JpYsWYL9+/fjq6++wvfff4/XX3+90uecN28eAgICLD/R0dF1eStE1MTJBHEXMxYwdx9Xb2qxYsUKJCUlITAwEIGBgRg8eLDDsu158+bh5ptvhp+fH8LCwnDPPffg5MmTLn9vlTIHo+RlBegeHQAA2MulekREjdZbb72F6OhofPTRR7jlllsQFxeHQYMGoU2bNu5uGhE1cnKIwSgld9NzqVoFo0JCQqBQKByyoHJzcx2ynyQRERFOz1cqlQgODgYAzJo1C+PGjcPEiRPRtWtX3HvvvZg7dy7mzZsHk8n5dtkzZsxAYWGh5SczM7M2b4WIPISUGSXnGm63qI9NLbZt24axY8di69atSEtLQ0xMDJKTk5GVlWU5Z/v27Zg8eTJ2796NzZs3w2AwIDk5GcXFxfX+ngFYdtNDyRX0jhWv7z3HYBQRUWP13XffoXfv3vj73/+OsLAw9OzZEytWrKjyMeXl5SgqKrL7IaLmx5IZxfGGS9UqGKVWq5GQkIDNmzfbHd+8eTP69u3r9DGJiYkO52/atAm9e/eGSiX+Y5aUlEAut2+KQqGAIAiWLKqKNBoN/P397X6IqPmxZkYxbdYdbDe16NixI1JTUxEdHY2lS5c6Pd92U4uOHTti4sSJmDBhAhYuXGg5Z82aNUhJSUGPHj3QoUMHrFixAiaTCVu2bLGcs3HjRjz66KPo3Lkzunfvjo8++ggZGRkNV/vDnBmF0qtIiGkBANh3/krDvDYREdXa2bNnsXTpUtx000346aefMGnSJPzzn//E6tWrK30MV2IQEQDIIY43FCwL4lK1XqY3bdo0fPDBB1i5ciWOHz+OqVOnIiMjA5MmTQIgZiyNHz/ecv6kSZNw/vx5TJs2DcePH8fKlSvx4Ycf4vnnn7ecM2LECCxduhSffvop0tPTsXnzZsyaNQt33303FNwhi4iqwDXc7lNfm1pUVFJSAr1ej6CgoErbUlhYCABVnuNSUjBKMKJXhDixci6/BJevlVfxICIicheTyYRevXph7ty56NmzJ5566ik88cQTlU6eAFyJQUQihXm8oWQwyqVq/dscM2YM8vPzMWfOHGRnZ6NLly7YsGEDYmNjAQDZ2dl2yzPi4+OxYcMGTJ06FYsXL0ZUVBTee+89jBo1ynLOyy+/DJlMhpdffhlZWVkIDQ3FiBEj8Oabb7rgLRKRJ7OmzbJzaGj1talFRdOnT0fLli0xePBgp88pCAKmTZuG2267DV26dKm0vS7d+ELlBSi9AEMpAlCEduG+OHXpOvadv4q/dYmo+/MSEVG9iIyMRKdOneyOdezY0W6ZeEUajQYajaa+m0ZEjZxUM4rL9FyrTqO3lJQUpKSkOL1v1apVDsf69++P/fv3V94IpRKzZ8/G7Nmz69IcImrGZFLnwGV6buPqTS1szZ8/H+vWrcO2bdug1WqdPt8zzzyDP//8E7/99luV7Zw3bx5ee+21Ks+pFa9A4FqpuFQvNginLl3H7rP5DEYRETVC/fr1c9jo4tSpU5YJdSKiykjL9JgZ5Vp12k2PiKixkDKjFJypaHD1tamFZOHChZg7dy42bdqEbt26OX2+f/zjH/juu++wdetWtGrVqsr2uny5hU3dqAHtQwEAGw5nw2hyXuuQiIjcZ+rUqdi9ezfmzp2L06dPY+3atVi+fDkmT57s7qYRUSNmNAlQSsEo7qbnUgxGEVGTxoKC7lNfm1oAwIIFC/D6669j48aN6N27t8PzCIKAZ555Bl999RV++eUXxMfHV9tel298YbOj3sD2YWjhrULutXLsOpN3Y89LREQud/PNN+Prr7/GunXr0KVLF7z++utITU3FQw895O6mEVEjpjeaoDCvxFCq1G5ujWfh6I2ImjS5YARkgIIFzN1i2rRpGDduHHr37o3ExEQsX77cYVOLrKwsy25FkyZNwqJFizBt2jQ88cQTSEtLw4cffoh169ZZnnP+/PmYNWsW1q5di7i4OEsmla+vL3x9fQEAkydPxtq1a/Htt9/Cz8/Pck5AQAC8vLwa5s17tRAvS69CrZRjeNdIrPk9A1/vz0LSTaEN0wYiIqqxu+66C3fddZe7m0FETYgYjDJPfnNzNZdiZhQRNWkKFhR0qzFjxiA1NRVz5sxBjx498Ouvv9ZoU4tt27ahR48eeP311x02tViyZAl0Oh1Gjx6NyMhIy8/ChQst5yxduhSFhYUYMGCA3Tnr169vuDfvZc6MKi0AANzXqyUAYOPRHJToDA3XDiIiIiKqFwajYAlGMTPKtZhKQERNliAIkAsmQAYomRnlNq7e1OLcuXPVvqZU9NytLDWjrgAAesUEIjbYG+fzS7Dp6CXc07OlGxtHRERERDdKbzRBa5785koM12JmFBE1WUaTYMmMYs0oanA2BcwBcTfAe3qIAaj/230eGfkl7moZEREREbmA3iRYatRCzmV6rsRgFBE1WXqjdXcL7qZHDU4qYG4ORgHAveZsqH3nr+L2BVuR/J/tLGhORERE1ETpDSYozZPfkHPy25UYjCKiJktvMkEukwoKsnOgBiZlRpVcsRyKC/HBf8Z0R2LrYCjkMpy6dB0Pf/A7lm470ziWFhIRERFRjRmMRihk5u9wDEa5FH+bRNRkGYyCZaZCqWJmFDWwCsv0JPf2bIV7e7ZCYYkec74/hi/3X8BbG08gu7AUc0Z2cUNDiYiIiKgu9AabTWm4TM+lmBlFRE2WwWiyrOFWKBiMogbm5bhMz1aAtwoL/94Nr98jBqDW/ZGBojJ9Q7WOiIiIiG6QQa+z3pAxGOVKDEYRUZOlN1lrRnGmghqcbWZUJUvwZDIZxt0ai9ahPtAbBWw/ebkBG0hEREREN8JglxnFhWWuxGAUETVZBqPJspseOwdqcFIwSjAC5UVVnnpnp3AAwOZjl+q7VfXGaGLNKyIiImpeDAabrHaON1yKwSgiarL0RgEKKTNKxo8zamAqLaDyFq+X5Fd5arI5GLX1ZC70RlN9t8zlFvx0Ar1e34zMKyXubgoRERFRgzGyZlS94eiNiJosg8lks0yPMxXkBoHx4mXO4SpP6xEdiBBfNa6VGfD72StVntsYbT1xGYWlehy6UODuplA9OZBxFZPX7seFqww4EhERSewyozj57VL8bRJRk6U3CJYC5gxGkVvE3SZepu+o8jSFXIZBHaSlejn13SqXKywVv4iVlBvd3BKqL2t+z8APf2bjx8NN7/8nERFRfTGag1EGKACZzM2t8SwMRhFRk6U3GqGSSTWjmDZLbhB/u3iZ/mu1p9rWjRIqKXjeWBWZg1HFOkM1Z1JTVaY32l0SERG5lb4M+PMz4Lp7N38xGsXvPiaGTlyOv1EiD6UzNL26NLVlMNgMmpgZRe4Q1w+ADMg7CVyrujj5bTeFwEulwMXCMuzPKGiQ5rmCwWjCtXLxi1iJjoEKTyXVMmuKNc2IiKgR27UI2DSr0p2HK3X4M+CrJ4Ctb9ZPu2pIyowyyTjx7WoMRhF5oC/2XUDHVzZi45Hs+nuRyyfFGQs3MnINN7mbVyAQ0VW8fq7qpXpalQJDu0YAAN7edLLJZEcVlVmzoYrLmRnlqQxG8f+jztg0/l8SEVETYDQAm18Bdr0HFJyv3WOvnhMv80+7vFm1YTRPfhvBYJSrcfRG5IH+SM+H0STg/V/PVn3iplnAB3cC+tLavcC5ncDiW4ANz9W9kS5gMNrubsHMKHKTWizVmzq4HdQKOXadyce2k+5NO68pqV4UwMwoT6ZjZhQREblaST4gmL87FGbV7rHFeeLltXqcXK8Bk1H8HiRw4tvl+Bsl8kAl5QZEIB8HMq7i7OXrlZ+4/2Pgwh/AxQO1e4FLR8XL7EN1b6QL2GVGMRhF7lKLYFR0kDce7RcHAJj343EYmsDA3zYYxcwoz8VlekREVCv5Z4Ad7wC64srPKc61Xi+6WLvnl4JRRdm1X+LnQtZlehxruBqDUUQeqF/+F9it/Qfulf+Grw9UMgthKAfKCsXrte0cSqSZCvfuumQw2GZGMXWW3CQmEZApgKvpQEFmtadPHtAWAV4qnLp0HV/su9AADbwxzIxqHvTm5XkMRhERUY1sfwvY8hpwcG3l51y3qadZVMvMKGm8oS8Gyotq377ayD4E7F4KmBz7QKN5vMGaUa7HYBSRBwovOwMAuFV+HF8fyILJ5GQ24boLZiqKLwNGfdXn1iOT7WuzgyB30foDUT3F69XUjQKAAG8V/nFHWwDA+7+ebfS1o+wyo7ibnseSsvR0hsb9/5GIiBqJkiviZc7hys+x3QmvruMNQMyOqk/f/QPYOB34a5PDXSaT+N1HYOjE5fgbJfJACqNYWLyN/CIuXC3FnnNXHE+6kbTZEpvOwY3ZUQYpbRZyQM6PM3Kj1v3Fyx1vA6UF1Z7+wC0x8NUokZ5XjLQz+fXbthtUWKKzXC8pZ2aUp9JZCpgzM4qIiGpAqjl7+UTl59iNN+pYMwoArtVyrFIb+lIg54h4/dIRh7tNRmZG1RcufCTyQEpzMKqd/CIAAev3ZuKW+CDIZDIAQG5RGVoUXoJaekCtOwebwfO1HKBF9A23uVIHPhG3hH1wPRAYa3eXJW0WckbWyb36PA0cWi/u+PLFBODBzwBF5V2sr0aJe3pG4ZPdGVjzewb6tg1pwMbWjt0yPT0zozyVpWaUgcEoIiKqnklfAjkAfc4x/HgwC61DfdE5TANdeSk+O1KE/x26iGf0x2CurImyKxdw4Ew+QnzViGzhBQDIu1aOUr0RMUHe8NHYfG8y6IDyQuttJ5lRgiDg1KXr2HYyF6dzr8NPq0KgtwpdWgUgsXUwtCpr8EhvNGH7ycsoKNUjPsQbrUN8EehjHgnlHLEUWRcun8Tla2UwGAUo5DLojSZcvVYi3sdglMsxGEXkgVQmMRjlj+sIwjV8tT8LWVdLcXePKHy57wL2ZxRggtcOvGI+/9rlTGzefwGxwT7oHOUPrUoBQRBgMAlQKZyEeewyo6pOmzWaxA/zOtu9DLh8HDj6NXDbFLu7TOZglFGm4IcZuZdvKDB2LbDyb8CZLcCPLwB/+zegVFf6kAdvicUnuzPw09EcXL5WjlA/TQM2uObsglHMjPJYLGBORES1kXflKsIAqPTX8Oanv+ASgrDCaxGShL14v3wBLgihyFdlAuYYTuGlcxi7YnelzxcVoEW7CD90iPCHv+EyUmzue/vL7fjgq2DIZYBMJoMgCDAKAsr0zvssjVKOhNhAxIX4wFulwHeHLiL3WrndOdFBXugVE4jB137ACPOxE4f3YOieLXbn9ZFl4wkNILA+rctx/EbkgVQm64ftzFuUeGm/HMfTM2A8twv7hQ4AAK0uH1CJ51y7fB7TPhN3xlPKZfDTKlFUZoBJENA21BfdWrVA15b+6NwyAP5aFWILL0Frfv5Nuw/gz8z2KNMbYTAJCPXToFWgF9LzirHp6CUcyy6CSiGDj0aJzlH+GNolEsmdwhHqp4FMJsORrEKs+f08cgrL0DbMF+3C/dA9ugXahvpCbiwTA1EA9JdO4PiFAugMJigVchhNJpy9LM6YcA03NQqR3YF7lgKfPwLs/RA49xswfKF1t70KOkX5o2dMCxzIKMBnezMxeWDbBm5wzbBmVPMgZURxmR4REdWETFqmB2BEZCG+zA9Af9PvUMuMGOidjqikJHTeUw6YN9sLRSHaBmuQW2xEUZn4fcJbrYBaKUdBiR4XC8twsbAM205eRifZOaTYzNGF4gpK9Y4TYhqlHIltgtErJhAlOiNyr5Vh95l8XCwsw64z+dhlUwohxFeNduF+OJ9fgqyCUmReEX9uU+6zREXihCzIZSYo5UoYBQFKuQwhWjlgAHy9tA6vTzeGwSgiD6QWygBzMtLo2BIk3nEXrnx4P7pe+xVfdFmKfnfei5JvNwBnxXPCZQXoGx+AU5fLkHe9HFdLrIPPv3Kv46/c6/hyv3hbBhNOawosz3/67GksOnW6yvbojQIKSvTYeTofO0/n4+VvjiDAS4VgHzXO5lm3g9160lrk0E+jRH+f81hkLhp45NAe3Ltnp93ztpZdxFQN13BTI9L5HsD0IfDji0DeSeDjEUDCY8CQNwG1j8PpD/WJxYGMAny08xyulRnQOtQHd3QIQ4hv48mSYmZU86A3cTc9IiKqOZVQZrn+8i0yvBAaAPUn4veEV27zgWpAG+BYqSUYJZcJ+PmJ9kCLaFwvN0AuA7zVYjjiarEOZy5fx4mcazieXYSYgmzgvPW17m+vwIBhAyFAgCAAirJ8hH03DopWvaC8+z927ZKW7x3OKkRGfjEuXy9H3zYhGNI5AmqlOIFdVKbHocwCHMoswIC9FwFxJR68ZDocn9YZmtDWYtmFK+nA7c8DnwJemsqz3aluGIwi8jBGkwCNoLMEi5B3Ci27K9CybC8AYHTkZSDAC/CyBoEUMGHt2NYQ/CKRXViG6+UG+GvFtKmjFwtx6EIhjmYV4lh2EYSSPChk1t2WbgvX41JMLLRqBRQyGXKKynDhaimCvNUY1DEMt90UAkEArpbo8OupPGw4nI3DWYUoLNWjsFQPlUKGYV0j0Ts2EGcuF+N4dhEOZxXiWrkBLQzHLNlbbWRZCPFRw1erhN68jruj2gcoANRqdg7UiHQdDbQdBGx5XcyQ2vcRkL4d+PvHQGQ3u1Pv6haJuRuOI+96OZZtF3fBVMplGNQxDI/1i8etrYMBAKdzr2P+xhMY1DEMY26OadC3U1BinxklCIKl/hx5DusyPe6mR0RE1VPbrMRA7nGoddaxhepapnjFtoA5IG6a1CIavhr7MESgjxq9fYLQOy5IPPDnCbtglLb0EmKCva0HvpsO5B4E8o4Aw/4NKK2TeDKZDO0j/NA+wq/StvtrVUi6KRRJcb7AjnTxoE8oUHwZmqunAbUGOPKlePziQfMTc/Lb1RiMIvIwpXojtDLr7lfI+wu4eADQm0P+BRnipe1WqwBQlA2ZfxSizAUFJREBWgzqGG49cPkksNh6s1tAKbqN7GI9YDKKWSG+YUDvFyyHo1p4oXNUAJ4e0AalOiPO5RfjYkEpurYKQJiffdqrwWjCX7nXEfzz14A4Poe/rBR7n+0C+EeKBdRL8gFjKLAMUFZRKJrILbwCgbveATrdDXyTAlw5K14+/ZvdaVqVAl9MSsSvpy4jPa8YBzIL8OeFQvx09BJ+OnoJ9/duhdvbhWLGl4dxrdyA7acu485OEQjyabgArG1mlEkAyg0mu6Kg5BmkZXrMjCIiomoJAjSwCUZdPgEUZlpvXz0PGA3WHfGC24qbvNR00ySpPm1Qa/E7lG0B88w9wP7V4nWTQXze8M51ex9S8XKfMCCun1ij9vIJoNRmJ/K8k+KlnOMNV+NvlMjDlOgM8LLtHPJOAed2WG9LwShppkImBwSTuXNIqP4FbLdZBRx3t9i3CtizQrze5ylAG+DwFF5qBTpG+qNjpL/Tl1Aq5OJ914/b33H5hBiMWvcAcHE/MOoD8Tg7B2qsWg8AHvsReLcbkHtM3B2mQlHz1qG+aB3qa7l9IqcIH+86j3V/ZOCzvRfw2d4LAACZTAwErfsjo0HrSxXZBKMAoLjcwGCUB5IyonTcTY+IiKpj1EEBm/4i94Q4npAUZIgTxxDEsUZEV3Mw6mLNnr/YPGke0U0MRhXnisEtmQz4YZr9ubnH6x6MunhAvIzqAYSKdXWRd1J8TkneX+Ilxxsux6q/RB6mpNwIL9hkRhWcB85stbktZUaZg1Eh7cTLmnYO0kyFV6B4eS3H5r4rwC+vW29fPlnzhlekL7V2BJHdxcu8U+LrXfhDnAm5IC49BHe3oMasRQyg9hVn3q6mV3t6hwh/zLuvKz57KhHxIWKdqbG3RGPevV0BAP+Xdr5Bs1cKKwSjSnSsG+VpBEGA3sTMKCIiqiFpxQUAQSYHdNcAfTEgN9fXKLxg3XHbOxgIiBavS+ONggzHCW5b0n2hHcTlcYIJuH4JOPB/QM6fgCYA6HCXeM6lo+JlyRVgzf1A2hJAqOGS8+yD4mVkDyC0vXg99wSQ/qv1nHxzbVyON1yOwSgiD1NSboC3TMqMkokf3udtlgYVZACGcqCsQLwd2UO8rGnarNQ5RIgDY5QXAtIa8W3zgNKr1nNzK2Q21calo+Lg3TsEaHOHeOzySSDdJstLCnaxc6DGTCYT09MBMaBaQ7fEB2HjlCRsfX4A5t7bFff2aokQXw1yisrw45Gc6p/ABfRGE4rNwSeVQqwTxR31PI/RJFi+t7NmFBERVcdQJn731wsKmALbWO9oc4eYQWTSi0EjQFwC599SvF6UJa6qWHwr8P7tQPk15y9QYt4FzzcM8IsQr1/LBv78XLyeNA2I7y9el8Ybh78A/voJ+GkG8NWTgL4M1ZLqQUX1BELMwajsg0DRBes5RvMkP8cbLsdgFJGHKSuzFg+0ZD0BgLYFAJk4k5F7TDwmVwLhncTr1yost6uM1DkExonZHoCYrXTpGLDnQ/F2VC/x8vIJ6+OK8wGjfYZFlWzTZqXOIe8UcM5mpkIa2DNtlhq7kJvESynVu4Y0SgXiQ3wgk8mgUSrw8K1i8fIVv57Fb3/l4fez+Sg3WDOV9EYTdp/Nh9HkmoCC7RI9qbZbMXfU8zi2AShmRhERUXVKi6+Ll1ADYR2sd8TdBgS0Eq9LKxh8wwD/KPF60UXgxPdiFlVRFvBbqvMXkJbp+YQAfpHi9bxTQOZu8XqnkUBYR/G6NK6xLUty+DNg9d1ieYTK6EutY5WoHkBwGzELy7yTN3wj7M/neMPlGIwi8jDlpTbBKNudu+Jus3YEUufgE2ozU3FRXIv98d3Aqrsq//CWMqO8Q+xnKvauFDOZOtwF9H5MPC51DlfOAu90AJYkAvlnavZGbGcqQs1Btcsn7dNmpSWH3N2CGrtgczBKSvWuo4f6xEKtkONwViEe/vB3jFm+G/9cdwCCOa3lhS/+xAPLd2P+TyeqeaaaKTAHo/w0SvhpxS9hJcyM8jg6mwAUg1FERFSdklIpGKWBQprYBoDYfmJ5AqBCMMpmvHHie+v5aYvEJX0V2Y43/M3BqEOfioGioDZAUDwQZn7dgvNihtX5XeLtO14GNP5A5u/24wa7588HPn1IHLv4RYo/So34vJIeD8K6PTkYjKoHDEYReRgpGKWH0lqIDwDikqydQ9Y+8dK3Qtpsxi5xC/pzO6xFyCuSakbZzlRcywHO/CJe7/GgtXPINQ+IT/0kprjm/wV8MAg4Z7+jmFO2a7ilDK/iXODqOZuTzLP57ByosQuRlunVLjOqolA/DaYP7YCOkf5oH+4HpVyGn45ewtcHsvDT0Rx8fUBcbvvhjnSczr1+o6221Ivy91LBx7wNMzOjPI9tAIoFzImIqDrlJeLyunKZxjreUHmLE+EtYsXb0qS0T6h1QvxatnUcENoBMJQBW+Y4voBlvBEK+Jkfm75dvGw72HxfMOBr3vH72LfiY5ReQN9nxd2MAfsVFZKsfcD7ScCZLeL5wxaIJRWkNkluSrbWugI4+V0PGIwi8jD6MnEAqpNp7JfpxTmZqfAJs842FGWLH+SS7W+JhQArssuMMj82Yzdw5Yz4IR2XZC0AeD1HfA6p01H5iDWl/u/eqjOkirKt67+jegAaP2vQDLAGuyRcw02NnfS3mH9jwSgAmHBbPH58Ngk/Tb0dU+8Un3f2d0fx0teHAQB+WiUMJgGvf3/MkjFVV1IwKsBLBW+1+HdWqmdmlKcx2C3TY80oIiKqWnmJNN7QAm0Girve3fo0oFBZg1HSpLFvmPgjU4iZSCaD+F3+3mXi/X+uB05vsT65QQeUFYrXfWwyoyRSMAqwjgn+WC5eRt8s7locd7t4u2Jm1KlN4gqQoiyxnucTW4COI6z3S2MYlQ/QMgEIbm29j+MNl2MwisjD6KWCgnKtWGRcJhfXPId1tgajpAGxb5g1oGQstxYF1PiLncD2+Y4vINWM8gm2LtM78oV42epmQOsvBo+kmYTcY8D5neL1B9cDLXuLWVInNzh/A5dPAh8mi51VSDtrEMo2sNZ+mBhIk7BzoMYuyFzcs/SqmBruIk/d3ho9olvgWpkBedd1uCnMF19M6guVQobtpy7jlxO5N/T8RTbBKB81M6M8lZ7L9IiIqBZ05slvvVwr7rA9aQcw6BXxzsBY+5N9w8Xv6n42QaUOd4mlOHo+LN7+9EFrQEoaa8gUYs1b28cpNOIEu0QKRmUfEi9jbxMv45Osx0sLxOsH1wLrHhDr57YZBDyxFQjvbN/WVreIl23vEINaQTbF2bkSw+UYjCLyMJbdLeTmdc/jvhZ/5HJrMEriEyquj/YJFW+XF4qBqFEfiLf3rLAutZPYreE2p81KO+hJu94B1jTXI1+J96t9gZhbxYKDgP2ueJJzvwEf3gkUZogf/g9+ZpM22956XnwSEGQ7U8HOgRo5tbc1QOuC7CiJUiHH2/d3h1Ylh0Iuw4K/d0f7CD88fpv49/Hq/46iqKwWGwdUIGVGtfBWwVsjBn2bS82orSdzXbLUsSmwrRllMAkwuagAPhEReSZp8tsg1zje6Wy8AVjHDQDQYbh4OfwdoN3fxOV668aKASlpiZ53kDh+sQ1GxfYF1D7W2+EVVkvE3WZ9reCbzLuK7xJXZHz7jDjZ3X2sOEGu9Xdse7sh4rhpxHvi7WDbYBQnv12NwSgiD2MsLwEAGBRe4oHWA6wf1C0qzlSYs4tsP+Tb/U38IL5piJhG+8ko4Eq6eJ8g2GRG2RQwl7QZaL0u7azx53rxMuZWMXVXmqnISBMLpkv2fgSsHilmZLW6BXh8s30RQSkzSqEGovvYdw5cw01NQbBr6kZV1CbUF99Ovg3fpPRDj+gWAIBn7miLVoFeyLxSihc+/xOCIMBoErD7bD7OXK55gKWgpHlmRp3PL8ZjH+3BM2v3u7spDaJiNpTexOwoIiKqnKGswnjDVmXjDSkYFRADRHYXrys1wP3/B7QfLq7S+OE5m530nASxbJfoAdYd9QAxa6plgvV2vM1SvZ2pYiCqzSDgnqXimMQZmUycXPcOEm8zM6peMRhF5GGMulLxUqF1vNNhpkLqHGzqMUkF/0YuEgNARRfEtdVX0sVAkcmcZWFbMwoANAFAVC/rbSltVmce+MaaU2ojugHaAKC8CMgxp9Rung18P0UMfnUZBTzynbgM0FZ8fzEQ1fFuQOVlH6hi5+BWS5YsQXx8PLRaLRISErBjh5OsNxvbt29HQkICtFotWrdujWXLltndv2LFCiQlJSEwMBCBgYEYPHgw/vjjD7tzfv31V4wYMQJRUVGQyWT45ptvXP22XC9E2lHPtcEoAGgf4YeurQIst301Six+sBdUChk2Hs3B7O+OYvh7O/DA8t0Y9PZ2jF66C5/tybRkPlXGWc2o5pAZlXutHACQU1Tm5pY0DEOFOlEsYk5ERFUxlouZUSalk/GGb7gYGJJI4w1pYrnT3daVD4C4HG7UCrGY+NV063I9b/NYwC8Sll3t2g6yf63QDtb7Wt0MqGzaIwWjTnwPHFwnXu//ov1rVyeYwaj6xGAUkYcx6cydg7NglH9LsYaUpOJMhcrHOuPgGwY88j8xxbXoAvDZeGtWlNpX/LC3DUbFJwEKmw9p290oALGwOSCmuEqBqfQdQM4RcbYCELdiHfWhGGyqKKQt8Pwp4J4l4u0gFhRsDNavX48pU6bgpZdewoEDB5CUlIShQ4ciIyPD6fnp6ekYNmwYkpKScODAAcycORP//Oc/8eWXX1rO2bZtG8aOHYutW7ciLS0NMTExSE5ORlZWluWc4uJidO/eHYsWLar39+gyweZgVN7pBnm57tEt8PJwMSi8Ou08TuRcg69GCYVchr3nr+KFL//EzW/8jIkf70XmlRKnz2G7m563lBml8/zMqFLzeyxtBu8VsF+mB7CIORERVc2oE783mJROvrPL5UALc2kCmVxcTQEAfZ8B7l4kft+vSO0DtEsWrx/4RLyUHqfxBYbMFWtSVRxfqH2AwDjxum0tKcA69ijMFCfTY28DYvrU/E0CYpaXtAJDxtCJq/E3SuRhBHNmlOCsc1CqrdujAtZglLR8qP3f7ANBfhFiQEquAnL+tBYit8xU2CzTs60XBdjXeFL5iLviSaTO4dwOYOe74vVO9wC3/6vq2QqvQDGdF6iQNstglLu88847ePzxxzFx4kR07NgRqampiI6OxtKlS52ev2zZMsTExCA1NRUdO3bExIkTMWHCBCxcuNByzpo1a5CSkoIePXqgQ4cOWLFiBUwmE7Zsse60MnToULzxxhu477776v09ukyI+e+sHjKjKjM+MRZ/T2gFhVyG8Ymx2PHCQOyafgf+NaQ92oX7Qmc04efjl/CvLw45fbxtZpSPVDOq3PMzo8r0YhCq3GCCsRnUT9IbKgajmBlFRESVE8zBKDgbbwDW1Rjewdbv6doAoNc455POAND5XvGyrEC8lJbpAUBiCpD0nPNxQpf7xInyLqPsj/sEA+FdrLeTplX6fiqlVFvfCzOjXI7BKCJPoxc7B6GyD3rbpXpS2mzCo8DQBeJPRf6RYt0pQKzrBFhnKpQacYZCqQVuutP+cWof65pxqV6URKobdW4ncMScEXPb1Grfmh0u03M7nU6Hffv2ITk52e54cnIydu3a5fQxaWlpDucPGTIEe/fuhV7vfMlYSUkJ9Ho9goKCXNNwd5Eyo66cBYx1LypeGzKZDPNHd8OxOUMwZ2QXBPqoEe6vxeSBbbFpan98O7kfFHIZdp+9ghM5RQ6Ptytg3pwyo/TW91im9/z3WzETisv0iIioSubJ70oDS9IYwHb36+rclAyovK23vUNq9rhBrwAzLthPhEukpXqRPRwnzmtKWqrH8YbLMRhF5Gn01XQO0narMoWYaQSIO331edKxTpNEqiN10VzM17ZzePhL4MltjvWoACCiq3gpBZ8kYZ0BryDAUGouJniHfeZUTWgDrO1gAXO3yMvLg9FoRHh4uN3x8PBw5OTkOH1MTk6O0/MNBgPy8vKcPmb69Olo2bIlBg8e7PT+miovL0dRUZHdT4PybynOIJoMwNXzDfayMpkMGqXzv5Hu0S0wpLP47/HxrnMO9xeWOMmMagY1o2wDUCXNIPhWsWA5M6OIiKhKBnNmlNrb+f3SuMA31Pn9zqh9xICUpLJxiTOVrazo+0+gx0NimY/a1IqyJa0gqazoOdUZg1FEnsZgLrhbXWaUT6i4prsm2g+zXyftYxOMCmhlv5OFrUGzxaV3tzxlf1wut1/XXdusKIllpoLBKHeSVejcBUFwOFbd+c6OA8D8+fOxbt06fPXVV9BqndRBq4V58+YhICDA8hMdHX1Dz1drcjkQai7eeeGPqs9tQI/2FbMMvz6QhYISnd199gXMm89uera1oppFZpTDMj3PX5pIRER1JzOvxJCrfZyf0G6IWBqk08jaPbG0VA+wX6ZXV/6RYiAqvHPdn6PXI2KQrNv9N94essNgFJGHURjEzCi5K2cqfEKsRccBa82o6oS2E4sUOmtL64HiZcve1hpStSUVMWfarFuEhIRAoVA4ZEHl5uY6ZD9JIiIinJ6vVCoRHGz//2rhwoWYO3cuNm3ahG7dut1we2fMmIHCwkLLT2Zm5g0/Z621Hy5e/rm+4V+7EjfHBaJTpD/K9Cas32P/O7GrGdWMdtMr1VuDM80iM6pC8ImZUUREVBW5efJboakkGBXeGXjuONB7Qu2e2HapXm2W+NWn8E7AQ58DUT3d3RKPw2AUkYeRG6sJRrUZBIS0B7o/WLsntp3Z8KnhGu6q9HoEGP4OcP/quqfNSsEops26hVqtRkJCAjZv3mx3fPPmzejbt6/TxyQmJjqcv2nTJvTu3RsqlfXfccGCBXj99dexceNG9O7d2yXt1Wg08Pf3t/tpcN3HiJdntwOFWVWf20BkMhke7RsHAPjwt3QcySoEINYNkmonBXip4K1pPplRttlQpc0hM6pC8Kni7npERES2FObxhkJTyXijrtTewIj3gD6TgOha7nxHTQ6DUUQeRmmUZioq6Rz8I4Fn/hB3paiNDsOt12taULAqCiVw8+NAQMu6P0e3MUDbO4Fe42+8PVQn06ZNwwcffICVK1fi+PHjmDp1KjIyMjBp0iQAYjbS+PHWf59Jkybh/PnzmDZtGo4fP46VK1fiww8/xPPPP285Z/78+Xj55ZexcuVKxMXFIScnBzk5Obh+/brlnOvXr+PgwYM4ePAgACA9PR0HDx5ERkZGw7zxugqMM2cZCo0qO+ruHlGIDvJC7rVyjFy8Ewt/Oom9565Y7vfTNq/MKPuaUZ7/fisGnyou2yMiIrIljTdU2koyo25Et78DQ9+qeTkRarLq9C+8ZMkSxMfHQ6vVIiEhATt27Kjy/O3btyMhIQFarRatW7fGsmXLHM4pKCjA5MmTERkZCa1Wi44dO2LDhg11aR5Rs6YyiZ2DsrK02bryj7LuqldZjaiGFhgLPPyFdacManBjxoxBamoq5syZgx49euDXX3/Fhg0bEBsrFsrPzs62CxDFx8djw4YN2LZtG3r06IHXX38d7733HkaNsm7Hu2TJEuh0OowePRqRkZGWn4ULF1rO2bt3L3r27ImePcWU6WnTpqFnz5545ZVXGuid34DuD4iXhz4FhMZRm0erUuDrlH4Y1jUCRpOARVtP48EPfgcA+GuVUMhllsyo5rBsrbntpmdwWKbXOP5fEhFR4ySNN+olGEXNRq0Lraxfvx5TpkzBkiVL0K9fP7z//vsYOnQojh07hpgYx9200tPTMWzYMDzxxBP45JNPsHPnTqSkpCA0NNQy+NDpdLjzzjsRFhaGL774Aq1atUJmZib8/Pxu/B0SNTMqUzkgB5T10TmM/kjclr5lL9c/NzVZKSkpSElxnmm3atUqh2P9+/fH/v37K32+c+fOVfuaAwYMsBQ+b3I6jQQ2/AvIOwlcPNBo/p5CfDVY8lACfvgzG6t2peNkzjUUlRlwc1wQAFgyo8oNJhiMJigVnjtjaVvAvDkE3you02PNKCIiqopKKAcAaLx83dwSaspqHYx655138Pjjj2PixIkAgNTUVPz0009YunQp5s2b53D+smXLEBMTg9TUVABAx44dsXfvXixcuNASjFq5ciWuXLmCXbt2WWqGSLPqRFRzBqMJanPnoHZ1ZhQAeAeJP0RUd9oAoMNdwJEvgB1vA3//WFy22kgM7xaJ4d0iIQgCrpboEegt9steauuulSV6I/w9ORhlWzOqGQajWDOKmoN58+Zh5syZePbZZy3jFCKqGY1QDsgAjTeDUVR3tfomqdPpsG/fPiQnJ9sdT05Oxq5du5w+Ji0tzeH8IUOGYO/evdDrxV16vvvuOyQmJmLy5MkIDw9Hly5dMHfuXBiNnv8FkMiVSvRGaGXi1uxqb6bNEjVatzwByOTAie+Bz8YBuhJ3t8iBTCZDkI8aMvMGA2qFHEq5eL3Ew4uYl9nsptccCpg71IxiMIo83J49e7B8+XKX7NRK1NyUG4zQQpz81jIzim5ArYJReXl5MBqNDlt2h4eHO2zVLcnJyXF6vsFgQF5eHgDg7Nmz+OKLL2A0GrFhwwa8/PLLePvtt/Hmm29W2pby8nIUFRXZ/RA1d6U6I7zMnYPLa0YRkevE3AqM+QRQaoGTG4D/uwcoK3R3q6okk8ngbc6OKvbwot5lzSwzyrFmFINR5LmuX7+Ohx56CCtWrEBgYKC7m0PU5BSXW8cbXsyMohtQpxx7WYVt2AVBcDhW3fm2x00mE8LCwrB8+XIkJCTggQcewEsvvYSlS5dW+pzz5s1DQECA5Sc6Oroub4XIo5TojPCCmBklU3m5uTVEVKUOw4Fx34jL9jJ/Bz4ZDZQ17okVH6mIuYdnRpXqm3nNKEMTrcdGVAOTJ0/G8OHDMXjwYHc3hahJKi43WCe/WcCcbkCtglEhISFQKBQOWVC5ubkO2U+SiIgIp+crlUoEBwcDACIjI9GuXTsoFNZ6FB07dkROTg50Op3T550xYwYKCwstP5mZmbV5K0QeqbjcYFmmBwajiBq/2ETgkf8B2hbAhT+ANaOB8mvublWlmktmlG02VHPYTa/iMj3WjCJP9emnn2L//v1O69w6w5UYRI6ul5RCLTP3jSpv9zaGmrRaBaPUajUSEhKwefNmu+ObN29G3759nT4mMTHR4fxNmzahd+/elmLl/fr1w+nTp2EyWb/8nDp1CpGRkVCr1U6fV6PRwN/f3+6HqLkr1VvTZtk5EDURkd2B8d9aM6Q+ewQwNs5gjyUzysODUWXNLTOqQiaUzsBgFHmezMxMPPvss/jkk0+g1Wpr9BiuxCByVFpy3XqD4w26AbVepjdt2jR88MEHWLlyJY4fP46pU6ciIyMDkyZNAiBmLI0fP95y/qRJk3D+/HlMmzYNx48fx8qVK/Hhhx/i+eeft5zz9NNPIz8/H88++yxOnTqFH374AXPnzsXkyZNd8BaJmo8SnRFaMDOKqMmJ6gGM+1r8UndmC/DTDHe3yClLZpSHL9OzqxnVDDKjHJbpMTOKPNC+ffuQm5uLhIQEKJVKKJVKbN++He+99x6USqXTjZO4EoPIUVlpMQDABBmg1Li5NdSU1Xov6TFjxiA/Px9z5sxBdnY2unTpgg0bNiA2NhYAkJ2djYyMDMv58fHx2LBhA6ZOnYrFixcjKioK7733HkaNGmU5Jzo6Gps2bcLUqVPRrVs3tGzZEs8++yxefPFFF7xFouajtFxvqRnFmQqiJqZlAnDfcmD9w8Afy4GQduKue42Ij7p5ZEaVNrcC5iYGo8jzDRo0CIcPH7Y79thjj6FDhw548cUX7cqFSDQaDTQaDraJbJWbM6N0Mg20VdSNJqpOrYNRAJCSkoKUlBSn961atcrhWP/+/bF///4qnzMxMRG7d++uS3OIyKy0tBRymXm5BTOjiJqejiOAwa8CP78K/PQS0Gkk4Bsm3pd3Wryudd+ydG/zMj1Pz4wqbWaZUbqKy/SMLGBOnsfPzw9dunSxO+bj44Pg4GCH40RUufJSKRilRc0WvBI5V6fd9IiocdKVFVtvKBmMImqS+k0Rs6SM5cCeD8VjZ34BFt8MfDzCrfWkfMzL9Dw5M8pkElCmt2YGefJ7lUiZUNIENzOjiIioMvoyMRil///27js8qmpr4PBv+qRDEkgIkBB6FwlFugVBsYuCFRsqYkOu136LFQvXj8tVwAI2pFiwoxIUkF5C751QEkII6cnU8/2xZ1JICAnpk/U+T56ZOXPOnH0os3PWXnttvWQNisqRYJQQPsTp6RycGMFwQYmPQojaptNBv8fU8/UfqdX1fn0ONDckbYaET2qtaf4F0/R8N1vIdlbx7jyH7wdmvMEnf5MKNjqkgLloIJYuXcqUKVNquxlC1CtOz+C30yB5UaJyJBglhA9x2FTn4NBL5yBEvdbpegiJhtzTMHskpO4BnaeeyZ+vQc7pWmmWf0FmlO8Go86elpfXIDKj1LQ87zRMyYwSQghxLg5bLgAug8zCEJUjwSghfIjLlgfISIUQ9Z7BCJeoVWo5ulY9Xv0WRHSF/HT489VaaZa/xbuanu8GaPLPDkY1gJpRBZlRnmCj1IwSQghxLm5PMMptlPsNUTkSjBLChzg9mVEuCUYJUf9dfDdYPMXKI7pBr/vh6rfV64RP4cTmGm9SQAOYplcyM8p3r9WrMBglmVFCCCHK5vbcb2hSn1ZUkgSjhPAh7oK0WQlGCVHvWYPh0ucgqBlcNwX0Bmg1ALqOBDT49RnQajaDxZs5k+3DmVFnB58aUjDKW6BeglFCCCHORXOo+w3N5F/LLRH1nQSjhPAhBZ2DpM0K4Rv6PQp/2w0tehVuu/JVMAWo6Xtb50NuGvz4BPzwKDjt1dqclqHqF8+tx9J9NmDhnaZXsHKgw4VWw0G/muadlhcgNaOEEEKcj+d+QyfBKFFJEowSwododlUzyi1ps0L4rpDmMPhp9XzRSzBjEGz8DDbNhr/ertZT94ppTGiAmTO5DtYeTKvWc9UW7zS9xgFmQCWfnb3Cnq9xnl0zyunbwTchhBCV4FD3G5glGCUqR4JRwudpmsarP+/k05WHarsp1c/bOchIhRC+rd+jENoGck5B5jEIjFTbl/8HEtdW22mNBj3Du0QAsHB7UrWdpzblO1RgprG/uWCbr0/Vk5pRQghRx6Tsgh3f1/h0/PLQO9X9hkGCUaKSJBglfN6BUznMXHGIf/+0kw2Hq2gkv5qnwlwondMbjJLMKCF8mtEC10+FwAjocRc8vgG63waaG757CGzZ1XbqEd2aAfD79mRc7rr3S3JleTOjAi1GzAZ9sW2+ylEwTU9qRgkhRI3LTIKtX4O7yHfvV2Pg63tUBnQdC0jpXfkAGCwSjBKVI8Eo4fOKFtr95w87KnbzZMuC3b+Au8iNyK/PwtuxsC++CltZNbwjFTKHW4gGoNVAeHov3Pg+WIJgxNsQEg1nDsOfr1XbaS9pHUYjfxOnc+ysPXS62s5TW/I9WVB+ZgN+3rpRPp4ZZXc2zMyo33ck88euk7XdDCFEQ/fL32DBWNj2lXqdcxpS96rnq99TWc91iMGl7jeMloBabomo7yQYJXxerr0wGLUzKZM56xLLf/Afr8C8O2D9TPVa02DbN2DPViMWxxKquLWV4x2p0MtIhRANjzUErv+ver7+Izi1p1pOYzLoGdZZTdX7dVtytZyjNnmzoPxMBvxMKhiV7+OZUU538dX0vAXNfVme3cVjczbyyJcbC4JxQghR49wuOLxcPT/0l3o8sVE9Gizq8c9XYcv8mm9bKTRNw+S53zD5STBKVI6xthsgRHXz3kTodCqW9Pavu4nfeRKbw0VseAD92oTRJSoYvU4HqOkK+Q4XFpOedvsWYwBydy8mIfQmtDNHGJybqj7YkYv25a1k3fkLp63R+JkMRIZYi513f0o2+1KyOJ1t55LW6jw6z3mqg3ekwmCWaXpCNEhtLocO18CeX+C35+Gub9WXXxW7ulszvtpwjF+3J/Pv67tg0Fff91pN8wajrCZDQUFvX8+M8k7T82aCORpAcCbb5vRct0aOzYnZaD7vMUIIUeVO7gBbJgDa0bUkns7BunsVEcDpmKtwBkYRsXU6eX++zUb/ywnyM9ExMhizUY/d6WbvySy2H89g2/EMzuTa6RsbxqUdmtAsRN0LuNzqvsbucmPU67B6Blr0RfptTdPIyHNw7Ewep3Ps6AC9Tkeew0W2zYFRr6d1kwBaNPLn6JlcrKhyJWarBKNE5UgwSvg8701EXHRjcuwudiVl8tfeUwCsPZTGvPVHSz0ujAwSrAcByDm4mrt3rWWEfi2DzbDH3YJ8zFyUd5BtHzzAnY4XAYgJ86dHy0YcSs1h54lMnGdNCYwKsdKmaSAmgx69Todb09A0jWA/E+GBFhr7m/AzG1UnoVP3kKnZdo6m5XIyMx+7y43DqZHvdJFnd2E06GkfEUhseABpOXZaO/PBCAZJmxWi4Rr2KuyPhwN/wIr/A80FThsM+luV1ZMb0CacED8Tqdk2vt5wlNv6RFfJ59YF+QXBKD1WT2aUz9eM8gSfAizq10J7A5imZ3MW/p3mOlw0rsW2CCHqvxybk7tmruV0tp2mQRYsJj2BqVv5R97bzNFfx58hN+FvNuB0a9idbvIcLnLtLm7XFjLR8xm60/u58Z0fece0hAgDvLcnmK9dcWywmPDL2M8bs+azQ4vFbNQTE+rPkdO5Jb6vF5YjY1mvgxA/EwEWI/kOF9k2Z8HiHeXxuckGgNkvsNzHCFEaCUYJn+ddBSnQauS9O3qyZE8K4Tn7GLB2PJsaXckb9tEcTcvFGzayGPWYDXoucWwGz/dyE10mg8JzGOY+Drmw19qN92zX8DuPMcCwg7b6dA45GnPkdC5HTucWnDs0wEy7poEEWIysPnCaExn5nMjIr9Lr25WUWfB8klGNVFj9pXMQosEKawOXjIeVU+CPlwu3mwNh4IQqOYXZqOfxy9vy2i+7mPTrboZ2jiA80FIln13bik7T82ZG5RWZ7u2L7AWr6TWcAua2Itlfvv73K4SofluOprMpMR2AxLRcDLj42TyVFvpTjHPP5Yvk/mRRsoxGe9MOMBS+7mvaz8UGtQL4yaAuhBDGcnsfrnSv5IGgtbzsaE9GnoN9KWqhkmCrkW4tQujaPIQgi5Hl+1LZcOQMLrebq/XrCNVl8aXrCgx6fUHdXLcGZ3IdnMl1FGtL0wADLYN05Or80TQNq8lAkNVIrt3FgVPZpOc6CLIaCTe6wAl6WU1PVJIEo4TPy3O4sGLD3wiRIVZuj2sGH90B+ckMSJnLL08+DyHNSx64aAmsKnz5xTAdJCTDEbju6uu47uI7cc6ahzFxBYuHniSr9yjWHUpj+/FMYpsE0DO6Ec0b+RVMy8t3uFh7KI20HBsOl4bLrWHQ6UAHGbkOUrNtpOc6yHW4PAE0DU1TIxctQ/2JamTFajJgMugLRuzz7C72nszmcGoOoYFm+if6wwkwSWaUEA3b4Kfh2AbISwNrI0hcBRs/gwFPVtm0vXv7t2LBxuPsTMrkjV928e7oHlXyubWttALmPp8Z5fLWjPIUMG8A0/RsRbIAcmy+/fcrhKh+OXYXXXSHCAhtxj3D+9Nizyd02qFmXwTr8vjhkr3sbfsA/u4sIo7Hk9vuWix+IbT7cgLkQk5gKwKyDzOtRyL6bemgMzBt4j1g9oc9dpi7kptNa7jp2VkcOZVB2t61hHUeTHRYYLESII9d3o78zFQMv0zAtOcnAF6591oM7a7A5dawOVUmVHqug6x8J34mA4EWI00Czfh9exfsXwzjlkPTTiWuMdeu9td98BokA7JgkqgkCUYJn+fMzWSV5XG0xCA4NhsOLIHkbepNtxPWfQBXvqIKSiVvhaadwWCCxLVqn8BIyE6GxNVwYrPa1rwnAMYeoyFxBWydT9DAp7iiUwRXdIootR1Wk4Eh7ZuoJddXvAvpR+Had9UqWOejaZB7GgLCS7xV7HzzdHCCKpuKI4SopyxBcN8v6rktG/7TEdIOqiKpsYPBkQe5aaUH4svJaNDzxs3duGnaShZsOs7IuBYMaFvyO6q+KVozylvA3JdrRrncGt4Z5f4NqIB5sWl6Pvz3K4SoGfrT+/jF8iL2HBPmEw/Bvs/VG60vg4NLaL3/c1oPewRmP6QKlOduhMtehNwU0JsIGPwYLHwa/Y7v1HERnVUgCqDtFeAfDjkp6LbOp9XaGbRK3gZ5j8Hw14s3JOM41pnDIPNYwSbDjgXQ7goMbjv+nwzDX6ej6X2/gqnIPciGT2Dvr+r5ju9KDUZ5V1zFoWrUSjBKVJaspid8njnzCKG6bMIcSTBrOCx7S73RfbR63PAp2LLgl4nwwWC1vKojH5I2q/f7Pqwet38Ljhw11SW8vdrW6Xq10sWp3SrAlXEcVv0PslNKb8zuX+D9PmqJ1m1fwea5he+5nKquy9k0Db57GN5pA4dXlH2xDs8UQekchBBelkDofqt6nvApZJ6A93rD1B5weGWlPrpHy0bc1TcGgCfnbSYpI69yba0D8jwZM36mIplRPhysKDolz99TM6rBTdNzyDQ9IUTl6DNVFpQZB6x5H+xZ0LwX3D4Pgpurge0ZgwpXytv2Nayaqp5HXQyxQ9Rzt2fqXFTPwg83mKDrSPX8h0cLB9XXTFcF0ItaOUUFohq3guGT1LZdP6l7jG3fqPubE5vU/YpX+lFY9I/C1wf+LPtiC4JRMvgtKkeCUcLnue05RV441Zd8hxFw4wwIawu2DPj0WtgwS+2z8XPY9AW47BDQFLqPUtvzM9Rj1MWg90zu9msEHa5Szxf/Cz4YBItegq/GqCBSUYlrYd4dkHkcjJ4v721fq0eXEz6+HP57EWSdLH7cjgWw1bOc67Zvyr5Y6RyEEKWJu1c97vwRZo+EjKPqO+77cZCfWeah5/P8iI50jAwiNdvGuNkbCwqA11fe9vuZi9aMqt/XVJaigaeABlozSjKjhBCV5cpXNZzSjE0hrB1YgtUMCJNV1XEEFSQy+qkMZSi894jpp+5J/IospdC8SDAK4KLRhc9DW6uMK80FvzxdeM+RmwabZqvn1/0X+o6DoGbqXmf/YlgzrfAzlntmabgc8NMTKnjWtLN673gC5KUXP3/GMbVKb9pBGfwWVUaCUcLnue3qC/OUf1u44X3ocRdcNxX0+sLOwZsFFdYW0NSXLUB0XwhpAUFRhR94dufgzbA68KeaSgdqSt+WucX3845+dLwWHl0DOj0cWwdph2Dn95C0BbKSYPG/C4/JOqkytbwO/FEyyFVUQecgwSghRBHNLlKBdLcDUnaqQHtINKQnwu8vnP/4g0th4TOFAe8i/M1GPry7FyF+JrYcTedfP+woeXw90tBW03MUmZLn15CCUUX+TnOlZpQQopLcNjX4nWqNgcfWw9/3q74XIO4eNc1OZ4BbP4WbP1IzLbyi+6n7khZ9CrdFnXW/EdUTLroD2g2DB+Lh+v+pYFDiqsLB7Q0z1b1AZDeVaaXXQ5eb1XuLXoKT28EUoDK2nHnw42Pw0WXqHsZohVGfq0Ca5lbT+gsuzg3fPKCCWXPvAO9Av9xviEqSYJTweZpNBWhcRj+4+C648X0IbKLevOh21TkAXPoC3PUtGMyFKbItL/E89i78wLM7h7ZXQoDn83qOUfO/QX3p56ap52mH1BQ9gMv/oVJnWw1Sr7d/q1JqvbbMgaPrVTrtT09C3hlo2gX0JnXjmHaw+PntObBmhhrdcHhW6pPOQQhxNm92lDkQ7vwabpoO6FQm6J7fyj528cuqvt7mL0t9OzrMn/fuuBi9DuZvOMr6w2lV2vSa5M2CKrqani9nzjg9gSeDXlcQfHO4NLSyBj58QPHMKJmmJ4SoHM3hvd/wVwuFGIusMGsJgoeWwCOr1IyKoEgYNLHw/ZZ9PY+eYJTRr2TNJp1O9dt3fq1qyDZqqRYrAXW/sOETWPuhet3/icLFSrzT+7z3DxffBddNUYPiB5eqKX9+jWHkTAhvB20uU/sVnaq3YSYcXaOen9oFLk9ZEcmMEpUkwSjh83QOFb13G0v5wjT7w5gfYPSXMOQZFSTq81Dh+9GeYFTRkYrmccU/w2iGe39Rn3P9/2DgU9Cko8qSWvQPlcm07iNAgzZXQNOO6rhunhouK/+rOgKTP3S6Tm376QlVv2rvr6A3ws0fFLbl7HncPz0Jvz2rpt7kp6ttEowSQpytx10w7DW45yeI6gGtBhZmh678b9nHph9Rj/v/OOcug9o1YXTvaADeWLir3gYzSitgXt+nHpbF7glGGfU6TIbCXwsdPl7EvFgwyof/foUQNcSTGaWdK0DTKLrwHgDgkkeh840wYAL4h6pt7Yap7Kk2l6s6UefT7zF1b+HIhZ8nQE6Kqk/V5abCfZr3VPc3AOjgknEqc6rfY2pTp+vh0XXQ6Vr1us3l6vHAEvWYfrRw1kbRzwW53xCVJsEo4fs8IxXn7Bwiu6ovYO8IwuCnIaQlNIqByO5qW6sB6jG4hZq2d7YmHaD1peq5wQTXvKueb54Nc0apOlRQeOMHKvBkMIPNU6+l5z3qOEuwmkZzarfK2rr1M9VpeDuHojeD274pTM1N3QPZnnpTMlIhhDibwQj9Hy8+1bjfo4BOpfmnJ5Z+nD23cArywWXgtJ/zFE8NbYefycCmxHR+3Z4MQEpmfr0K5niDUaqAuSro7cuZUd6gk9mgx1wsGOXbU/WKraYn0/SEEJXkHfzWShv8Lo3JCqM+gytfLtzWrDs8nqAGocvDaFGZUpe/pDKdQNWJKhrI0umgm6f+bcdrVL0pUCuJ//0AjP4CApsW7t9qoBoIP3NIzdRY8BDYs1X21shZEHdfkWuQYJSoHAlGCZ+nd54nGHU2v8Ywfg08ulZlPYGqtXLrZ3Db7MKgVVlaDYBrp6iV9vYtUkUBwzuopVkLztNIjYCA+tLv96jqDK56U83bvugONefcO1LhPfbwcnUzmHEMfvak+La/uvj5pXMQQpRHSHP1iyeoKcOlyTxe+NyRo2rinUPTYCsPDla/6L7+yy5GTl9Fnzf+4M6P1+J2149MG5t3NT1zYWaUb9eMUtdrMuoxGXQltvsq798z+HawUQhRM3Se+w3MlRwQDo1V0/rKS2+AwX+HsYthxOTiA99eg/6m7kuuL7KCnk6npvudzRJUOCNk1jA1WGX0U8fq9TD8dWg7VA2iexd0EuICSTBK+Dy9UxXc1VUkW8gSWDKg0+VGFZQqr173wYN/QHh79XrQxJKBrN5jAZ0aZWjUUm27+E54IUnNC/em7QJEdFOZUvZsVRx97m1qdYzmvWD0bDUS4mWUYJQQopy63aIet35d+vsZR4u/3r+4zI97aHBrwgMtHE/PI+HIGQASjpzh+83HyzyuriiaGdUQVtOze6armQw6DHpdQTdl9/VgVJFpenkOqRklhKgcvXcRIXNA7TSgeRz0eVBlQZ/NZFX3JUXvK8rirRuluSGiKzywSM0CAXV9d30L10+tmnaLBk2CUcLnGTwjFbrKjlRciMhuMG4FPJYAF91W8v02l8HT++Dqt4pv15fyX1OvL+wcfnrCU3AwFG7+UHU8Q19WUwVjhxQWVBdCiPPpfIOaMpyyA06WshJexjH1qPek/ZdRNwog0GLknVu7079NGM9d3ZFxQ9oAMPn3PfViup438GQ1GRrEanpOT8aaUa9HpyusG+X7NaOKTNPz4WCjEKJmGFxq8FtfG/cbVa3HHWqFv8HPwIN/qumDQlQDCUYJn2d0qRXm9JZaGqkwWiC87bnfD2xS/jRXb90ogNjBKtAVpm70MFlVEfV7fiw9mCVENZk2bRqxsbFYrVbi4uJYvnx5mfsvW7aMuLg4rFYrrVu3ZsaMGcXe/+ijjxg0aBCNGzemcePGDB06lHXr1lX6vOIc/BoXThneVkp2lDcY1eFqVZMiZQdklJ3ldFmHpsx58BLGDWnDhKHtiAqxciIjn1krD1Vx46uWpmnFCpg3hNX0vNPxzEbVb1i8wShnw8mMypGaUUKISjJ6glEGS2Att6QKhLSA+3+Dy18sviqgEFVM7liFzzO5VTDKUFvBqKrU+UZVS+rqt+HuH1S9FyFq0fz585kwYQIvvvgimzZtYtCgQVx99dUkJpZeDPvQoUOMGDGCQYMGsWnTJl544QWeeOIJvv22sF7R0qVLuf3221myZAmrV68mOjqaYcOGcfx4YQCkoucV5+Fd3XPrV5CfWfw9bzCqWffC1UQPlJ0dVZTVZODp4Sq9f/qSAyzakVxnV9orGqDwMxvwM/v+anqOItP0QNWOgoZVM0qm6QkhKsvkGfw2WH3gfkOIGiLBKOHzTG41UmG0+sBIhdlf1ZLq+7BkP4k64d133+WBBx5g7NixdOrUiSlTptCyZUumT59e6v4zZswgOjqaKVOm0KlTJ8aOHcv999/P5MmTC/b58ssvGT9+PD169KBjx4589NFHuN1u/vijMABS0fOK82g/HAIjVLHyL28BW3bhe96aUSEtVdFSUAszVMCNPZpzUctGZNmcPPRFAiOmruDXbUl1rqh50aCT1agvKGCea/fdYIW3NpR3ep43KOX7NaNkmp4QouqYPfcbJl+43xCihsjdrPBpmqZhcctIhRDVwW63k5CQwLBhw4ptHzZsGKtWrSr1mNWrV5fYf/jw4WzYsAGHw1HqMbm5uTgcDkJDQy/4vAA2m43MzMxiP8LD5KeWh7aGwNG1MGcU2D3FWL2ZUSEtCqfz7f8THPnl/ni9Xsfn9/Vh/KVtCDAb2JWUySNfbmT4lL/4ePlBfth8nCV7Ujh4KhtnLQZBvFP0zAY9RoO+IDPKlwuYOz21oYwFwSj1aG9A0/RyZZqeEKKSzJrqE31i8FuIGlJKuX0hfIfN6cYPGwBmvwoskyqEOK/U1FRcLhcRERHFtkdERJCcnFzqMcnJyaXu73Q6SU1NpVmzZiWOee6552jevDlDhw694PMCTJo0iZdffrlc19YgNbsI7v4ePr8BjqyEDTPhkkcL60OFtIBGMRAUBVkn4NAylVFVTiH+Jp65qiMPDmrNrJWH+HTVYfalZPPaL7uK7Wcy6LihR3PeGtkdg153jk+rHoXFy1VApmA1PV+epuetGeXJiDI3mALmRYJRMk1PCFFJVi0fdGDxl2CUEOUlmVHCp+XaXfjrVDDK5CedgxDVQacrHjDQNK3EtvPtX9p2gLfffpu5c+eyYMECrFZrpc77/PPPk5GRUfBz9OjRc+7bYDXvCUOeVc8PLYfcVHDZAJ0KQul00PEa9f7uny/oFI0DzPxtWAdWPnc5z17Vkau6RDKgbRgdI4OwmvQ4XBrfJBzjo+UHq+aaKqBo8XIAf5Mas3O4NJ+toVRyml5DqRlVGGD05cw3IUT1szvdWD2D3xYZ/Bai3CQzSvi0PIeroHMw+MJSq0LUIeHh4RgMhhLZSCkpKSWylrwiIyNL3d9oNBIWFlZs++TJk3njjTdYvHgx3bsXLit8IecFsFgsWCyyKsx5xfRXj0fXQLqnIHxQJBjN6nnHa2D9R7DnV3C7yr8a6FmCrSYeubRNsW1ut8acdYm89P12/rNoDwPbhtO1eciFXkmFeWtGeafnWc2FY3Z5DldBoMaXeDOgCoJRxoZSM6pIZpQEo4QQlZBnd+HvnYnhL8EoIcrL936rEqKIPLuzoHPAJDWjhKhKZrOZuLg44uPji22Pj4+nf//+pR7Tr1+/EvsvWrSIXr16YTKZCra98847vPrqq/z222/06tWr0ucVFRDZXX1f5mfAfk/R+JAWhe+3GgiWEMg5BcfWV+mp9Xodd/aN5qoukThcGk/M20RSRl6VnqMs+Z4V1ryFy80GfcFUwXwfDVg4z5UZ5fM1o4oXMK9rxfSFEPVHTpH7DSkLIkT5STBK+LSi0/SQzCghqtzEiRP5+OOPmTVrFrt27eKpp54iMTGRcePGAWpq3JgxYwr2HzduHEeOHGHixIns2rWLWbNmMXPmTJ5++umCfd5++21eeuklZs2aRatWrUhOTiY5OZns7Oxyn1dUgsEILTwBwG1fq8eiwSiDqbBW1AVO1SuLTqdj0s3diAi2cPBUDgPfWsKjczayJzmrys91tsKaUYaCthSuqOebwShHQTBK53lseDWjAPKdvvn3K4Sofrn5diw6zyIsZhn8FqK8JBglfFqe3VVQwByTBKOEqGqjR49mypQpvPLKK/To0YO//vqLhQsXEhMTA0BSUhKJiYkF+8fGxrJw4UKWLl1Kjx49ePXVV5k6dSojR44s2GfatGnY7XZuueUWmjVrVvAzefLkcp9XVFJ0P/V4ep96LBqMgsK6Ubt+Bq3qgxaNA8x8cm8fLmkdisut8cvWJK57bwVz1iYW1BirDt6aUd4AFBRO2fPVIub2s6bpmRtMzaji1+erwUYhRPWz5RYZLJH7DSHKTWpGCZ+WW3SanoxUCFEtxo8fz/jx40t979NPPy2xbciQIWzcuPGcn3f48OFKn1dUUvQlxV+HRBd/3XYoGCxw5hAcXgGxg6q8CZ2jgpn3UD92nsjknd93s2TPKV74bhvfJBwlM9/JqSwbt/eJ5pnhHdBX0ap7hQXMC8fqGk5mlHeaXkOpGVX87zPX5gJZ50QIcQHyczMBcKHHYJTalEKUl2RGCZ9mz89Fr/OMostIhRBClE+LXqAr8ivC2ZlRlkC4+C71/PcXVCHzatI5KpiZ9/Tm+as7YtDr2JiYzv6UbDLyHMxYdoCnvtqMvRz1jcqTUXV2AXMAf8/zfB/NjPLWhjIbz56m5+vBqLMyoxzOWmqJEKK+c+SpMgI2nUWtOiuEKBfJjBI+zZ5bWGNGglFCCFFOliCI7AZJW9Trs4NRAJe9ANu+geStsPlL6Dmm5D5VRK/X8fCQNgxsF07CkTPEhAWQlJ7HS99v54fNJziUmsPQThHEhgeQcOQMqw+cJt/porG/GbNRz4n0PE5m5jO6d0teu7HbOc+T7yheMwrUqn8Ay/elMqBteLVdY21xeAp3G/Xe1fQaSgFzmaYnhKga9jw1Tc+msyJ3G0KUnwSjhE9z2HLUIyZMBvnnLoQQ5Rbdr+xgVEA4DHkGFr0If7wKnW8Ea3C1NqlLVAhdokIKXkeGWHlk9ka2Hstg67GMEvsfOZ1b7PXsNYn0ignlxoubA3Amx04jfxM6z0h2nr34anoAY/rHsO5wGh/8dYB+bcIY0r5JlV9XbTp7mp65oRQw9wQezQY9dpe7oHi9EEJUlCNfDX7b9X613BIh6he5Oxc+zVXQOVgxnWdfIYQQRURfAmtngCkA/BqXvk+fh2DDTEg7CCv/C1f8o0abeGmHpix6ajB/7DrJxsR0DqXm0K1FCIPahtMkyMLpHDv5DhfNG/nxx+4Upi89wEvfbyeqkR8fLz/Iop0neeyytjw9vANQegHza7tHsfrAab5cm8hT8zfzyxMDaRbiOzcc3gwoU8E0vYZSM0pdX+MAEyczbeTYZJqeEOLCeO83HHprLbdEiPpFglHCp7m8mVEG37lxEEKIGtHmcjVVr2Xfc9fAMJph6Mvw1d0qcNXvUfAPrdFmtgz1594Bsdw7oOz9erRsxPpDaWw4coZRH6wu2D5j2QFuvLg5bZsGllozCuAf13Zm89F0dpzI5F8/7ODDMb2q/DpqizczylxQwNz3a0ZpmlYYjPI3czLT5rOrJQohqp/3fsMp9xtCVIgUMBc+rbBzkJEKIYSoEGsIjFsB1/yn7P06XQcR3cCeDavfr5m2XQCjQc+U23oQZFXjcD2jG3FJ61Ccbo3XftlJvsPF1mPpQPGaUd7X/ze6BwDxu05y7Ezx6X/1mbdmlKkBBaOKZn018ld501IzSghxodw21Se4jBKMEqIiJBglfJpmU2mzToOUExRCiGqh08Glz6rnaz+A3LTabU8ZWjT257vx/floTC++GdefSTd3x2TQsXTPKa6ZupyNielYjHou79i0xLHtI4IY0DYMTYO56xJrofXVwztNz+iZnmc2+n7NqHxHYTAqNMAMINP0hBAXTLOrwW+XUe43hKgICUYJn6Y51EiFWzKjhBCi+nS4BiK6gj0L1kyr7daUqW3TIK7sHIFeryM2PIB7+rUC4MCpHIIsRj6/vw+dmpVeiP2uvjEAzF9/FJvTNzJpSk7T89SM8uHV9Lx/dzodhPipzCgpYC6EuGCeYJQmwSghKkSCUcK32T3BKJN0DkIIUW30ehjiyY5aMx3S60/m0ONXtCM2PIDIYCtzH7qEvq3Dzrnv0M4RRARbSM2289v25BpsZfXxZkAVrqZn8Gz34WCUJzPKYtTjZ1LTNnOlZpQQ4gLpHHkAaGa53xCiIiQYJXyazqmCUTJSIYQQ1azjtdDyElU76vvx4K4fwYwQPxO/PjmIlc9dTtfmIWXuazLoua13NACfrz7iE9lD3vpJBTWjjA0hM8objDLg7ylWL5lRQogLpXeqzChk8FuICpFglPBpes9IBTJSIYQQ1Uuvh5umgykADi+HtdNru0XlZjUZMOjPsWLgWW7vE41BryPhyBn6vrGYf/6wnd93JJOSmV/NraweTtdZNaMaQAFz7zQ9i1GPv0UFo6RmlBDiQumd6n5DZw6o5ZYIUb9cUDBq2rRpxMbGYrVaiYuLY/ny5WXuv2zZMuLi4rBarbRu3ZoZM2acc9958+ah0+m48cYbL6RpQhSj92RGyUiFEELUgNDWMPw19Xzxy5C8vXbbUw0iQ6y8cVNXwgMtnMl18PnqIzz8RQJ93viDK/6zlBnLDpCSVX8CU95peuYSq+n5bgHzgswokx5/z8qJMk1PCHGhDC4VjNJbJBglREVUOBg1f/58JkyYwIsvvsimTZsYNGgQV199NYmJpdeHOHToECNGjGDQoEFs2rSJF154gSeeeIJvv/22xL5Hjhzh6aefZtCgQRW/EiFKYfR0DjrpHIQQombE3QfthoHLBnNGQeaJ2m5RlRvdO5o1z1/Op/f15rbeLekYGYRep4qgv/nrbvpP+pPJv++pF0XOS0zT8zzafTkzylF0mp6qGSXT9IQQF8rkUoPfBktgLbdEiPqlwsGod999lwceeICxY8fSqVMnpkyZQsuWLZk+vfR0/BkzZhAdHc2UKVPo1KkTY8eO5f7772fy5MnF9nO5XNx55528/PLLtG7d+sKuRoizyEiFEELUMJ0ObvoAwttD5nH4chTkZ9Z2q6qc0aDn0g5NeXNkd36bMJgt/xrGWyO70TO6EU63xntL9nPd/1aw+sBpNK3uZhk5CoJRumKPMk1P+JpJkybRu3dvgoKCaNq0KTfeeCN79uyp7WYJH2ByqWxYg1WCUUJURIWCUXa7nYSEBIYNG1Zs+7Bhw1i1alWpx6xevbrE/sOHD2fDhg04HI6Cba+88gpNmjThgQceqEiThChTQecgc7iFEKLm+IfCnV9DQFM4uQ3mjIac07XdqmoVZDUxunc0C8YPYPqdPQkPNLP3ZDa3f7SGEVNXsGDjsToZlHKevZqesSHUjCpcTa+ggLlM0/N5y5Yt49FHH2XNmjXEx8fjdDoZNmwYOTk5td00Uc+Z3Wrw2yTBKCEqxFiRnVNTU3G5XERERBTbHhERQXJy6UscJycnl7q/0+kkNTWVZs2asXLlSmbOnMnmzZvL3RabzYbNZit4nZnpe6OuovJM7nzQgcEqwSghhKhRjVvBHfPhs+shcRV8dCncPg8iutR2y6rd1d2a0bd1GP9ZtIdvNx5jV1ImE7/agsutcWuvlrXdvGIc55im53DWvcBZVSm6mp6fSf0qnCvT9Hzeb7/9Vuz1J598QtOmTUlISGDw4MG11CrhCyyaut8w+UkwSoiKuKAC5jpd8RVnNE0rse18+3u3Z2Vlcdddd/HRRx8RHh5e7jZMmjSJkJCQgp+WLevWL3ei9mmapjoHZKRCCCFqRfOeMDZeBabSE+HjK2H/4tpuVY0IDTDz+k3dWPv8UO7t3wqANxbuIi3HXrsNO4u9xDS9hlAzyjNNz6QnwDNNT2pGNTwZGRkAhIaGnnMfm81GZmZmsR8hinK5NayaSpAwSzBKiAqpUDAqPDwcg8FQIgsqJSWlRPaTV2RkZKn7G41GwsLCOHDgAIcPH+a6667DaDRiNBr5/PPP+fHHHzEajRw4cKDUz33++efJyMgo+Dl69GhFLkU0AHaXGz8kGCWEELWqaSd4cAnEDgZHjpqyt/WrkvvZsmu+bTUgxN/Ei9d0omNkEGdyHbz+yy72nsxi3BcJ3D1zLftOZtVq+woyo4zezKiGUDOq5DS9HLvUjGpINE1j4sSJDBw4kK5du55zPxn8FueT53Dhp1PBKKt/UC23Roj6pULBKLPZTFxcHPHx8cW2x8fH079//1KP6devX4n9Fy1aRK9evTCZTHTs2JFt27axefPmgp/rr7+eyy67jM2bN5/zS99isRAcHFzsR4ii8u1u/PCMVPhLMEoIIWqNfyjc+S10vQXcTljwIPz1Drjd4HLAT0/CpObw4+PqdW1zu2DhM7Dxiyr5OJNBzxs3d0Ong283HuOqKX/x245klu9L5ZqpK3j7t908880W+k36gxveX8mS3Sk1Vl/KOx3P7K0ZZWhINaMM+Jllml5D9Nhjj7F161bmzp1b5n4y+C3OJ9fmxN8z+C2ZUUJUTIVqRgFMnDiRu+++m169etGvXz8+/PBDEhMTGTduHKC+tI8fP87nn38OwLhx43jvvfeYOHEiDz74IKtXr2bmzJkFX/5Wq7XEiESjRo0AyhypEOJ8ch1O/D3BKKMstSqEELXLaIabP4LAprBmGvz5GhxZBZoGB5eofTZ+DmcOw6gvwK9R7bX14FJY9wEYzNDpWvBrXOmP7BndmLv6xvDFmiO4NbiqSyQ2p4sle04xbWlhFnhSRj73fbqeXjGNuaZ7Mwa2Dadt08AyyyFUhtOtAjNG7zS9ggLmvlwzqshqeiaVGWV3unG63BgNF1TBQtQjjz/+OD/++CN//fUXLVq0KHNfi8WCxWKpoZaJ+ijX7iLSc7+hkwWThKiQCgejRo8ezenTp3nllVdISkqia9euLFy4kJiYGACSkpJITEws2D82NpaFCxfy1FNP8f777xMVFcXUqVMZOXJk1V2FEKXIsxemzWLyr93GCCGEAL0ehr+hpu4tfAYO/Km2mwJgwBOw6n9w6C/46DK4cQZE962ddh7boB5ddti+AHpXzUq/L17TidjwAC5qGUJcTCiaprFg43G+33ycNk0CubRDE1YfOM0nqw6z4cgZNhw5A0BMmD83XBTF9T2a07Zp1Q6u2J3FC5h7M6Oybb47bc3m8GRGmfT4e2pGAeQ6XARLMMpnaZrG448/znfffcfSpUuJjY2t7SYJH5CTb8Oq82T0SjBKiAqpcDAKYPz48YwfP77U9z799NMS24YMGcLGjRvL/fmlfYYQFZVrd9HIM1KBWYJRQghRJ+h00HMMtOgNCx6C/AwY9TlE9YCO18Cc2yDtIHxyFfR7DK74JxhMNdvGY+sLn2+ZV2XBKKvJwP0DC2+AdTodI+NaMDKuMDvj0g5NuXdAK77fdIJVB1JZdyiNI6dzmfrnfqb+uZ9uzUO46eLmjOrdkkDLBf0aV4w3A8obhGrTNBCDXsepLBvHzuTSorHv9Z9Fp+mZDXoMeh0ut0ae3UWwtYb/rYka8+ijjzJnzhx++OEHgoKCCmrahoSE4OfnV8utE/WVLa9IvUMZ/BaiQmT4Ryj2XMg5XdutqFJ5DlfBND3pHIQQoo5p2gnGLYcnNqtAFEBkN3hkJVx0B2huWDVV1ZPy1k9yu8BWzQW/3e7iwahj6yB1f/We8yzNQvx45NI2fPFAXzb+40r+e1sPLuvQBINex7bjGbzy805unraS4+l5AKRm2/htexL5jorXPSooYO4JRgVajHRrHgLAmoNpVXRFdUvRaXo6na5gqp7UjfJt06dPJyMjg0svvZRmzZoV/MyfP7+2mybqsfxcFYxyowOTBDWFqIjKD6kJ3zB3NBzfBI+sUEtw+4C8fLukzQohRF2nP2tczK8R3DQd2g+Dbx6AzV+qfql5T/jlb5B9Cu78CloNrJ72pB2A/HQw+qlpggeXwpa5cMU/qud85xFgMXJDj+bc0KM5qdk2ft5ygmlLD7D3ZDY3vr+Sq7pE8nXCUfIdbro1D+HDMXE0Cym8IVp94DRz1iUSaDESF9OYXjGNiQnzR6fToWkaTrcK9HlrRgH0axPG5qPprD5wmlviyq6pUx8VzYwC8LcYyLI5yZUV9XxaTS0KIMpwdL3Khm03tLZbUmUceWqAxKaz4FdNtf2E8FUSjGqA4nee5KsNR/nXdZ1V+n1+hqrRAWq57SHP1G4Dq4ikzQohRD3W5SbIS4efJ8CS14u/N+9OGPsHhLct3GbLghObIaY/6A1csKPr1GPUxWo64cGlsHU+XPZiycBZDQsPtHDvgFiu7BLJ/Z+sZ8/JLL5YcwQAoydr6vr3VvLw4NbYnG5W7Etl9cHCrOe561RNz+aN/OjXJoyY0MK+0VSkVlK/1mFMX3qANQdPo2latRVPry1Fa0YB+JuNgE0yo4SoTi4HfDkS8jNh/GqVHesD7J77DbvOiuRFCVExMk2vAfpk5SHid57kibmbcLrccLxIPa9t3xROh6jnnPmSNiuEEPVar/tgwAT1XKeHS8arWlP56TDnVhU4yjgOaz+E//aAz65V2VOV4Z2i16IXdLgGLCGQcRQOLa3c51ah5o38+PqRflzTvRmD2oXz2f19WPL0pXSMDOJUlo3XftnFO7/vYfXB05gNeu66JJqHh7SmV0xjTAYdx9Pz+CbhGP+J3wuoMl4WY+GvhL1aFe53NC2vti6z2hSdpgfgJ9P0hKh+p3arAXA0VYuvOmgaOGr2O8vlud+w6+VeQ4iKksyoBigrX6Whb0xM5/0lB3jSnFD4ZuoeSNkJEV2q9qSOfDi5Q02zqKERVkdeDgB2nQWrj43qCiFEg3HFv6B5HIS1UX1Tdgp8fIUqcj7zypL7J3wCba+ATted/7Nz08CvcfF+qSAY1RtMVug+CtZ/BOs+gjaXV801VYFgq4n37+hZbNs3j/Tnf3/s49iZPAIsBiKCrdzWJ5rmjQpvknLtTtYfPkPC4TSSMvI5mWWjb2woVlNhNpm/2chFLRqx4cgZVh9MJTosusauqyacPU0vwLOiXp5M0xOi+hQb/P5afbdXZbapIx++uR/2LYKx8Sq7tQa4bCoY5TRYa+R8QvgSCUY1QEWXa5765z5ui1lFBIDeCG4nbP+2aoNRuWnwxU2QtBlu+gAuuq3qPrsMTrsKRjn0VqR7EEKIekqvh87XF74ObAp3fgu/PQun9kBWEgQ0VVPM0w7C6vfgx8chqieEND/35656Dxa9CC37wjXvQmRXNdUvZad6v0Vv9dj3YRWM2vMrpB2C0Lq7HHygxcjzI8qe+uJvNjKkfROGtG9S8k23u+DmsF+bMBWMOnCa0b19NRjlyYwyq1+Hc2ySGSVEtTlRJBiVeRyOrITYQVXz2Y58mH8n7F+sXm+eU3PBqHzP/YZBMqOEqCiZptcAeYNRXaKCcbnd6E6ozKifzFcDkLpmLm/8spNZKw7x45YT/LX3FBsTz7D+cBqr9qey5Wg6JzPzcbnLMZ0vOwU+vUYFokAFumqIN23WIWmzQgjhW5q0h7u/g4k74aVT8Lfd0PsBNdLerAfknYE5o+DIqtKP370QFr2knh9dCx8Mhp+fUlNHNDeEtITgZur98HbQdiigqewoX5XwGbwZDYdXAKpuFMBqT90oX2LzrDpYUDPKO03vAlYjFEKUkzczKsjz3bq1ilYxTNmtvu/3LwY8Wa67f6mxsiOaZ/DbZZT6tEJUlGRGNUA5nmDUWyO789Nf62i6Jx2npuef6ddwhWUR4Y4TNF79Bi11JziiNeUJ510UfLmfJdBiJNBiRK8Dl6Zh1OsJDTATZcljcM7vDM/6jnB3Kjn6IALcWTj3L2X6r5sw+QcTYDZgKTItwM9kIMBiwM9kxGrSYzbqcbvB7nJj0OuwGPWYDDrsTg2Hy43VZCDYz4ifyYDDpeHWNEL8TAVTDdyezkHSZoUQwocZivwqYzTDLbPgo8vh5Hb45GoVSGo3XE31M/mp+k/fjgU0uOgOcOTAzh9gw6zCz2nRq/g5+o5TNzqbvoDLXgBLYI1cWo3a/QvYs1QGWKuB9IxpjNmg52SmjT0ns+gYGVzbLawyZ0/Ta+RvAuBASvY5jxFCVIIjvzDr9Ip/wffj1Pdul5tg5/fQtAtcMq5in5mVrGoE7v5ZvTb5w+gv4Kt7VObViU2qPMjvL0LyVrhtDliCqvSyoDAY5ZZglBAVJsGoBsbl1si1u9DhJjLEyvPdc2APuJp05q3LLiN15WVEn/iNR4w/FRyzu9Fg1rg6YtLruMG9iL2OCH7LaYdbU1lWTexHOaGFYcMMQIuMjbxrfpsAnQ2AY1o4d+a9wOemN4nRp7B9+Q/87u7N88YvGaBP4A77iyQTVmXXGGgxYtDr6GM/xGgTOA3SOQghRIMR1gYeXQvL3lLZPvsXF07dKCp2CFw/FQwmtaLs+pkqION2QNuzalG1uQLC2sLp/bDxc+g3vmaupSadOaQeU1VRc6vJQP+2YSzdc4pxXyTw1bh+NA3yjcGds6fpDe8Sybz1R/l+83Geu7pjsfpZQogL88vWJD5ffRhNg3aO3bzudpJlaMRLO9vzL0NTQm0pMPvmgv0nbgznEM1o7Erj2YxXSTD3Yo7f7QC01Y7waNZUFlhvZrGuHwa9jlfzXqe3bQ1udGzw6898/zvZ/5uVp+nBIFbwzZcz2GjuxRvp7wHwwftv8UfANWiahndyh1Gvw2TQo6E26HU6orUTtLXtYK3/ZeRjwu50Y3O6cWsaJr0eo0GH060Gxp0ujSFpKQBosnK3EBUmwagGJsfuZLzhex40LiQgaTYcV1P0LK36MKxLJDR+Dr7ZC41i1GoUR9cwOWY93DpeTbH7ZhqY/HE9u540QxO07d/S9Pe/kRk9lMThs7C73LT54S0CTtvIDGrLobZjONxsBPc6jJzesYGYE3N4OHIP7Rp14+GDvwDwfMQavmt0L3l2F7l2F7l2J/kO9cVvMugwGnS43eqXR6MrF5fRH5NeR77TTWaeA6fb24FQECAD8NOrYJh/YNWPggghhKjDgiLh2v+DSx5Vfdex9WqUHA3MgdCsO1z/PxWIAogdrH5yTkPagcJ6UV56vcqOWvi0qjPlyIGBf6va4ru1ye2GM0fU81N7CjZPurkbt0xfzeHTuYyZuY55D11CI39zLTWy6py9mt7g9k2ICrFyIiOf33ckc0OPMmqNCSHK5X9/7mN3chYAHQ2bwAQb7DH8sDWZaMNg/mb6hmzNyhktiJb6U1x0Yh4LnPfxuvETOhj30MG5h6/OdGCr1ppJ5ndopz/MWPt7fG5rS6Qujd6WNbg1HTfbX2Zzfls4A5DB1/qLGGRewUXZK2jFpoKiNH3Sf2VSSr8y29xed5T/mV+hkS6Hfu55THQ8QqoWwqWGzeRpFn5y9y9xzBBDLpjAz1/uN4SoKAlGNTA5NieXGrbQWJeN9v2DqugrqOkLoIr9PbFJPU/aCh8Mgl0/qqWz/3xdbXfkYvjjZZqMeBtW/BOA4MTFdHXtVisSnd4CBjPBD//KRYFNuch78qg74LM59MxfS0+9o6BNN+hWcMO975e9yp7LCQseVKm8vcbDFf8EowXNacPlsGOwqikTWTYnp7JsuNwazQ4kwyJoFNKoSv7shBBC1DPhbeHSZ8u/f0CY+ilN3H2q/uGm2fDna3B4JQz9N0T1KL7fob9gy3zodT+0iLvAhtew7GRwqQEc0hPVYJTJj2Yhfsx5sC+3zljN7uQsHp+7ic/v74Ounq9Qa3N4MqM8GVAGvY7RvaP5v8V7mbM2UYJRQlQBQ14qPXVHuHLYdVx76CtIhMbt+vKP1p3xM3biz8zrSQtsT3DaVlpueIg7LStod/WjXLJ4GZ5EJT5v9hXJrW6m/cbDAITpsljYZxvmnONwAI5HXModfW7mPqMes0GV+DA7O+L+7kPacRwAl8GKzu3kYv1+PrsuhLyQNpgdGWiaRp4xBKdLQ6cDv+xjDFr+JH42Ne2uo/4oP1v/gV4rrCV3x6DepIT1xujJkDIb9LTZugx2QlTTqpvlIURDIcGoBibH5iSIPAB0Oacg55R6o3kpvzA36w4t+sCxdTBntBottoSALRO2faVWMPIeD7D0DbCGqOfdR6kVj4qKvgSsjSD3NOyPB50BjBZIPwKJayCmnyo26HYWjlaDGrH94VHYsUC9Xv0eHFwGoa3QHVii/hE/tBTC2xFsNRFs9Rx7yK4eTVLAXAghRCUZjHDD+xDdT9UpObgEPlyipvRd9rzqR/fFw7w7wGWHzbPh4rth6MvnDnDVFWmHirzQ1HTEyG4AxIQF8MUDfbn+vRUs35fKNwnHuLVXy9ppZxU5e5oewKjeLfjvH3tZeyiNA6eyadPEB+uCCVGDXrBNYYBlC6dt+YTl7QagR9/L6dHBuyJpa/WgdYTEKRhTdtJ/1YOgOdX9x6ndBKdtJ/iMp9ZU26GwfzExu2cWBM9bXvscLaPP/j6KgM2D4MCfABj6Pwopu2DPQobk/A6tb4FPrwV08MAiaNoRsk7CJ+PAdgqadFK1pxb/G/3un9V+AeGQc4p+yV/CFTcWP91B9aAzB1TlH58QDYKP5JeL8sq2uQj0BKMKmIMgvH3pB/R5UD2e3KYeL30WLr5TPT+8XD3e9AHoTXBwKez8UW27pJR6GgYTtBtW+LrHHapwIcDWeZCbBh8OgakXw+kDarumwa9/V+/rDDD4GfAPU+3Z9RPYs9XP8ndLns+Rqx5N0jkIUZ2mTZtGbGwsVquVuLg4li9fXub+y5YtIy4uDqvVSuvWrZkxY0ax93fs2MHIkSNp1aoVOp2OKVOmlPiMrKwsJkyYQExMDH5+fvTv35/169dX5WUJUbqL74JxK6DbKNDp1eDKR5fD7FsKA1Fh7dS+m76AT0eoTKO67Mzh4q+LTNUD6BAZxMQr1e8Jr/68k5Ss/BpqWPU4e5oeQLMQPy7vqAbR5q1LrJV2CeErNE2jhZYEQNiaN+GUCkYR1bPkzjqdmgYNhYPcw99Qi0WAWuE0sjvcPg8iuqmFFlx2FbCKvqT0BnS8Rj36NYYBT0IPz73Llrnw5a1qYN2WAXNvU/ccX9wEaQehUTTcvUCtojp6Njy6Hp7eC/f/rr7v9y2CkzuLn8uhMqmQmlFCVJgEoxqYHJuTIJ0nSDP4GUAHbS8H/TmKdXa+QQV/AIJbQK8H4PJ/qgAWqC/3i26Dnnd7DtCg9aUQ0aX0z+twtXo0mGHIs+pYgO3fwdzbIWmLWulozmgVnPrlb7D+Y9XOmz+Ey1+ER1apjmXwM3Cj5yZ221eQfrT4ueye6zRL5yBEdZk/fz4TJkzgxRdfZNOmTQwaNIirr76axMTSb+YOHTrEiBEjGDRoEJs2beKFF17giSee4Ntvvy3YJzc3l9atW/Pmm28SGRlZ6ueMHTuW+Ph4vvjiC7Zt28awYcMYOnQox48fr5brFKKY8HYw8iN4bANcdDugU0Eplx06XgvjV6ubl4Cm6ibsz9dqu8VlOzsYlbqvxC4PDIylW/MQMvOdPPR5AhPmbWLsZxvYdiyjZtpYhbyZUWcXKr+9TzQAX204Rq7dWePtEsJX5DlcBJFbfGNwcwiKKP2A7qPAL1Q9bzcMWvaG3g+q8iEGM1zzrhrUvuIfhccMeOLcDehxF/R7DG79TM3aaDdM3c/knILsk9C0swo8nTkE7/eFlB0QGAljfoDgKPUZOh00aa9meoS1gU7Xqe2r/ld4npM71WwNAIvvrDgqRE2RYFQDk5XnKMyM6nWfqg9144xzH2C0wIAJgA6GvQImq+pIbpqhRoeHeX7BHvQ31VmAKhh7Lp2ugz4Pq6kOjVpCzEAV5LJlwNE1ahpgUBSc3gfv9YYNM9W5b3gPut2iPiMoEq58RQWmetyuis66ncU7B7dbTTMAGakQohq9++67PPDAA4wdO5ZOnToxZcoUWrZsyfTp00vdf8aMGURHRzNlyhQ6derE2LFjuf/++5k8eXLBPr179+add97htttuw2KxlPiMvLw8vv32W95++20GDx5M27Zt+fe//01sbOw5zytEtQhro/rDR1ZB11ugz0Nw66fqpin6EtV3Aax+Hw6vqNWmlsm7kp63jmTqnhK7GA163hrZHaNex+aj6Xy/+QSLd51k3OwEMvMdJfavqzRNw17KND2ASzs0JSbMn4w8B1+tP1ra4UKIcsjOcxSUBdHaX6U2xgw49wEmP/W7fWS3wnsLgxHu/QWe3KKCU6CCSpeMh573QIcRZXyeFYa/Dq2HqNdGM3T3DIAHRcGd38Btc9XsCbdDBcLG/AChrc/9mf2fVI/bvoatX8PKqfDxFWoQPaSlGsAXQlSIBKMamPzcbIw69UsYlmAIjT1/5lD/x+H5Y9B1ZOG2TteqgJK/ZxQjpAWM+gKufgfaXVn654D6BX3E22oEBNRKRN1v9bxnhtu+hDvmqwBSbqpKib3pAxX4OpeBE9Xjxs8h8wRkJaupEju/V9tLq4clhKg0u91OQkICw4YNK7Z92LBhrFq1qtRjVq9eXWL/4cOHs2HDBhyO8t3QOp1OXC4XVmvxZeb9/PxYseLcN/w2m43MzMxiP0JUiYjOcMtMGPFO8ZqH7YdDzzGABt89oqaza1pttfLcvJlR3qn0pWRGAXSOCmbanT0ZOzCW56/uSHSoP8fT8/j3Dztqpp1VwJsVBYUFzL0Meh1jB6p6NjNXHsLpciOEqLisnGxMOjUdVnfTB3D39+r3/7L0vFtNgW7SoXCbOaAwUwlUttJVk+D6qeee1XEuQ55RszLu/RlCmkNkV7h9DnS6XgWimnYs+/gWcSqg5nbAgrEQ/w9VEqT1pfDQsnNnfQkhzkkKmDcw9jyVTu9Gh768hfZ0OrCUo5Bnh6surFH9HlOr93QfDbGD1LZRX8Cyt1QgrPP1ZR/f+lKVxntiE7zbqXC7waI6Pm9arRCiSqWmpuJyuYiIKP4LWEREBMnJyaUek5ycXOr+TqeT1NRUmjVrdt7zBgUF0a9fP1599VU6depEREQEc+fOZe3atbRr1+6cx02aNImXX365HFcmRBUa/oaaxpF+BD6/QdWTCoyA/HSVWXXzx2rU/lxcDtAby15xtrK8waj2w1Th9dR94HaVerM3rEskw7qo6bO9WjXm1hmrWbDpOJd3asq13aNK7F/XFAtGGUuOyd4S15L/W7yPo2l5/LYjuV5ckxB1TV7WGcBzv2EJhjaX1XKLAL9GhXWovFpfqn7Ka9ir8MvT6jvZrxG0GqjuYyoaGBNCAJIZ1eA4c9MBsOkDqvcX24oICIdbZqkRZK92Q2Fs/PkDUaCu4/J/qALnXuEd1AoZcffWnesUwkedvcy7pmllLv1e2v6lbS/LF198gaZpNG/eHIvFwtSpU7njjjswGM79C+Hzzz9PRkZGwc/RozINR9QASxDct1DVPzEHqmnoR1bAye2w8wcV/DmXjZ/DmzHw7djqy6iyZRUWDW41SA3kuGwqeHYecTGhjL+0LQCPz93E2M/Ws3J/asH/6brIW7xcrwOjvuR3jp/ZwN2XxADw0V8H6/S1CFFX2bLTAcjFX82C8BXN4+ChJeoe5c6vVQ1bCUQJccF86NtBlIcrT01LsRt8bIW5tlfA80fhuUR4KQUeXQtRPWq7VUL4tPDwcAwGQ4ksqJSUlBLZT16RkZGl7m80GgkLCyv3udu0acOyZcvIzs7m6NGjrFu3DofDQWxs7DmPsVgsBAcHF/sRokaEtIBrJsPEXTBypvrp/7h6b9k74DhrdTpHvlrA48fH1UpN27+Bvb+p9/LOwPL/qJWfqsIZT9DJr7Gaeh/uyS48x1S9sz1xRTuu6d4MTYPFu1K48+O1/O3rLeQ7XFXTvipmc3jrRRnOGQAf0y8Gi1HPlmMZPPPNVs7k2GuyiULUe/YclRmVp/ex+w0hRJWSYFQDUxCMMpZj2l19Yw5QK2YYLZINJUQNMJvNxMXFER8fX2x7fHw8/fv3L/WYfv36ldh/0aJF9OrVC5PJVOoxZQkICKBZs2acOXOG33//nRtukAKiog6zBqvFOLrdojJ6g1tA1glI+ARs2bD0Tfh4KLzZsnAlWW/dw9+eV6vMzh4Jf7wCX41RU+kqyztFr7EnkOsNRp0qWcS8NGajnvfv6MkffxvCmH4x6HWwYONxbp62ir/2nuLgqew6FZiyFRQv18GPT8BPT5bIOgsLtDDxyvYAfJ1wjKHvLmPxzpM13lYh6it7TjoA+b42+C2EqFISjGpgtPwsAJwmHwxGCSFq3MSJE/n444+ZNWsWu3bt4qmnniIxMZFx48YBamrcmDFjCvYfN24cR44cYeLEiezatYtZs2Yxc+ZMnn766YJ97HY7mzdvZvPmzdjtdo4fP87mzZvZv39/wT6///47v/32G4cOHSI+Pp7LLruMDh06cN9999XcxQtRGUYLDPm7ev7XO2oF2aWT4Nh6cNnVik93zFeFdQMjPUuQ94HjCeqY5G2w6YvynctpU1MC594Oc0arwJeXdyW9xq3UY7ineHDq3gpdTpsmgbxyQ1dmj+1LWICZnUmZjJm1jsv/s4yLXl7E019vYcvR9GLHZOQ6iN95EkcNFgr3TtOLMmbCxs8g4VM4WbIA+8ND2vDNuH60axrI6Rw7D89O4LtNx2qsnULUZy5PjVqbLw5+CyGqjBQwb2D0NpUZ5TZL5yCEqLzRo0dz+vRpXnnlFZKSkujatSsLFy4kJkbVXElKSiIxMbFg/9jYWBYuXMhTTz3F+++/T1RUFFOnTmXkyMLVOk+cOMHFF19c8Hry5MlMnjyZIUOGsHTpUgAyMjJ4/vnnOXbsGKGhoYwcOZLXX3/9grKrhKg1Pe6EFf9XJDupFQz+O8T0V5lK3izfK1+G7x5WtZ3MgdD1ZlVP6o9XoctNKkPqxCa1mId3lVuvYwkw9zbISSnclvBJ4TRB77lDz8qMqmAwyqt/m3B+fmIgr/+yi93JWSSl55Fjd/FNwjG+SThGr5jGPHp5WzLzHLz6805Ss+2M6RfDKzd0vaDzVZQ3MyrKkA7eBTz3/KpW1jpLr1ah/PLEIF74bhvfJBxj4ldbyLG5uMtTU0oIUTrNE4xyGiUzSghxbhKMamD0DpUZpZmDarklQghfMX78eMaPH1/qe59++mmJbUOGDGHjxo3n/LxWrVqdt2jwqFGjGDVqVIXaKUSdYzDBNe/Cb8+poNLAp8DkV3K/bqNg+wI4ugZGz4bofpC4RgWMPrlGPbpsaoWnNpfDxXdBx+tUsfQvR6o6U0HNoNlFqvbU6mnQ52G1il/RQBhAZDf1eGKzOs6vcYUvq1mIH+/d0RNQCxRsTExn9poj/LI1iQ1HznDfJ+uL7T93XSIPD2lD80alXHsV89aMitRlFG7c+2thltpZzEY9b4/sToDZwGerj/DS99sJtBi58eLm1d5WIeorzeadiSH3G0KIc5Npeg2M3u5JzbdI4V4hhBCi1rW9Ah5br5YcLy0QBWo1qtvnwdP7IHawCmINf0O9d3KbCkQFNAW3E/YtUvWkpl0Cn9+oAkrN4+CxDTDqczXlL+sEbPtaHV+iZlR7aNpFfeb2BZW+PJ1OR1xMY/5vdA+WP3sZYwfG4mcyYDHqeXpYey5pHYrDpfHen/uLHed2a+w7mUW2zVnpNhTlnaYXoT9TuPF4AmQln+MI0Ot1/Pv6Ltw/QP0Z/f2bLazan1ql7RLCl+gKZmLI/YYQ4twkM6qBMTpVMEpnlZEKIYQQot7Q60FvKXzd7kpVBD3jKFx8two4pe6DrfNg3ceQ6ilAHt4B7vwGLJ7p+Zc8Aov/BSv/q7KevKvpeTOjdDrocQcsehE2z4HeD1TZJUQEW3np2s48MbQdTpdGaICZvq3DuHXGar7ecJRHhrThVLaNn7eeYOG2JE5m2mjsb+LZqzoyqldL9PrKL07inabXhPTib+z9HeLuOedxOp2Ol67pxMmsfH7ZmsTDXyTw/IhOXN6xKZEh1kq3Swhford7ZmLI4LcQogwSjGpgLJ5glMEvpJZbIoQQQohKGfx08ddN2sMV/4QBT6rV+FJ2wdCXi9eR6nUfLP+PClbNu11taxwLwVGF+3QfBfH/hOMb1Kp6TTpUabODrYW13Xq3CmVQu3CW70vlyv9bVhAsAtDr4Eyug+cWbOPTVYe5tENTerQMITPPyeHTOfibDQxs14RuzUPQAVk2J8FWI7oyVtQtCEZpaWqDJRhsmWr6YhnBKFAZUv+59SJOZdpYdziNF77bBsCVnSN4746LsRgNF/gnIoRvMXrKguisEowSQpybBKMaGIs7BwCDn3QOQgghhE+yhsCgv537vd5jYcW7YLSqTKmBT4G+SCAlsCm0G6ZqKW2eowqoV6OnrmzP8n2p2JxuAswGruwcwbXdo+jfNow5axP5v/i97E7OYndyVoljJy/ai5/JgN3lxuXW6NwsmA/ujqNlqH+p57I51DS9UG8wqvsoFbg7sAQceeeeKulhNRmYdV9vPl15iMW7UthyLJ34nSd57tttvDvqojIDYUI0FGaHGvzWy+C3EKIMEoxqQDRNw+rOBT2YAxrVdnOEEEIIURsue0EVKm/ZB0JalL5Pj9tVMGrLXFUYPf0IxAxQxdENVbtqZc/oxnx+fx/yHC6GtG+C1VQYGBs7qDU39GjOkj0pbDicxs6kTBr7m4kJ8+d0tp0V+1LJKlJXamdSJje8v5IP746jV6vQEufyZkaFuj3BqLZD1RS9jKOwLx46X3/e9gZajDx2eTseu7wdy/ed4t5P1vPdpuPEhgfwxBXtKvmnIUT9Z3apYJRRglFCiDJIMKoByXe4CSAPAHOAdA5CCCFEg2QwQdeby96n/VWqplT2SVg+WW3b9jWs+p/Kumo95NyBrAswuH2Tc77XJMjCqF4tGdWrZYn3HC43iWm5BFmM2JxuHvkyge3HMxn94Rp6t2rM5R2b0iosgECLEbNRz76TKrsqxOUJRgVFqpUMV02F319QBeL9GpW73YPaNeHVG7rywnfbeDd+L/tSshk3pDUdIoI4nWPnTK6dPLsLDbioRSMMVVD3Soi6zuqZiWGS+w0hRBkkGNWAZNucBJELgMW/Ue02RgghhBB1l9ECV78Nm2ZDaCz4h0PCp5B2AH4Yr/ZpFA03fQgx/WqtmSaDnjZNAgtef/VwP/7+zVZ+2ZrEmoNprDmYVuIYPW6CnZ7tgZEw5BnY9aNaWfCXv8HIj1Uh93K6o280x9NzeX/JAX7acoKftpxApwNNK75fn9hQPr+/T7HMLyF8kZ8nGCUzMYQQZZFgVAOSY3MSpFOZUXqpGSWEEEKIsnQfpX68Bk6ANTNg98+QvA3SE+HHx2D8WjDUjV8p/c1G3r+jJ88Oz+XP3SdZsT+V1Gw7OTYndpcbo15HC3MW+tNu0OkhoIlq+8iZMHMYbP9GTV/s/aBawbCc/j68IyO6NWPGsoP8svUEbk0VYG/sb8bPbCA128a6Q2k8Nmcj0++Kw2Qo/2cLUZ9omkaAlgs6sAY1ru3mCCHqsLrxm4OoEdk2Jy080/SQpVaFEEIIURGWIBjyd/WTmwb/i4PT+2HbV9DjjtpuXTHRYf7cOyCWewfElnzzxGb4kMJAFECLXnDp87DkNfj1GVgzHfo9Cr0eKHdQqktUCP+7/WJeub4LLk2jsb+5YFreukNp3D1zLYt3pfDE3E38fXgHWhfJ6BLCV9ic7oKZGH6BEowSQpybDMs0INn5DgILglFBtdsYIYQQQtRf/qEw4En1fNlb4HJU7vPyzoAtu/LtKo/sk+oxKLL49kETYcizYG0EZw7Bwqdh2ZsV/vjGAWbCAy3F6kP1iQ1l+l09Meh1/Lo9mcv/s4xRH6xm5f7USlyIEHVPdm4uVp36PvAPKrmIgBBCeEkwqgHJy83GqFOryEgwSgghhBCV0udBlV105jD88Qr8+Rp8cz8s/jdsngN56ef/jLx0+P1FeKcdfDC4ZgJSWUnqMfCsYJTeoFYanLgTrviX2rbsLbXaXhW4vGMEX47tyxUdm6LXqWypOz9ey9jPNrA/JavYvvkOF9pZRadsThdu91mFqISoY3IzzxQ8l7IgQoiyyDS9BsSWkw6AGz16c0DtNkYIIYQQ9Zs5AAY+pVahWzW15PuhreGhZWANhpxUNfWty00Q2VW9f3glzL8L8jzFxNMOwJI34Ko3qrfdWefIjPIyB6gsqczjsP5jWPAgPLRUXU8lXdI6jEtah5Gckc+MZQf4Ys0RFu86yeJdJ+kTG0q/1mGsPniaDYfTiItpzNTbL6ZJoIUpi/fx4V8HQQctGvnRITKIwe2bMKR9E6Ia+VW6XUJUlfwsFYzKwUqAXor1CyHOTYJRDYgjJwOAPL0/ARVYJUYIIYQQolS97oddP6lso5aXQNNOkHFUbUs7qKa6XfMfmH0zJG2BTV/AI6tVraYFD6pAVHgH6Harqte0djp0vxWiLq6+Nnszo84VjPIa/oaqL3V8A3x0OQx7DXrcWaGV9s4lMsTKv6/vwl2XRPP2b3tYvOsk6w6lse5Q4ep/6w+fYcR/lxMbHsDGxPSC7QdTcziYmsOv25PR6eChwa15ZnjHYtMChagt+dkqGJWn80eGvoUQZZFgVAPizMsEwKYPkM5BCCGEEJVn8oP7fyu5vdut8MnVsHU+HNugsp5A1Wv6eQL4NVaZR41j4aElKhvp1G61mt2PT8CDS6pvhb5z1Yw6m9ECo7+AOaPU6oE/PApb5sE170KT9lXSlLZNg/hwTC+SM/L5esNRdp/Mok+rULpEBfPvn3aw/XgmZxLTCTAbeOPmbvSMbkxiWi4JR86wdE8KGxPT+WDZQXaeyORf13UhwGIgyGoi0FL4Z3c8PY9V+1O5tVfLKmmzEGWx53oHv+VuQwhRtgYfjHK5NTYcVqNQfVuH1XJrqpczT3UOdqN0DkIIIYSoRtGXwJDnYOkbKhBlClDT7375G+z6sXC/G95TgSiAqybB/nhI3qoyqq79vyrJQirhXDWjShMcpQJja6bBkklweDlM7w8DnoDBz4DJWiVNigyx8vgV7Ypt+2Zcf/4vfi/7UrL5x7WdiQ1Xf04tQ/0Z0DacJ65ox09bTvDMN1tZvi+Voe8uA9QfWedmwfSKacy24xkFWVW9W4XSKlx+BxTVy5mbDkC+QVaLFEKUrcEXMP9i9WFGf7iGd+P31nZTql++yoxySjBKCCGEENVt0N+g7ZVgDoLRn0PcvSpA5dV7LLQaWPg6sClcNxXQQcInqhaVVoGC3YdXQsqu8+9XUDMqonyfazCplQMfXQPthoHbAcv/A3NHgyO//O2rIKvJwPMjOjHr3t4FgaizXXdRFAvG96dr82D8zQaMeh2aBjtOZPLZ6iNsTExHp1Or+WXmV3LFQyHKwZXrHfyWYJQQomwNPjPqik4R/Punnaw/nEZqto3wQEttN6n62DzBKJOspCeEEEKIamYwwp1fgyMPzP5q28CnVOZT7mkY+u+Sx3S5EWz/gx8fU9lIJ7dDiz7QvCfEDgGL5wbX5VQpQN4CyfsXw+yRoDfC1W9D7wdKb5PbVWSaXrOKXU/jVnDHVyqz67tH4OBSVYD9ti/VlL6yOPLVPtWQ6dWpWTA/Pz6o4HVKVj6rD5xmU2I6MWH+jOjWjIjgqsngEuJ83PkqGOWQYJQQ4jwafDCqZag/3ZqHsO14Bot2nOSOvtG13aTqY1PLBrvNEowSQgghRA3Q6QoDUaACVKO/KPuYnneDM19N1Tv0l/oBMFggph/kpqn6UkHN4N5fVEbVwmfUPm4n/DIRkjZDrwcgshvo9JB3Rk0HzM8AzQXoIKDphV1P5xvAPwxm36KmFX51D9z6iaqfBeB2q0e9ZwLCwWWqgPugv8FlL1T8nBXUNMjKDT2ac0OP5tV+LiFK8MzEcJmDa7khQoi6rsFP0wO4qquqGfDr9qRabkn10tuzAdAkGCWEEEKIuqzPgzBuJYyYDBffrbKSXDaVjZS8FVx2SD+igjx/vqrqUgVGwKXPAzrY+Dl8OAQmtYTXI+HtWPhPB9jxvfr8gCaVK5DeaiDcMQ+MVtj7K3xxs5r+t/QtmNQCvi2SmbXsLRUkWzOjWqf1CVEX6O1q8FszS2aUEKJsDT4zCuDqrpG88/seVh84TUaugxB/U203qVqYHKpz0FklGCWEEEKIOi6yq/oBVTsqZRccWakyooKawVd3Q+pe9QMw7DXoPgpa9FKBn6NrC0oUACo76te/q+flrRdVltaXwl3fwtw7IHEVvNvJk3UF7FigMrz8QlWbAWwZsPtn6HZL5c8tRB1lsHv+z1kkM0oIUTYJRgGtmwTSMTKI3clZxO86yS1xLWq7SdXC6MwBQGcNqeWWCCGEEEJUgE4HEZ3Vj9dd38Ks4WrqXcwA6Har2t52qPpxu+D0fjCYwa8RzLuzMDBU0XpR59JqINz/q6pXlZUEQVHQtBMc+APi/wVNOqr9jH7gzIPNcyQYJXyaweG53/CT+w0hRNlkmp7bBT89yZhWZwD4dZvvTtUzu1TnYPSTkQohhBBC1HNNO8E9P0Gfh+HmD0sWB9cboEkHCI0Fv8Zw+zyI6qneaxxbde2I6AIPLYWbP4LH1qtHc5CaTrjtK7XPje+rxwN/Qsbxqju3EHWM2almYuhl8FsIcR6SGbVyCiR8ym2mr/lZ/yTL93Xn/SX7GdK+CR0jgzAafCdeZ/UGo/wlGCWEEEIIH9DsIvVTHtZguPs72P4tdLquatsRFKmmCIJa8W/gk/Dna+p1y0ug60hYP1NlZq37QGVK7f5Z1ZwKCIeO10DPMVXbJiFqgcV7vxEgwSghRNkkGNX7QTi4FP2hv/jU/DbP2B/i3d8dvPO7AYtRT/uIIKIaWTEa9JgNegIsBgIsRqJD/bmoRSM6RAZhqicBKz8tB3Rg8pfOQQghhBANkF8j6P3AeXertEvGw7qPITsZ+o1X23p4pgmu/G/J/ff+rrK2vDWyhKinrC61YJLZv1HtNkQIUedJMMoaDHd+Awsewrzze6aYp/GG7jPWuTtw2BVOWnIwmcn+5GEhTzNzEgs5WPnaHU0awZgMOiJDrESF+BEbHkDbpoFENfLDoNeh1+kwGXSYDXosJgP+ZgNmo55cm4tsm5PGASZahQVgNRmq/TIdLjf+Wi7owBrYuNrPJ4QQQgjRYJkDYMwPkLIDOl2vtnW+AX5/AfLTIaIb9H8MLEEqY+rAHxD/T7h7QfHPObIa9v0OWcmQmwaR3aD9cGgep6YhClHH+Gu5AJgDG9VuQ4QQdd4FBaOmTZvGO++8Q1JSEl26dGHKlCkMGjTonPsvW7aMiRMnsmPHDqKionjmmWcYN25cwfsfffQRn3/+Odu3bwcgLi6ON954gz59+lxI8yrOaIFbZsEfrSDhE/zzM7hUt7HMPx0HJn6lH5/aLmd7WixH0/JYeyjtgk4fFmBGr1d1Dhr5mWgabMGg15OSmU96roPQADNRjaw0DbYSHmAm2M+Ezekm3+FCp9NhMeoxGXSYDHrMRj1RjfxoEx5Is0bWgqytHJuTIF0eAFbpHIQQQgghqlfTjurHyxIID8RDzimI6V9Y46ppZ3ivtwpI7V+siq/npMKil2DL3OKfue93WD4ZmvWA+34Fs3+NXY4Q5RHgmYkh9xtCiPOpcDBq/vz5TJgwgWnTpjFgwAA++OADrr76anbu3El0dHSJ/Q8dOsSIESN48MEHmT17NitXrmT8+PE0adKEkSNHArB06VJuv/12+vfvj9Vq5e2332bYsGHs2LGD5s2bV/4qy0NvgCtfhiv+qQpOHl0H2SmQmwq2LLDngiNHPealYUo7yPX8xfWWv3DrjGQHxnBGH0qa08oZt5VsXRCZBJBOEGlaECfcjdjnjCDFFUAzs42WxnRO5sK+/GBO5xQ241SWjX0p2cWalpyZz86kTC6EyaDDajKg1+lYhgpGGWV1CyGEEEKImtekvfopKjQW+j4Mq9+DX59VBdH3/wn2LECnVgmM6AzmQDXNb+8iSNoMa2fAoIm1cRX1WkUH1UX5ORx2AnQ2AAKCQmu5NUKIuk6naZpWkQP69u1Lz549mT59esG2Tp06ceONNzJp0qQS+z/77LP8+OOP7Nq1q2DbuHHj2LJlC6tXry71HC6Xi8aNG/Pee+8xZkz5ijlmZmYSEhJCRkYGwcE1UKD7eAKs/RD2/qqWFC4vvQncjmKbnNZQnIFROPyb4nA4cduycaOHwKbogiLJMIaTRBhpDhNZeXay7ZDhH01uQAvcmh6dIweX00EmAeQ5XCSm5XI4NRe7y13kLBr7LXdj1Llh4m4IrqIljYUQ9UaNf0/WcfLnIYSoM3LTYOrFagqfV0Q3uO6/0CKu+L5b5sN3D4ElGJ7YDAFh1dYsX/uenD9/PnfffXexQfWPP/74nIPqZ/O1P4+qln46hUb/aweA84WTGM3WWm6REKKmVeR7skKZUXa7nYSEBJ577rli24cNG8aqVatKPWb16tUMGzas2Lbhw4czc+ZMHA4HJpOpxDG5ubk4HA5CQ+twRL15HNz8AWgaZB6HU7vVLxL5GZ6fdMhLh7wzKtU646jazxuI8gsFRx448zDmp2HMT6PE17Vn1l8ToG1pbTCY1aPLrh71JgiMgCbtcXfuSn5wK/KNQeSZGmMLaYvxM09wyiqdpxBCCCFEneEfCje8DwmfQote0OYKT12oUhbJ6XYrrP4fJG9TU/aumqSy+c8cgeyTxbP6LYEQ0BQCm6gC6Q38d8B3332XBx54gLFjxwIwZcoUfv/9d6ZPn17qoLqomNysMzQC8jUTVglECSHOo0LBqNTUVFwuFxEREcW2R0REkJycXOoxycnJpe7vdDpJTU2lWbOSGTrPPfcczZs3Z+jQoedsi81mw2azFbzOzLywaWyVptNBSAv1cz72XFUnILApmPxUICvvjApSZSZBVhLojaropdup9s1KgswTkHEcnHmgM4AzH07vV49FuR2QeQwyj6E/8Cf+QEElAb3nr1qnB5PUFxBCCCGEqFM6Xat+zkevhytfgS9ugnUfwZ6FcObw+Y97cAk071npZtZXFzKoXlX3G7vXLyZj7ZcXdGx9YrBlEAXk6AJKDrILIcRZLqiAuc5bcNFD07QS2863f2nbAd5++23mzp3L0qVLsVrP/TU2adIkXn755Yo0u/aZ/cEcU/hap1MjYf6hanWUinC7IOOYCi75h6pgU3aKClyl7IST29X7eemFWVkAwc0LC2YKIYQQQoj6p83l6ufAn55AlGdwNDACApqoVfrM/pCfqQY3s1MgKLK2W12rLmRQvaruN7KO7qBv6oLz7+gjzhjCqL7Jo0IIX1GhYFR4eDgGg6HEF3ZKSkqJL3avyMjIUvc3Go2EhRX/mpo8eTJvvPEGixcvpnv37mW25fnnn2fixMKijZmZmbRs2bIil1O/6Q3QOKb4tkYt1U903+LbNU1lUh1erlZfEUIIIYQQ9dtNH8LW+dCkI7TsDVZZoKY8KjKoXlX3G43bxLH6zNgKH1c/6Yjoe0ttN0IIUQ9UKBhlNpuJi4sjPj6em266qWB7fHw8N9xwQ6nH9OvXj59++qnYtkWLFtGrV69i9aLeeecdXnvtNX7//Xd69ep13rZYLBYsFktFmt9w6XQQ3k79CCGEEEKI+i+wCfR/rLZbUW9cyKB6Vd1vtL1oIG0vGljpzxFCCF9SSlXEsk2cOJGPP/6YWbNmsWvXLp566ikSExMZN24coEYQiq6AN27cOI4cOcLEiRPZtWsXs2bNYubMmTz99NMF+7z99tu89NJLzJo1i1atWpGcnExycjLZ2dlVcIlCCCGEEEKIhqzooHpR8fHx9O/fv5ZaJYQQDVeFg1GjR49mypQpvPLKK/To0YO//vqLhQsXEhOjpowlJSWRmJhYsH9sbCwLFy5k6dKl9OjRg1dffZWpU6cycuTIgn2mTZuG3W7nlltuoVmzZgU/kydProJLFEIIUZ2mTZtGbGwsVquVuLg4li9fXub+y5YtIy4uDqvVSuvWrZkxY0ax93fs2MHIkSNp1aoVOp2OKVOmlPgMp9PJSy+9RGxsLH5+frRu3ZpXXnkFt9tdlZcmhBDCh5xvUF0IIUTNuaAC5uPHj2f8+PGlvvfpp5+W2DZkyBA2btx4zs87fPjwhTRDCCFELZs/fz4TJkxg2rRpDBgwgA8++ICrr76anTt3Eh0dXWL/Q4cOMWLECB588EFmz57NypUrGT9+PE2aNCkYpMjNzaV169bceuutPPXUU6We96233mLGjBl89tlndOnShQ0bNnDfffcREhLCk08+Wa3XLIQQon4aPXo0p0+f5pVXXiEpKYmuXbsWG1QXQghRc3Sad2m7ei4zM5OQkBAyMjIIDg6u7eYIIUSdUx3fk3379qVnz55Mnz69YFunTp248cYbmTRpUon9n332WX788Ud27dpVsG3cuHFs2bKF1atXl9i/VatWTJgwgQkTJhTbfu211xIREcHMmTMLto0cORJ/f3+++OKLcrVd+g0hhCibfE8WJ38eQghRtop8T1Z4mp4QQggBYLfbSUhIYNiwYcW2Dxs2jFWrVpV6zOrVq0vsP3z4cDZs2IDD4Sj3uQcOHMgff/zB3r17AdiyZQsrVqxgxIgR5zzGZrORmZlZ7EcIIYQQQghR8y5omp4QQgiRmpqKy+UqsQpRREREidWKvJKTk0vd3+l0kpqaSrNmzcp17meffZaMjAw6duyIwWDA5XLx+uuvc/vtt5/zmEmTJvHyyy+X6/OFEEIIIYQQ1Ucyo4QQQlSKTqcr9lrTtBLbzrd/advLMn/+fGbPns2cOXPYuHEjn332GZMnT+azzz475zHPP/88GRkZBT9Hjx4t9/mEEEIIIYQQVUcyo4QQQlyQ8PBwDAZDiSyolJSUEtlPXpGRkaXubzQaCQsLK/e5//73v/Pcc89x2223AdCtWzeOHDnCpEmTuOeee0o9xmKxYLFYyn0OIYQQQgghRPWQzCghhBAXxGw2ExcXR3x8fLHt8fHx9O/fv9Rj+vXrV2L/RYsW0atXL0wmU7nPnZubi15fvAszGAy43e5yf4YQQgghhBCidkhmlBBCiAs2ceJE7r77bnr16kW/fv348MMPSUxMZNy4cYCaGnf8+HE+//xzQK2c99577zFx4kQefPBBVq9ezcyZM5k7d27BZ9rtdnbu3Fnw/Pjx42zevJnAwEDatm0LwHXXXcfrr79OdHQ0Xbp0YdOmTbz77rvcf//9NfwnIIQQQgghhKgoCUYJIYS4YKNHj+b06dO88sorJCUl0bVrVxYuXEhMTAwASUlJJCYmFuwfGxvLwoULeeqpp3j//feJiopi6tSpjBw5smCfEydOcPHFFxe8njx5MpMnT2bIkCEsXboUgP/973/84x//YPz48aSkpBAVFcXDDz/MP//5z5q5cCGEEEIIIcQF02neyrH1XEZGBo0aNeLo0aMEBwfXdnOEEKLOyczMpGXLlqSnpxMSElLbzal10m8IIUTZpN8oTvoNIYQoW0X6DZ/JjMrKygKgZcuWtdwSIYSo27KysuSmAuk3hBCivKTfUKTfEEKI8ilPv+EzmVFut5sTJ04QFBRUoeXBoTB6V19HOep7+6H+X0N9bz/U/2uQ9p+fpmlkZWURFRVVovh3QyT9Rv1tP9T/a6jv7Yf6fw3S/vOTfqM46Tfqb/uh/l+DtL/21fdrqGv9hs9kRun1elq0aFGpzwgODq6X/6i86nv7of5fQ31vP9T/a5D2l01GtgtJv1H/2w/1/xrqe/uh/l+DtL9s0m8Ukn6j/rcf6v81SPtrX32/hrrSb8gQhxBCCCGEEEIIIYSoMRKMEkIIIYQQQgghhBA1RoJRgMVi4V//+hcWi6W2m3JB6nv7of5fQ31vP9T/a5D2i5pU3/++6nv7of5fQ31vP9T/a5D2i5pU3/++6nv7of5fg7S/9tX3a6hr7feZAuZCCCGEEEIIIYQQou6TzCghhBBCCCGEEEIIUWMkGCWEEEIIIYQQQgghaowEo4QQQgghhBBCCCFEjZFglBBCCCGEEEIIIYSoMQ0+GDVt2jRiY2OxWq3ExcWxfPny2m5SqSZNmkTv3r0JCgqiadOm3HjjjezZs6fYPpqm8e9//5uoqCj8/Py49NJL2bFjRy21uGyTJk1Cp9MxYcKEgm31of3Hjx/nrrvuIiwsDH9/f3r06EFCQkLB+3X9GpxOJy+99BKxsbH4+fnRunVrXnnlFdxud8E+deka/vrrL6677jqioqLQ6XR8//33xd4vT1ttNhuPP/444eHhBAQEcP3113Ps2LE6cQ0Oh4Nnn32Wbt26ERAQQFRUFGPGjOHEiRN16hpEcdJv1A7pN2qH9BvSb4jKk36jdki/UTuk35B+o9y0BmzevHmayWTSPvroI23nzp3ak08+qQUEBGhHjhyp7aaVMHz4cO2TTz7Rtm/frm3evFm75pprtOjoaC07O7tgnzfffFMLCgrSvv32W23btm3a6NGjtWbNmmmZmZm12PKS1q1bp7Vq1Urr3r279uSTTxZsr+vtT0tL02JiYrR7771XW7t2rXbo0CFt8eLF2v79+wv2qevX8Nprr2lhYWHazz//rB06dEj7+uuvtcDAQG3KlCkF+9Sla1i4cKH24osvat9++60GaN99912x98vT1nHjxmnNmzfX4uPjtY0bN2qXXXaZdtFFF2lOp7PWryE9PV0bOnSoNn/+fG337t3a6tWrtb59+2pxcXHFPqO2r0EUkn6jdki/UXuk35B+Q1SO9Bu1Q/qN2iP9hvQb5dWgg1F9+vTRxo0bV2xbx44dteeee66WWlR+KSkpGqAtW7ZM0zRNc7vdWmRkpPbmm28W7JOfn6+FhIRoM2bMqK1mlpCVlaW1a9dOi4+P14YMGVLQOdSH9j/77LPawIEDz/l+fbiGa665Rrv//vuLbbv55pu1u+66S9O0un0NZ3+xlqet6enpmslk0ubNm1ewz/HjxzW9Xq/99ttvNdZ2r9I6uLOtW7dOAwp+Sa1r19DQSb9R86TfqF3Sb0i/ISpH+o2aJ/1G7ZJ+Q/qN8mqw0/TsdjsJCQkMGzas2PZhw4axatWqWmpV+WVkZAAQGhoKwKFDh0hOTi52PRaLhSFDhtSp63n00Ue55pprGDp0aLHt9aH9P/74I7169eLWW2+ladOmXHzxxXz00UcF79eHaxg4cCB//PEHe/fuBWDLli2sWLGCESNGAPXjGrzK09aEhAQcDkexfaKioujatWudux6vjIwMdDodjRo1AurnNfgq6Tdqh/QbtUv6jbr/nSv9Rt0l/UbtkH6jdkm/Ufe/c+tKv2Gstk+u41JTU3G5XERERBTbHhERQXJyci21qnw0TWPixIkMHDiQrl27AhS0ubTrOXLkSI23sTTz5s1j48aNrF+/vsR79aH9Bw8eZPr0O3HVFwAABXtJREFU6UycOJEXXniBdevW8cQTT2CxWBgzZky9uIZnn32WjIwMOnbsiMFgwOVy8frrr3P77bcD9ePvwas8bU1OTsZsNtO4ceMS+9TF/+f5+fk899xz3HHHHQQHBwP17xp8mfQbNU/6jdon/UbhPnXx/7n0G3Wb9Bs1T/qN2if9RuE+dfH/eV3qNxpsMMpLp9MVe61pWoltdc1jjz3G1q1bWbFiRYn36ur1HD16lCeffJJFixZhtVrPuV9dbT+A2+2mV69evPHGGwBcfPHF7Nixg+nTpzNmzJiC/eryNcyfP5/Zs2czZ84cunTpwubNm5kwYQJRUVHcc889BfvV5Ws424W0tS5ej8Ph4LbbbsPtdjNt2rTz7l8Xr6GhqE//P7yk36gd0m/UjWs4m/QboqbVp/8fXtJv1A7pN+rGNZxN+o3q0WCn6YWHh2MwGEpE+lJSUkpEPuuSxx9/nB9//JElS5bQokWLgu2RkZEAdfZ6EhISSElJIS4uDqPRiNFoZNmyZUydOhWj0VjQxrrafoBmzZrRuXPnYts6depEYmIiUPf/DgD+/ve/89xzz3HbbbfRrVs37r77bp566ikmTZoE1I9r8CpPWyMjI7Hb7Zw5c+ac+9QFDoeDUaNGcejQIeLj4wtGKaD+XENDIP1GzZJ+o25cg/QbJfepC6TfqB+k36hZ0m/UjWuQfqPkPnVBXew3Gmwwymw2ExcXR3x8fLHt8fHx9O/fv5ZadW6apvHYY4+xYMEC/vzzT2JjY4u9HxsbS2RkZLHrsdvtLFu2rE5czxVXXMG2bdvYvHlzwU+vXr2488472bx5M61bt67T7QcYMGBAieVt9+7dS0xMDFD3/w4AcnNz0euL/7c3GAwFS63Wh2vwKk9b4+LiMJlMxfZJSkpi+/btdeZ6vB3Dvn37WLx4MWFhYcXerw/X0FBIv1GzpN+oG9cg/Ubd+86VfqP+kH6jZkm/UTeuQfqNuvedW2f7jWorjV4PeJdanTlzprZz505twoQJWkBAgHb48OHabloJjzzyiBYSEqItXbpUS0pKKvjJzc0t2OfNN9/UQkJCtAULFmjbtm3Tbr/99jq1zOfZiq5uoWl1v/3r1q3TjEaj9vrrr2v79u3TvvzyS83f31+bPXt2wT51/RruuecerXnz5gVLrS5YsEALDw/XnnnmmYJ96tI1ZGVlaZs2bdI2bdqkAdq7776rbdq0qWDlh/K0ddy4cVqLFi20xYsXaxs3btQuv/zyGl1qtaxrcDgc2vXXX6+1aNFC27x5c7H/2zabrc5cgygk/Ubtkn6j5km/If2GqBzpN2qX9Bs1T/oN6TfKq0EHozRN095//30tJiZGM5vNWs+ePQuWLq1rgFJ/Pvnkk4J93G639q9//UuLjIzULBaLNnjwYG3btm211+jzOLtzqA/t/+mnn7SuXbtqFotF69ixo/bhhx8We7+uX0NmZqb25JNPatHR0ZrVatVat26tvfjii8W+iOrSNSxZsqTUf/f33HNPudual5enPfbYY1poaKjm5+enXXvttVpiYmKduIZDhw6d8//2kiVL6sw1iOKk36g90m/UPOk3pN8QlSf9Ru2RfqPmSb8h/UZ56TRN0y48r0oIIYQQQgghhBBCiPJrsDWjhBBCCCGEEEIIIUTNk2CUEEIIIYQQQgghhKgxEowSQgghhBBCCCGEEDVGglFCCCGEEEIIIYQQosZIMEoIIYQQQgghhBBC1BgJRgkhhBBCCCGEEEKIGiPBKCGEEEIIIYQQQghRYyQYJYQQQgghhBBCCCFqjASjhBBCCCGEEEIIIUSNkWCUEEIIIYQQQgghhKgxEowSQgghhBBCCCGEEDVGglFCCCGEEEIIIYQQosb8P7Pj+/abZwgUAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "ax[0].plot(logs[\"train_losses\"], label=\"Train\")\n",
    "ax[0].plot(logs[\"test_losses\"], label=\"Validation\")\n",
    "ax[0].set_title(\"Combined loss\")\n",
    "ax[0].legend()\n",
    "ax[1].plot(logs[\"train_recon_losses\"], label=\"Train\")\n",
    "ax[1].plot(logs[\"test_recon_losses\"], label=\"Validation\")\n",
    "ax[1].set_title(\"Reconstruction loss\")\n",
    "ax[1].legend()\n",
    "ax[2].plot(logs[\"train_cov_losses\"], label=\"Train\")\n",
    "ax[2].plot(logs[\"test_cov_losses\"], label=\"Validation\")\n",
    "ax[2].set_title(\"Covariance loss\")\n",
    "ax[2].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
